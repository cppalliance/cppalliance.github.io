<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.7">Jekyll</generator><link href="http://cppalliance.org/feed.xml" rel="self" type="application/atom+xml" /><link href="http://cppalliance.org/" rel="alternate" type="text/html" /><updated>2025-10-20T16:30:42+00:00</updated><id>http://cppalliance.org/feed.xml</id><title type="html">The C++ Alliance</title><subtitle>The C++ Alliance is dedicated to helping the C++ programming language evolve. We see it developing as an ecosystem of open source libraries and as a growing community of those who contribute to those libraries..</subtitle><entry><title type="html">Making the Clang AST Leaner and Faster</title><link href="http://cppalliance.org/mizvekov,/clang/2025/10/20/Making-Clang-AST-Leaner-Faster.html" rel="alternate" type="text/html" title="Making the Clang AST Leaner and Faster" /><published>2025-10-20T00:00:00+00:00</published><updated>2025-10-20T00:00:00+00:00</updated><id>http://cppalliance.org/mizvekov,/clang/2025/10/20/Making-Clang-AST-Leaner-Faster</id><content type="html" xml:base="http://cppalliance.org/mizvekov,/clang/2025/10/20/Making-Clang-AST-Leaner-Faster.html">&lt;p&gt;Modern C++ codebases — from browsers to GPU frameworks — rely heavily on templates, and that often means &lt;em&gt;massive&lt;/em&gt; abstract syntax trees. Even small inefficiencies in Clang’s AST representation can add up to noticeable compile-time overhead.&lt;/p&gt;

&lt;p&gt;This post walks through a set of structural improvements I recently made to Clang’s AST that make type representation smaller, simpler, and faster to create — leading to measurable build-time gains in real-world projects.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;A couple of months ago, I landed &lt;a href=&quot;https://github.com/llvm/llvm-project/pull/147835&quot;&gt;a large patch&lt;/a&gt; in Clang that brought substantial compile-time improvements for heavily templated C++ code.&lt;/p&gt;

&lt;p&gt;For example, in &lt;a href=&quot;https://github.com/NVIDIA/stdexec&quot;&gt;stdexec&lt;/a&gt; — the reference implementation of the &lt;code&gt;std::execution&lt;/code&gt; &lt;a href=&quot;http://wg21.link/p2300&quot;&gt;feature slated for C++26&lt;/a&gt; — the slowest test (&lt;a href=&quot;https://github.com/NVIDIA/stdexec/blob/main/test/stdexec/algos/adaptors/test_on2.cpp&quot;&gt;&lt;code&gt;test_on2.cpp&lt;/code&gt;&lt;/a&gt;) saw a &lt;strong&gt;7% reduction in build time&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Also the &lt;a href=&quot;https://www.chromium.org/Home/&quot;&gt;Chromium&lt;/a&gt; build showed a &lt;strong&gt;5% improvement&lt;/strong&gt; (&lt;a href=&quot;https://github.com/llvm/llvm-project/pull/147835#issuecomment-3278893447&quot;&gt;source&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;At a high level, the patch makes the Clang AST &lt;em&gt;leaner&lt;/em&gt;: it reduces the memory footprint of type representations and lowers the cost of creating and uniquing them.&lt;/p&gt;

&lt;p&gt;These improvements will ship with &lt;strong&gt;Clang 22&lt;/strong&gt;, expected in the next few months.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;how-elaboration-and-qualified-names-used-to-work&quot;&gt;How elaboration and qualified names used to work&lt;/h2&gt;

&lt;p&gt;Consider this simple snippet:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;namespace NS {
  struct A {};
}
using T = struct NS::A;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The type of &lt;code&gt;T&lt;/code&gt; (&lt;code&gt;struct NS::A&lt;/code&gt;) carries two pieces of information:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;It’s &lt;em&gt;elaborated&lt;/em&gt; — the &lt;code&gt;struct&lt;/code&gt; keyword appears.&lt;/li&gt;
  &lt;li&gt;It’s &lt;em&gt;qualified&lt;/em&gt; — &lt;code&gt;NS::&lt;/code&gt; acts as a &lt;a href=&quot;https://eel.is/c++draft/expr.prim.id.qual#:nested-name-specifier&quot;&gt;&lt;em&gt;nested-name-specifier&lt;/em&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Here’s how the &lt;a href=&quot;https://compiler-explorer.com/z/WEWc4817x&quot;&gt;AST dump&lt;/a&gt; looked before this patch:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ElaboratedType 'struct NS::A' sugar
`-RecordType 'test::NS::A'
  `-CXXRecord 'A'
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;RecordType&lt;/code&gt; represents a direct reference to the previously declared &lt;code&gt;struct A&lt;/code&gt; — a kind of &lt;em&gt;canonical&lt;/em&gt; view of the type, stripped of syntactic details like &lt;code&gt;struct&lt;/code&gt; or namespace qualifiers.&lt;/p&gt;

&lt;p&gt;Those syntactic details were stored separately in an &lt;code&gt;ElaboratedType&lt;/code&gt; node that wrapped the &lt;code&gt;RecordType&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Interestingly, an &lt;code&gt;ElaboratedType&lt;/code&gt; node existed even when no elaboration or qualification appeared in the source (&lt;a href=&quot;https://compiler-explorer.com/z/ncW5bzWrc&quot;&gt;example&lt;/a&gt;). This was needed to distinguish between an explicitly unqualified type and one that lost its qualifiers through template substitution.&lt;/p&gt;

&lt;p&gt;However, this design was expensive: every &lt;code&gt;ElaboratedType&lt;/code&gt; node consumed &lt;strong&gt;48 bytes&lt;/strong&gt;, and creating one required extra work to uniquify it — an important step for Clang’s fast type comparisons.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;a-more-compact-representation&quot;&gt;A more compact representation&lt;/h2&gt;

&lt;p&gt;The new approach removes &lt;code&gt;ElaboratedType&lt;/code&gt; entirely. Instead, elaboration and qualifiers are now stored &lt;strong&gt;directly inside &lt;code&gt;RecordType&lt;/code&gt;&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;https://compiler-explorer.com/z/asz5q5YGj&quot;&gt;new AST dump&lt;/a&gt; for the same example looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;RecordType 'struct NS::A' struct
|-NestedNameSpecifier Namespace 'NS'
`-CXXRecord 'A'
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;struct&lt;/code&gt; elaboration now fits into previously unused bits within &lt;code&gt;RecordType&lt;/code&gt;, while the qualifier is &lt;em&gt;tail-allocated&lt;/em&gt; when present — making the node variably sized.&lt;/p&gt;

&lt;p&gt;This change both shrinks the memory footprint and eliminates one level of indirection when traversing the AST.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;representing-nestednamespecifier&quot;&gt;Representing &lt;code&gt;NestedNameSpecifier&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;NestedNameSpecifier&lt;/code&gt; is Clang’s internal representation for name qualifiers.&lt;/p&gt;

&lt;p&gt;Before this patch, it was represented by a pointer (&lt;code&gt;NestedNameSpecifier*&lt;/code&gt;) to a uniqued structure that could describe:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The global namespace (&lt;code&gt;::&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;A named namespace (including aliases)&lt;/li&gt;
  &lt;li&gt;A type&lt;/li&gt;
  &lt;li&gt;An identifier naming an unknown entity&lt;/li&gt;
  &lt;li&gt;A &lt;code&gt;__super&lt;/code&gt; reference (Microsoft extension)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For all but cases (1) and (5), each &lt;code&gt;NestedNameSpecifier&lt;/code&gt; also held a &lt;em&gt;prefix&lt;/em&gt; — the qualifier to its left.&lt;/p&gt;

&lt;p&gt;For example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;Namespace::Class::NestedClassTemplate&amp;lt;T&amp;gt;::XX
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This would be stored as a linked list:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[id: XX] -&amp;gt; [type: NestedClassTemplate&amp;lt;T&amp;gt;] -&amp;gt; [type: Class] -&amp;gt; [namespace: Namespace]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Internally, that meant &lt;strong&gt;seven allocations&lt;/strong&gt; totaling around &lt;strong&gt;160 bytes&lt;/strong&gt;:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code&gt;NestedNameSpecifier&lt;/code&gt; (identifier) – 16 bytes&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;NestedNameSpecifier&lt;/code&gt; (type) – 16 bytes&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;TemplateSpecializationType&lt;/code&gt; – 48 bytes&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;QualifiedTemplateName&lt;/code&gt; – 16 bytes&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;NestedNameSpecifier&lt;/code&gt; (type) – 16 bytes&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;RecordType&lt;/code&gt; – 32 bytes&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;NestedNameSpecifier&lt;/code&gt; (namespace) – 16 bytes&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The real problem wasn’t just size — it was the &lt;em&gt;uniquing cost&lt;/em&gt;. Every prospective node has to be looked up in a hash table for a pre-existing instance.&lt;/p&gt;

&lt;p&gt;To make matters worse, &lt;code&gt;ElaboratedType&lt;/code&gt; nodes sometimes leaked into these chains, which wasn’t supposed to happen and led to &lt;a href=&quot;https://github.com/llvm/llvm-project/issues/43179&quot;&gt;several&lt;/a&gt; &lt;a href=&quot;https://github.com/llvm/llvm-project/issues/68670&quot;&gt;long-standing&lt;/a&gt; &lt;a href=&quot;https://github.com/llvm/llvm-project/issues/92757&quot;&gt;bugs&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;a-new-smarter-nestednamespecifier&quot;&gt;A new, smarter &lt;code&gt;NestedNameSpecifier&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;After this patch, &lt;code&gt;NestedNameSpecifier&lt;/code&gt; becomes a &lt;strong&gt;compact, tagged pointer&lt;/strong&gt; — just one machine word wide.&lt;/p&gt;

&lt;p&gt;The pointer uses 8-byte alignment, leaving three spare bits. Two bits are used for kind discrimination, and one remains available for arbitrary use.&lt;/p&gt;

&lt;p&gt;When non-null, the tag bits encode:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;A type&lt;/li&gt;
  &lt;li&gt;A declaration (either a &lt;code&gt;__super&lt;/code&gt; class or a namespace)&lt;/li&gt;
  &lt;li&gt;A namespace prefixed by the global scope (&lt;code&gt;::Namespace&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;A special object combining a namespace with its prefix&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;When null, the tag bits instead encode:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;An empty nested name (the terminator)&lt;/li&gt;
  &lt;li&gt;The global name&lt;/li&gt;
  &lt;li&gt;An invalid/tombstone entry (for hash tables)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Other changes include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The “unknown identifier” case is now represented by a &lt;code&gt;DependentNameType&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Type prefixes are handled directly in the type hierarchy.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Revisiting the earlier example, after the patch its AST dump becomes:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;DependentNameType 'Namespace::Class::NestedClassTemplate&amp;lt;T&amp;gt;::XX' dependent
`-NestedNameSpecifier TemplateSpecializationType 'Namespace::Class::NestedClassTemplate&amp;lt;T&amp;gt;' dependent
  `-name: 'Namespace::Class::NestedClassTemplate' qualified
    |-NestedNameSpecifier RecordType 'Namespace::Class'
    | |-NestedNameSpecifier Namespace 'Namespace'
    | `-CXXRecord 'Class'
    `-ClassTemplate NestedClassTemplate
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This representation now requires only &lt;strong&gt;four allocations (156 bytes total):&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code&gt;DependentNameType&lt;/code&gt; – 48 bytes&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;TemplateSpecializationType&lt;/code&gt; – 48 bytes&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;QualifiedTemplateName&lt;/code&gt; – 16 bytes&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;RecordType&lt;/code&gt; – 40 bytes&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;That’s almost half the number of nodes.&lt;/p&gt;

&lt;p&gt;While &lt;code&gt;DependentNameType&lt;/code&gt; is larger than the previous 16-byte “identifier” node, the additional space isn’t wasted — it holds cached answers to common queries such as “does this type reference a template parameter?” or “what is its canonical form?”.&lt;/p&gt;

&lt;p&gt;These caches make those operations significantly cheaper, further improving performance.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;wrapping-up&quot;&gt;Wrapping up&lt;/h2&gt;

&lt;p&gt;There’s more in the patch than what I’ve covered here, including:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;RecordType&lt;/code&gt; now points directly to the declaration found at creation, enriching the AST without measurable overhead.&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;RecordType&lt;/code&gt; nodes are now created lazily.&lt;/li&gt;
  &lt;li&gt;The redesigned &lt;code&gt;NestedNameSpecifier&lt;/code&gt; simplified several template instantiation transforms.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Each of these could warrant its own write-up, but even this high-level overview shows how careful structural changes in the AST can lead to tangible compile-time wins.&lt;/p&gt;

&lt;p&gt;I hope you found this deep dive into Clang’s internals interesting — and that it gives a glimpse of the kind of small, structural optimizations that add up to real performance improvements in large C++ builds.&lt;/p&gt;</content><author><name></name></author><category term="mizvekov," /><category term="clang" /><summary type="html">Modern C++ codebases — from browsers to GPU frameworks — rely heavily on templates, and that often means massive abstract syntax trees. Even small inefficiencies in Clang’s AST representation can add up to noticeable compile-time overhead. This post walks through a set of structural improvements I recently made to Clang’s AST that make type representation smaller, simpler, and faster to create — leading to measurable build-time gains in real-world projects. A couple of months ago, I landed a large patch in Clang that brought substantial compile-time improvements for heavily templated C++ code. For example, in stdexec — the reference implementation of the std::execution feature slated for C++26 — the slowest test (test_on2.cpp) saw a 7% reduction in build time. Also the Chromium build showed a 5% improvement (source). At a high level, the patch makes the Clang AST leaner: it reduces the memory footprint of type representations and lowers the cost of creating and uniquing them. These improvements will ship with Clang 22, expected in the next few months. How elaboration and qualified names used to work Consider this simple snippet: namespace NS { struct A {}; } using T = struct NS::A; The type of T (struct NS::A) carries two pieces of information: It’s elaborated — the struct keyword appears. It’s qualified — NS:: acts as a nested-name-specifier. Here’s how the AST dump looked before this patch: ElaboratedType 'struct NS::A' sugar `-RecordType 'test::NS::A' `-CXXRecord 'A' The RecordType represents a direct reference to the previously declared struct A — a kind of canonical view of the type, stripped of syntactic details like struct or namespace qualifiers. Those syntactic details were stored separately in an ElaboratedType node that wrapped the RecordType. Interestingly, an ElaboratedType node existed even when no elaboration or qualification appeared in the source (example). This was needed to distinguish between an explicitly unqualified type and one that lost its qualifiers through template substitution. However, this design was expensive: every ElaboratedType node consumed 48 bytes, and creating one required extra work to uniquify it — an important step for Clang’s fast type comparisons. A more compact representation The new approach removes ElaboratedType entirely. Instead, elaboration and qualifiers are now stored directly inside RecordType. The new AST dump for the same example looks like this: RecordType 'struct NS::A' struct |-NestedNameSpecifier Namespace 'NS' `-CXXRecord 'A' The struct elaboration now fits into previously unused bits within RecordType, while the qualifier is tail-allocated when present — making the node variably sized. This change both shrinks the memory footprint and eliminates one level of indirection when traversing the AST. Representing NestedNameSpecifier NestedNameSpecifier is Clang’s internal representation for name qualifiers. Before this patch, it was represented by a pointer (NestedNameSpecifier*) to a uniqued structure that could describe: The global namespace (::) A named namespace (including aliases) A type An identifier naming an unknown entity A __super reference (Microsoft extension) For all but cases (1) and (5), each NestedNameSpecifier also held a prefix — the qualifier to its left. For example: Namespace::Class::NestedClassTemplate&amp;lt;T&amp;gt;::XX This would be stored as a linked list: [id: XX] -&amp;gt; [type: NestedClassTemplate&amp;lt;T&amp;gt;] -&amp;gt; [type: Class] -&amp;gt; [namespace: Namespace] Internally, that meant seven allocations totaling around 160 bytes: NestedNameSpecifier (identifier) – 16 bytes NestedNameSpecifier (type) – 16 bytes TemplateSpecializationType – 48 bytes QualifiedTemplateName – 16 bytes NestedNameSpecifier (type) – 16 bytes RecordType – 32 bytes NestedNameSpecifier (namespace) – 16 bytes The real problem wasn’t just size — it was the uniquing cost. Every prospective node has to be looked up in a hash table for a pre-existing instance. To make matters worse, ElaboratedType nodes sometimes leaked into these chains, which wasn’t supposed to happen and led to several long-standing bugs. A new, smarter NestedNameSpecifier After this patch, NestedNameSpecifier becomes a compact, tagged pointer — just one machine word wide. The pointer uses 8-byte alignment, leaving three spare bits. Two bits are used for kind discrimination, and one remains available for arbitrary use. When non-null, the tag bits encode: A type A declaration (either a __super class or a namespace) A namespace prefixed by the global scope (::Namespace) A special object combining a namespace with its prefix When null, the tag bits instead encode: An empty nested name (the terminator) The global name An invalid/tombstone entry (for hash tables) Other changes include: The “unknown identifier” case is now represented by a DependentNameType. Type prefixes are handled directly in the type hierarchy. Revisiting the earlier example, after the patch its AST dump becomes: DependentNameType 'Namespace::Class::NestedClassTemplate&amp;lt;T&amp;gt;::XX' dependent `-NestedNameSpecifier TemplateSpecializationType 'Namespace::Class::NestedClassTemplate&amp;lt;T&amp;gt;' dependent `-name: 'Namespace::Class::NestedClassTemplate' qualified |-NestedNameSpecifier RecordType 'Namespace::Class' | |-NestedNameSpecifier Namespace 'Namespace' | `-CXXRecord 'Class' `-ClassTemplate NestedClassTemplate This representation now requires only four allocations (156 bytes total): DependentNameType – 48 bytes TemplateSpecializationType – 48 bytes QualifiedTemplateName – 16 bytes RecordType – 40 bytes That’s almost half the number of nodes. While DependentNameType is larger than the previous 16-byte “identifier” node, the additional space isn’t wasted — it holds cached answers to common queries such as “does this type reference a template parameter?” or “what is its canonical form?”. These caches make those operations significantly cheaper, further improving performance. Wrapping up There’s more in the patch than what I’ve covered here, including: RecordType now points directly to the declaration found at creation, enriching the AST without measurable overhead. RecordType nodes are now created lazily. The redesigned NestedNameSpecifier simplified several template instantiation transforms. Each of these could warrant its own write-up, but even this high-level overview shows how careful structural changes in the AST can lead to tangible compile-time wins. I hope you found this deep dive into Clang’s internals interesting — and that it gives a glimpse of the kind of small, structural optimizations that add up to real performance improvements in large C++ builds.</summary></entry><entry><title type="html">Conan Packages for Boost</title><link href="http://cppalliance.org/dmitry/2025/10/16/dmitrys-q3-update.html" rel="alternate" type="text/html" title="Conan Packages for Boost" /><published>2025-10-16T00:00:00+00:00</published><updated>2025-10-16T00:00:00+00:00</updated><id>http://cppalliance.org/dmitry/2025/10/16/dmitrys-q3-update</id><content type="html" xml:base="http://cppalliance.org/dmitry/2025/10/16/dmitrys-q3-update.html">&lt;p&gt;Back in April my former colleague Christian Mazakas &lt;a href=&quot;https://lists.boost.org/archives/list/boost@lists.boost.org/message/SW4QNUPFHJPT46Y3OY2CFCR3F73QKLRW/&quot;&gt;has
announced&lt;/a&gt;
his work on &lt;a href=&quot;https://github.com/cmazakas/vcpkg-registry-test&quot;&gt;registry of nightly Boost packages for
vcpkg&lt;/a&gt;. That same month
&lt;a href=&quot;https://conan.io&quot;&gt;Conan&lt;/a&gt; developers have &lt;a href=&quot;https://blog.conan.io/2024/04/23/Introducing-local-recipes-index-remote.html&quot;&gt;introduced a new
feature&lt;/a&gt;
that significantly simplified providing of an alternative Conan package source.
These two events gave me an idea to create an index of nightly Boost packages
for Conan.&lt;/p&gt;

&lt;h2 id=&quot;conan-remotes&quot;&gt;Conan Remotes&lt;/h2&gt;

&lt;p&gt;Conan installs packages from a &lt;em&gt;remote&lt;/em&gt;, which is usually a web server. When
you request a package in a particular version range, the remote determines if
it has a version that satisfies that range, and then sends you the package
recipe and, if possible, compatible binaries for the package.&lt;/p&gt;

&lt;p&gt;Local-recipes-index is a new kind of Conan remote that is not actually a
remote server and is just a local directory hierarchy of this kind:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;recipes
├── pkg1
│   ├── all
│   │   ├── conandata.yml
│   │   ├── conanfile.py
│   │   └── test_package
│   │       └── ...
│   └── config.yml
└── pkg2
    ├── all
    │   ├── conandata.yml
    │   ├── conanfile.py
    │   └── test_package
    │       └── ...
    └── config.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The directory structure is based on the Conan Center’s &lt;a href=&quot;https://github.com/conan-io/conan-center-index&quot;&gt;underlying GitHub
project&lt;/a&gt;. In actuality only
the &lt;code&gt;config.yml&lt;/code&gt; and &lt;code&gt;conanfile.py&lt;/code&gt; files are necessary. The former tells Conan
where to find the package recipes for each version (and hence determines the
set of available versions), the latter is the package recipe. In theory there
could be many subdirectories for different versions, but in reality most if not
all packages simply push all version differences into data files like
&lt;code&gt;conandata.yml&lt;/code&gt; and select the corresponding data in the recipe script.&lt;/p&gt;

&lt;p&gt;My idea in a nutshell was to set up a scheduled CI job that each day would run
a script that takes Boost superproject’s latest commits from &lt;code&gt;develop&lt;/code&gt; and
&lt;code&gt;master&lt;/code&gt; branches and generates a local-recipes-index directory hierarchy. Then
to have recipes directories coming from different branches merged together, and
the result be merged with the results of the previous run. Thus, after a while
an index of Boost snapshots from each day would accumulate.&lt;/p&gt;

&lt;h2 id=&quot;modular-boost&quot;&gt;Modular Boost&lt;/h2&gt;

&lt;p&gt;The project would have been fairly simple if my goal was to &lt;em&gt;just&lt;/em&gt; provide
nightly packages for Boost. Simply take the recipe from the Conan Center
project and replace getting sources from a release archive with getting sources
from GitHub. But I also wanted to package every Boost library separately. This
is generally known as modular Boost packages (not to be confused with Boost C++
modules). There is an apparent demand for such packages, and in fact this is
exactly how vcpkg users consume Boost libraries.&lt;/p&gt;

&lt;p&gt;In addition to the direct results—the Conan packages for Boost
libraries—such project is a great test of the &lt;em&gt;modularity&lt;/em&gt; of Boost. Whether
each library properly spells out all of its dependencies, whether there’s
enough associated metadata that describes the library, whether the project’s
build files are usable without the superproject, and so on. Conan Center (the
default Conan remote) does not currently provide modular Boost packages, only
packages for monolithic Boost (although it provides options to disable building
of specific libraries). Due to that I decided to generate package recipes not
only for nightly builds, but for tagged releases too.&lt;/p&gt;

&lt;p&gt;Given that, the core element of the project is the script that creates the
index from a Boost superproject &lt;em&gt;Git ref&lt;/em&gt; (branch name or tag). Each library is
a git submodule of the superproject. Every superproject commit contains
references to specific commits in submodules’ projects. The script checks out
each such commit, determines the library’s dependencies and other properties
important for Conan, and outputs &lt;code&gt;config.yml&lt;/code&gt;, &lt;code&gt;conanfile.py&lt;/code&gt;, &lt;code&gt;conandata.yml&lt;/code&gt;,
and &lt;code&gt;test_package&lt;/code&gt; contents.&lt;/p&gt;

&lt;h2 id=&quot;versions&quot;&gt;Versions&lt;/h2&gt;

&lt;p&gt;As previously mentioned, &lt;code&gt;config.yml&lt;/code&gt; contains a list of supported versions.
After one runs the generator script that file will contain exactly one version.
You might ask, what exactly is that version? After some research I ended up
with the scheme &lt;code&gt;MAJOR.MINOR.0-a.B+YY.MM.DD.HH.mm&lt;/code&gt;, where:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;MAJOR.MINOR.0&lt;/code&gt; is the &lt;em&gt;next&lt;/em&gt; Boost release version;&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;a&lt;/code&gt; implies an alpha-version pre-release;&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;B&lt;/code&gt; is &lt;code&gt;m&lt;/code&gt; for the &lt;code&gt;master&lt;/code&gt; branch and &lt;code&gt;d&lt;/code&gt; for the &lt;code&gt;develop&lt;/code&gt; branch;&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;YY.MM.DD.HH.mm&lt;/code&gt; is the authorship date and time of the source commit.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For example, a commit authored at 12:15 on 15th of August 2025 taken from the
&lt;code&gt;master&lt;/code&gt; branch before Boost 1.90.0 was released would be represented by the
version &lt;code&gt;1.90.0-a.m+25.08.15.12.15&lt;/code&gt;. The scheme is an example of &lt;a href=&quot;https://semver.org&quot;&gt;semantic
versioning&lt;/a&gt;. The part between the hyphen and the plus
specifies a pre-release, and the part following the plus identifies a specific
build. All parts of the version contribute to the versions order after sorting.
Importantly, pre-releases are ordered &lt;em&gt;before&lt;/em&gt; the release they predate, which
makes sense, but isn’t obvious from the first glance.&lt;/p&gt;

&lt;p&gt;I originally did not plan to put commit time into the version scheme, as the
scheduled CI job only runs once a day. But while working on the project, I also
had the package index updated on pushes into the &lt;code&gt;master&lt;/code&gt; branch, which
overwrote previously indexed versions, and that was never the intention. Also,
originally the pre-release part was just the name of the branch, which was good
enough to sort &lt;code&gt;master&lt;/code&gt; and &lt;code&gt;develop&lt;/code&gt;. But with the scope of the project
including actual Boost releases and betas, I needed beta versions to sort
after &lt;code&gt;master&lt;/code&gt; and &lt;code&gt;develop&lt;/code&gt; versions, but before releases, hence I made them
alpha versions explicitly.&lt;/p&gt;

&lt;p&gt;One may ask, why do I even care about betas? By having specific beta versions
I want to encourage more people to check out Boost libraries in beta state and
find the bugs early on. I hope that if obtaining a beta version is as easy as
simply changing one string in a configuration file, more people will check them
and that would reduce the amount of bugs shipped in Boost libraries.&lt;/p&gt;

&lt;h2 id=&quot;conan-generators&quot;&gt;Conan Generators&lt;/h2&gt;

&lt;p&gt;One of the most important Conan features in my opinion is its support for any
build system rather than for a limited selection of them. This is done via
&lt;em&gt;generators&lt;/em&gt;—utilities that Convert platform description and dependency data
into configuration files for build systems. In Conan 2.x the regular approach
is to have a set of 2 generators for a given build system.&lt;/p&gt;

&lt;p&gt;The main one is a dependencies generator, which creates files that tell the
build system how to find dependencies. For example, if you are familiar with
CMake, the &lt;code&gt;CMakeDependencies&lt;/code&gt; generator creates &lt;a href=&quot;https://cmake.org/cmake/help/latest/manual/cmake-packages.7.html#package-configuration-file&quot;&gt;config
modules&lt;/a&gt;
for every dependency.&lt;/p&gt;

&lt;p&gt;The other one is a toolchain generator. Those convert platform information into
build system configuration files which determine the compiler, computer
architecture, OS, and so on. Using CMake as an example again, the
&lt;code&gt;CMakeToolchain&lt;/code&gt; generator creates a &lt;a href=&quot;https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html&quot;&gt;toolchain
file&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The reason for the split into 2 generators is that there are cases when you
use only one of them. For example, if you don’t have any dependencies, you
don’t need a dependencies generator. And when you are working on a project,
you might already have the necessary build system configuration files, so you
don’t need a toolchain generator.&lt;/p&gt;

&lt;p&gt;For my project I needed both for Boost’s main build system,
&lt;a href=&quot;https://www.bfgroup.xyz/b2&quot;&gt;b2&lt;/a&gt;. Boost can also be built with CMake, but
that’s still not officially supported, and is tested less rigorously.
Unfortunately, Conan 2.x doesn’t currently have in-built support for b2. It had
it in Conan 1.x, but with the major version increase they’ve removed most of
the old generators, and the PR to add it back did not go anywhere. So, I had to
implement those 2 generators for b2. Luckily, Conan supports putting such Conan
extensions into packages. So, now the package index generation script also
creates a package with b2 generators.&lt;/p&gt;

&lt;h2 id=&quot;the-current-state-and-lessons-learned&quot;&gt;The Current State and Lessons Learned&lt;/h2&gt;

&lt;p&gt;The work is still in its early stage, but the project is in a somewhat usable
state already. It is currently located
&lt;a href=&quot;https://github.com/grisumbras/boost-conan-index&quot;&gt;here&lt;/a&gt; (I plan to place it
under boostorg GitHub organisation with the Boost community’s approval, or,
failing that, under cppalliance organisation). You can clone the project and
install and use some of the Boost libraries, but not all. I have tested that
those libraries build and work on Windows, Linux, and macOS. The b2 generators
are almost feature complete at this point.&lt;/p&gt;

&lt;p&gt;My future work will be mostly dedicated to discovering special requirements of
the remaining libraries and working out ways to handle them. The most
interesting problems are handling projects with special “options” (e.g.
Boost.Context usually has to be told what the target platform ABI and binary
format are), and handling the few external dependencies (e.g. zlib and ICU).
Another interesting task is handling library projects with several binaries
(e.g. Boost.Log) and dealing with the fact that libraries can change from being
compiled to being header-only (yes, this does happen).&lt;/p&gt;

&lt;p&gt;There were also several interesting findings. At first I tried determining
dependencies from the build scripts. But that turned out to be too brittle, so
in the end I decided to use
&lt;a href=&quot;https://github.com/boostorg/boostdep/blob/master/depinst/depinst.py&quot;&gt;&lt;code&gt;depinst&lt;/code&gt;&lt;/a&gt;,
the tool Boost projects use in CI to install dependencies. This is still a bit
too simplistic, as libraries can have optional and platform dependencies. But
I will have to address this later.&lt;/p&gt;

&lt;p&gt;Switching to &lt;code&gt;depinst&lt;/code&gt; uncovered that in Boost 1.89.0 a circular dependency
appeared between Boost.Geometry and Boost.Graph. This is actually a big problem
for package managers, as they have to build all dependencies for a project
before building it, and before that do the same thing for each of the
dependencies, and this creates a paradoxical situation where you need to build
the project before you build that same project. To make such circular
dependencies more apparent in the future, I’ve added a flag to &lt;code&gt;depinst&lt;/code&gt; that
makes it exit with an error if a cycle is discovered.&lt;/p&gt;

&lt;p&gt;Overall, I think Boost modularisation is going fairly well. Every library I’ve
tried yet builds correctly without the superproject present. I hope to finish
the project soon, preferably before the 1.90.0 release.&lt;/p&gt;

&lt;p&gt;After that there’s still an interesting possible addition. Christian’s vcpkg
registry mentioned in the very beginning also had a package for a candidate
library, so that people could easily install it and try it out during the
review period. My package index could in the future also do that. Hopefully
that will motivate more people to participate in Boost reviews.&lt;/p&gt;</content><author><name></name></author><category term="dmitry" /><summary type="html">Back in April my former colleague Christian Mazakas has announced his work on registry of nightly Boost packages for vcpkg. That same month Conan developers have introduced a new feature that significantly simplified providing of an alternative Conan package source. These two events gave me an idea to create an index of nightly Boost packages for Conan. Conan Remotes Conan installs packages from a remote, which is usually a web server. When you request a package in a particular version range, the remote determines if it has a version that satisfies that range, and then sends you the package recipe and, if possible, compatible binaries for the package. Local-recipes-index is a new kind of Conan remote that is not actually a remote server and is just a local directory hierarchy of this kind: recipes ├── pkg1 │ ├── all │ │ ├── conandata.yml │ │ ├── conanfile.py │ │ └── test_package │ │ └── ... │ └── config.yml └── pkg2 ├── all │ ├── conandata.yml │ ├── conanfile.py │ └── test_package │ └── ... └── config.yml The directory structure is based on the Conan Center’s underlying GitHub project. In actuality only the config.yml and conanfile.py files are necessary. The former tells Conan where to find the package recipes for each version (and hence determines the set of available versions), the latter is the package recipe. In theory there could be many subdirectories for different versions, but in reality most if not all packages simply push all version differences into data files like conandata.yml and select the corresponding data in the recipe script. My idea in a nutshell was to set up a scheduled CI job that each day would run a script that takes Boost superproject’s latest commits from develop and master branches and generates a local-recipes-index directory hierarchy. Then to have recipes directories coming from different branches merged together, and the result be merged with the results of the previous run. Thus, after a while an index of Boost snapshots from each day would accumulate. Modular Boost The project would have been fairly simple if my goal was to just provide nightly packages for Boost. Simply take the recipe from the Conan Center project and replace getting sources from a release archive with getting sources from GitHub. But I also wanted to package every Boost library separately. This is generally known as modular Boost packages (not to be confused with Boost C++ modules). There is an apparent demand for such packages, and in fact this is exactly how vcpkg users consume Boost libraries. In addition to the direct results—the Conan packages for Boost libraries—such project is a great test of the modularity of Boost. Whether each library properly spells out all of its dependencies, whether there’s enough associated metadata that describes the library, whether the project’s build files are usable without the superproject, and so on. Conan Center (the default Conan remote) does not currently provide modular Boost packages, only packages for monolithic Boost (although it provides options to disable building of specific libraries). Due to that I decided to generate package recipes not only for nightly builds, but for tagged releases too. Given that, the core element of the project is the script that creates the index from a Boost superproject Git ref (branch name or tag). Each library is a git submodule of the superproject. Every superproject commit contains references to specific commits in submodules’ projects. The script checks out each such commit, determines the library’s dependencies and other properties important for Conan, and outputs config.yml, conanfile.py, conandata.yml, and test_package contents. Versions As previously mentioned, config.yml contains a list of supported versions. After one runs the generator script that file will contain exactly one version. You might ask, what exactly is that version? After some research I ended up with the scheme MAJOR.MINOR.0-a.B+YY.MM.DD.HH.mm, where: MAJOR.MINOR.0 is the next Boost release version; a implies an alpha-version pre-release; B is m for the master branch and d for the develop branch; YY.MM.DD.HH.mm is the authorship date and time of the source commit. For example, a commit authored at 12:15 on 15th of August 2025 taken from the master branch before Boost 1.90.0 was released would be represented by the version 1.90.0-a.m+25.08.15.12.15. The scheme is an example of semantic versioning. The part between the hyphen and the plus specifies a pre-release, and the part following the plus identifies a specific build. All parts of the version contribute to the versions order after sorting. Importantly, pre-releases are ordered before the release they predate, which makes sense, but isn’t obvious from the first glance. I originally did not plan to put commit time into the version scheme, as the scheduled CI job only runs once a day. But while working on the project, I also had the package index updated on pushes into the master branch, which overwrote previously indexed versions, and that was never the intention. Also, originally the pre-release part was just the name of the branch, which was good enough to sort master and develop. But with the scope of the project including actual Boost releases and betas, I needed beta versions to sort after master and develop versions, but before releases, hence I made them alpha versions explicitly. One may ask, why do I even care about betas? By having specific beta versions I want to encourage more people to check out Boost libraries in beta state and find the bugs early on. I hope that if obtaining a beta version is as easy as simply changing one string in a configuration file, more people will check them and that would reduce the amount of bugs shipped in Boost libraries. Conan Generators One of the most important Conan features in my opinion is its support for any build system rather than for a limited selection of them. This is done via generators—utilities that Convert platform description and dependency data into configuration files for build systems. In Conan 2.x the regular approach is to have a set of 2 generators for a given build system. The main one is a dependencies generator, which creates files that tell the build system how to find dependencies. For example, if you are familiar with CMake, the CMakeDependencies generator creates config modules for every dependency. The other one is a toolchain generator. Those convert platform information into build system configuration files which determine the compiler, computer architecture, OS, and so on. Using CMake as an example again, the CMakeToolchain generator creates a toolchain file. The reason for the split into 2 generators is that there are cases when you use only one of them. For example, if you don’t have any dependencies, you don’t need a dependencies generator. And when you are working on a project, you might already have the necessary build system configuration files, so you don’t need a toolchain generator. For my project I needed both for Boost’s main build system, b2. Boost can also be built with CMake, but that’s still not officially supported, and is tested less rigorously. Unfortunately, Conan 2.x doesn’t currently have in-built support for b2. It had it in Conan 1.x, but with the major version increase they’ve removed most of the old generators, and the PR to add it back did not go anywhere. So, I had to implement those 2 generators for b2. Luckily, Conan supports putting such Conan extensions into packages. So, now the package index generation script also creates a package with b2 generators. The Current State and Lessons Learned The work is still in its early stage, but the project is in a somewhat usable state already. It is currently located here (I plan to place it under boostorg GitHub organisation with the Boost community’s approval, or, failing that, under cppalliance organisation). You can clone the project and install and use some of the Boost libraries, but not all. I have tested that those libraries build and work on Windows, Linux, and macOS. The b2 generators are almost feature complete at this point. My future work will be mostly dedicated to discovering special requirements of the remaining libraries and working out ways to handle them. The most interesting problems are handling projects with special “options” (e.g. Boost.Context usually has to be told what the target platform ABI and binary format are), and handling the few external dependencies (e.g. zlib and ICU). Another interesting task is handling library projects with several binaries (e.g. Boost.Log) and dealing with the fact that libraries can change from being compiled to being header-only (yes, this does happen). There were also several interesting findings. At first I tried determining dependencies from the build scripts. But that turned out to be too brittle, so in the end I decided to use depinst, the tool Boost projects use in CI to install dependencies. This is still a bit too simplistic, as libraries can have optional and platform dependencies. But I will have to address this later. Switching to depinst uncovered that in Boost 1.89.0 a circular dependency appeared between Boost.Geometry and Boost.Graph. This is actually a big problem for package managers, as they have to build all dependencies for a project before building it, and before that do the same thing for each of the dependencies, and this creates a paradoxical situation where you need to build the project before you build that same project. To make such circular dependencies more apparent in the future, I’ve added a flag to depinst that makes it exit with an error if a cycle is discovered. Overall, I think Boost modularisation is going fairly well. Every library I’ve tried yet builds correctly without the superproject present. I hope to finish the project soon, preferably before the 1.90.0 release. After that there’s still an interesting possible addition. Christian’s vcpkg registry mentioned in the very beginning also had a package for a candidate library, so that people could easily install it and try it out during the review period. My package index could in the future also do that. Hopefully that will motivate more people to participate in Boost reviews.</summary></entry><entry><title type="html">Writing Docs with Visuals and Verve</title><link href="http://cppalliance.org/peter/2025/10/15/Peter-Turcan-Q3-2025.html" rel="alternate" type="text/html" title="Writing Docs with Visuals and Verve" /><published>2025-10-15T00:00:00+00:00</published><updated>2025-10-15T00:00:00+00:00</updated><id>http://cppalliance.org/peter/2025/10/15/Peter-Turcan-Q3-2025</id><content type="html" xml:base="http://cppalliance.org/peter/2025/10/15/Peter-Turcan-Q3-2025.html">&lt;p&gt;In a past life I worked in the computer journalism business, and learnt over time what attracts people to read a page. Lot’s of things are important, the font used, the spacing between letters and lines and paragraphs, even the width of a column of text is super-important for readability (so the eye does not lose track of the line it is on). Other stuff is important to, readers, especially technical readers, love tables. A table of all the networking libraries available in Boost for example, becomes a reassuring point of reference, as opposed to a bunch of text listing the libraries. Two of the most important factors in drawing readers in are headlines and images. It can take some grey matter and experience and skill to come up with a catchy headline (“Phew - what a scorcher” - is a famous example of a tabloid headline after a super hot day!). The more I worked in journalism the more I appreciated all the skills involved - and those I had and those I had not!
When it comes to images, I decided to add at least one image to all the Scenarios in the Boost User Guide (Finance, Networking, Simulation, among others). One of the skills I do not have is that of an artist - so these images mostly had to come from elsewhere. Not all though, for the deformation example in the Simulation scenario, I came up with the following image - which works I guess!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/peterturcan/deformation.png&quot; alt=&quot;Cube deformation&quot; /&gt;&lt;/p&gt;

&lt;p&gt;For other images I used AI to come up with some text based diagrams, which do work well as “images” for a technical readership. For example, the following simple flow for a Message Queue shows what is going on, Receiver 3 picking up all the inappropriately addressed messages, as well as its own.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/peterturcan/message-queue.png&quot; alt=&quot;Message queue&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Other images required some research. I must admit I did not know the difference between a &lt;em&gt;petal&lt;/em&gt; and a &lt;em&gt;sepal&lt;/em&gt; until I did some research on the iris data used in the Machine Learning scenario. The following image is a composite of a picture taken by my wife of an iris in a New Mexico volcanic caldera, and a diagram generated by AI. Now I know, the sepals are the dangly bits I would have called petals before engaging in this research.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/peterturcan/iris-photo.png&quot; alt=&quot;Iris components&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Hopefully these images will draw in readers and entice them to try out the scenarios, and then continue their programming journey with the support of Boost libraries.&lt;/p&gt;

&lt;p&gt;Another topic I dug into this quarter is to find examples of good and bad practices, and then to tabularize them (remember, tables are trusted references…). I started with error messages. Here is an example of a tedious error message:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;error C2679: binary '=': no operator found which takes a right-hand operand of type 'boost::gregorian::date' (or there is no acceptable conversion)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Why is it tedious? Because it is verbose and yet still doesn’t say what the user did wrong, not even the library name is in the message. A shorter, sharper and more helpful message would be:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;boost::date_time::invalid_date: &quot;2025-02-30&quot; is not a valid Gregorian date&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This message contains the library name (date_time), and the invalid input. Error message content should be a high-priority issue for API developers.&lt;/p&gt;

&lt;p&gt;Another topic added to Best Practices is simply API design itself. The Boost filesystem library contains some good examples of clear design, for example - here is a section from the Contributor Guide:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/peterturcan/clear-overloads.png&quot; alt=&quot;Clear Overloads&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Of course there is an element of style, taste, personal preferences in all these issues. It is totally OK for APIs to reflect those traits of the developers, this guide is there as a check point - a resource to read over and reflect on when evaluating your own work.&lt;/p&gt;

&lt;p&gt;Talking of AI - and who isn’t? - I requested the Cpp Alliance give me an image-creating AI API account, so I could add a section to the AI Client scenario on creating images. It is a lot of fun asking an AI to create an image, though you would be correct in thinking you probably could have come up with better yourself! For example, check out this exchange:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Enter your request (ASCII diagram or text) or 'exit': Can you draw an ASCII diagram of a speedboat?&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Assistant Response:
Sure! Here's a simple ASCII representation of a speedboat:&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;        __/__
  _____/_____|_____
  \              /
~~~~~~~~~~~~~~~~~~~~~
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;On a tad more serious note, I added topics on Reflection and Diagnostics to the User Guide. And I scan the Slack conversations for words or phrases that are new to me, and add them to the User Guide Glossary - which is a fun document on its own account. Even a document as potentially dull as a glossary can be fun to create and fun to read. Everybody likes to be entertained when they are reading, it takes the grind out of the experience.&lt;/p&gt;</content><author><name></name></author><category term="peter" /><summary type="html">In a past life I worked in the computer journalism business, and learnt over time what attracts people to read a page. Lot’s of things are important, the font used, the spacing between letters and lines and paragraphs, even the width of a column of text is super-important for readability (so the eye does not lose track of the line it is on). Other stuff is important to, readers, especially technical readers, love tables. A table of all the networking libraries available in Boost for example, becomes a reassuring point of reference, as opposed to a bunch of text listing the libraries. Two of the most important factors in drawing readers in are headlines and images. It can take some grey matter and experience and skill to come up with a catchy headline (“Phew - what a scorcher” - is a famous example of a tabloid headline after a super hot day!). The more I worked in journalism the more I appreciated all the skills involved - and those I had and those I had not! When it comes to images, I decided to add at least one image to all the Scenarios in the Boost User Guide (Finance, Networking, Simulation, among others). One of the skills I do not have is that of an artist - so these images mostly had to come from elsewhere. Not all though, for the deformation example in the Simulation scenario, I came up with the following image - which works I guess! For other images I used AI to come up with some text based diagrams, which do work well as “images” for a technical readership. For example, the following simple flow for a Message Queue shows what is going on, Receiver 3 picking up all the inappropriately addressed messages, as well as its own. Other images required some research. I must admit I did not know the difference between a petal and a sepal until I did some research on the iris data used in the Machine Learning scenario. The following image is a composite of a picture taken by my wife of an iris in a New Mexico volcanic caldera, and a diagram generated by AI. Now I know, the sepals are the dangly bits I would have called petals before engaging in this research. Hopefully these images will draw in readers and entice them to try out the scenarios, and then continue their programming journey with the support of Boost libraries. Another topic I dug into this quarter is to find examples of good and bad practices, and then to tabularize them (remember, tables are trusted references…). I started with error messages. Here is an example of a tedious error message: error C2679: binary '=': no operator found which takes a right-hand operand of type 'boost::gregorian::date' (or there is no acceptable conversion) Why is it tedious? Because it is verbose and yet still doesn’t say what the user did wrong, not even the library name is in the message. A shorter, sharper and more helpful message would be: boost::date_time::invalid_date: &quot;2025-02-30&quot; is not a valid Gregorian date This message contains the library name (date_time), and the invalid input. Error message content should be a high-priority issue for API developers. Another topic added to Best Practices is simply API design itself. The Boost filesystem library contains some good examples of clear design, for example - here is a section from the Contributor Guide: Of course there is an element of style, taste, personal preferences in all these issues. It is totally OK for APIs to reflect those traits of the developers, this guide is there as a check point - a resource to read over and reflect on when evaluating your own work. Talking of AI - and who isn’t? - I requested the Cpp Alliance give me an image-creating AI API account, so I could add a section to the AI Client scenario on creating images. It is a lot of fun asking an AI to create an image, though you would be correct in thinking you probably could have come up with better yourself! For example, check out this exchange: Enter your request (ASCII diagram or text) or 'exit': Can you draw an ASCII diagram of a speedboat? Assistant Response: Sure! Here's a simple ASCII representation of a speedboat: __/__ _____/_____|_____ \ / ~~~~~~~~~~~~~~~~~~~~~ On a tad more serious note, I added topics on Reflection and Diagnostics to the User Guide. And I scan the Slack conversations for words or phrases that are new to me, and add them to the User Guide Glossary - which is a fun document on its own account. Even a document as potentially dull as a glossary can be fun to create and fun to read. Everybody likes to be entertained when they are reading, it takes the grind out of the experience.</summary></entry><entry><title type="html">DynamicBitset Reimagined: A Quarter of Flexibility, Cleanup, and Modern C++</title><link href="http://cppalliance.org/gennaro/2025/10/14/Gennaros2025Q3Update.html" rel="alternate" type="text/html" title="DynamicBitset Reimagined: A Quarter of Flexibility, Cleanup, and Modern C++" /><published>2025-10-14T00:00:00+00:00</published><updated>2025-10-14T00:00:00+00:00</updated><id>http://cppalliance.org/gennaro/2025/10/14/Gennaros2025Q3Update</id><content type="html" xml:base="http://cppalliance.org/gennaro/2025/10/14/Gennaros2025Q3Update.html">&lt;p&gt;Over the past three months, I’ve been immersed in a deep and wide-ranging
overhaul of the Boost.DynamicBitset library. What started as a few targeted
improvements quickly evolved into a full-scale modernization effort—touching
everything from the underlying container to iterator concepts, from test
coverage to documentation style. More than 170 commits later, the library is
leaner, more flexible, and better aligned with modern C++ practices.&lt;/p&gt;

&lt;h2 id=&quot;making-the-core-more-flexible&quot;&gt;Making the core more flexible&lt;/h2&gt;

&lt;p&gt;The most transformative change this quarter was allowing users to choose the
underlying container type for &lt;code&gt;dynamic_bitset&lt;/code&gt;. Until now, the implementation
assumed &lt;code&gt;std::vector&lt;/code&gt;, which limited optimization opportunities and imposed
certain behaviors. By lifting that restriction, developers can now use
alternatives like &lt;code&gt;boost::container::small_vector&lt;/code&gt;, enabling small buffer
optimization and more control over memory layout.&lt;/p&gt;

&lt;p&gt;This change had ripple effects throughout the codebase. I had to revisit
assumptions about contiguous storage, update operators like &lt;code&gt;&amp;lt;&amp;lt;=&lt;/code&gt;, &lt;code&gt;&amp;gt;&amp;gt;=&lt;/code&gt;, and
ensure that reference stability and iterator behavior were correctly handled.&lt;/p&gt;

&lt;h2 id=&quot;introducing-c20-iterators&quot;&gt;Introducing C++20 iterators&lt;/h2&gt;

&lt;p&gt;One of the more exciting additions this quarter was support for C++20-style
iterators. These new iterators conform to the standard iterator concepts, making
&lt;code&gt;dynamic_bitset&lt;/code&gt; more interoperable with modern algorithms and range-based
utilities.&lt;/p&gt;

&lt;p&gt;I added assertions to ensure that both the underlying container and
&lt;code&gt;dynamic_bitset&lt;/code&gt; itself meet the requirements for bidirectional iteration. These
checks are enabled only when compiling with C++20 or later, and they help catch
subtle mismatches early—especially when users plug in custom containers.&lt;/p&gt;

&lt;h2 id=&quot;saying-goodbye-to-legacy-workarounds&quot;&gt;Saying goodbye to legacy workarounds&lt;/h2&gt;

&lt;p&gt;With modern compilers and standard libraries, many old workarounds are no longer
needed. I removed the &lt;code&gt;max_size_workaround()&lt;/code&gt; after confirming that major
implementations now correctly account for allocators in &lt;code&gt;max_size()&lt;/code&gt;. I also
dropped support for obsolete compilers like MSVC 6 and CodeWarrior 8.3, and for
pre-standard iostreams, cleaned up outdated macros, and removed compatibility
layers for pre-C++11 environments.&lt;/p&gt;

&lt;p&gt;These removals weren’t just cosmetic—they simplified the code and made it easier
to reason about. In many places, I replaced legacy constructs with standard
features like &lt;code&gt;noexcept&lt;/code&gt; and &lt;code&gt;std::move()&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;constexpr-support&quot;&gt;constexpr support&lt;/h2&gt;

&lt;p&gt;When it is compiled as C++20 or later, almost all functions in DynamicBitset are
now &lt;code&gt;constexpr&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;dropping-obsolete-dependencies&quot;&gt;Dropping obsolete dependencies&lt;/h2&gt;

&lt;p&gt;As part of the cleanup effort, I also removed several outdated dependencies that
were no longer justified. These included Boost.Integer (previously used by
&lt;code&gt;lowest_bit()&lt;/code&gt;), &lt;code&gt;core/allocator_access.hpp&lt;/code&gt;, and various compatibility headers
tied to pre-C++11 environments. This not only reduces compile-time overhead and
cognitive load, but also makes the library easier to audit and maintain.&lt;/p&gt;

&lt;h2 id=&quot;strengthening-the-test-suite&quot;&gt;Strengthening the test suite&lt;/h2&gt;

&lt;p&gt;A part of this quarter’s work was expanding and refining the test coverage. I
added new tests for &lt;code&gt;flip()&lt;/code&gt;, &lt;code&gt;resize()&lt;/code&gt;, &lt;code&gt;swap()&lt;/code&gt;, and &lt;code&gt;operator!=()&lt;/code&gt;. I also
ensured that input iterators are properly supported in &lt;code&gt;append()&lt;/code&gt;, and verified
that &lt;code&gt;std::hash&lt;/code&gt; behaves correctly even when two bitsets share the same
underlying container but differ in size.&lt;/p&gt;

&lt;p&gt;Along the way, I cleaned up misleading comments, shortened overly complex
conditions, and removed legacy test code that no longer reflected the current
behavior of the library. The result is a test suite that’s more robust, more
meaningful, and easier to maintain.&lt;/p&gt;

&lt;h2 id=&quot;documentation-that-speaks-clearly&quot;&gt;Documentation that speaks clearly&lt;/h2&gt;

&lt;p&gt;I’ve always believed that documentation should be treated as part of the design,
not an afterthought. This quarter, I ported the existing documentation to MrDocs
and Antora, while fixing and improving a few bits in the process. This uncovered
a few MrDocs bugs, some of which remain—but I’m hopeful.&lt;/p&gt;

&lt;p&gt;I also spent time harmonizing the style and structure of the library’s comments
and docstrings.&lt;/p&gt;

&lt;p&gt;I chose to document iterator categories rather than exposing concrete types,
which keeps the interface clean and focused on behavior rather than
implementation details.&lt;/p&gt;

&lt;h2 id=&quot;new-member-functions-and-smarter-implementations&quot;&gt;New member functions and smarter implementations&lt;/h2&gt;

&lt;p&gt;This quarter also introduced several new member functions that expand the
expressiveness and utility of &lt;code&gt;dynamic_bitset&lt;/code&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;push_front()&lt;/code&gt; and &lt;code&gt;pop_front()&lt;/code&gt; allow bit-level manipulation at the front of
the bitset, complementing the existing back-oriented operations.&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;find_first_off()&lt;/code&gt; and &lt;code&gt;find_next_off()&lt;/code&gt; provide symmetric functionality to
their &lt;code&gt;find_first()&lt;/code&gt; counterparts, making it easier to locate unset bits.&lt;/li&gt;
  &lt;li&gt;A constructor from &lt;code&gt;basic_string_view&lt;/code&gt; was added for C++17 and later,
improving interoperability with modern string APIs.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Alongside these additions, I revisited the implementation of several existing
members to improve performance and clarity:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;push_back()&lt;/code&gt; and &lt;code&gt;pop_back()&lt;/code&gt; were streamlined for better efficiency.&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;all()&lt;/code&gt; and &lt;code&gt;lowest_bit()&lt;/code&gt; were simplified and optimized, with the latter also
shedding its dependency on Boost.Integer.&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;append()&lt;/code&gt; was fixed to properly support input iterators and avoid redundant
checks.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;minor-but-impactful-cleanups&quot;&gt;Minor but impactful cleanups&lt;/h2&gt;

&lt;p&gt;A large number of small edits improved correctness, readability, and
maintainability:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Fixed the stream inserter to set &lt;code&gt;badbit&lt;/code&gt; if an exception is thrown during
output.&lt;/li&gt;
  &lt;li&gt;Changed the stream extractor to rethrow any exceptions coming from the
underlying container.&lt;/li&gt;
  &lt;li&gt;Reordered and cleaned up all #include sections to use the “” form for Boost
includes where appropriate and to keep include groups sorted.&lt;/li&gt;
  &lt;li&gt;Removed an example timing benchmark that was misleading and a number of
unneeded comments and minor typos across code and docs.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These edits reduce noise and make code reviews and maintenance more pleasant.&lt;/p&gt;

&lt;h2 id=&quot;reflections&quot;&gt;Reflections&lt;/h2&gt;

&lt;p&gt;Looking back, this quarter reminded me of the value of revisiting assumptions.
Many of the workarounds and constraints that once made sense are now obsolete.
By embracing modern C++ features and simplifying where possible, we can make
libraries like &lt;code&gt;dynamic_bitset&lt;/code&gt; more powerful and more approachable.&lt;/p&gt;

&lt;p&gt;It also reinforced the importance of clarity—both in code and in documentation.
Whether it’s a test case, a comment, or a public API, precision and consistency
go a long way.&lt;/p&gt;

&lt;p&gt;The work continues, but the foundation is stronger than ever. If you’re using
&lt;code&gt;dynamic_bitset&lt;/code&gt; or thinking about integrating it into your project, I’d love to
hear your feedback.&lt;/p&gt;</content><author><name></name></author><category term="gennaro" /><summary type="html">Over the past three months, I’ve been immersed in a deep and wide-ranging overhaul of the Boost.DynamicBitset library. What started as a few targeted improvements quickly evolved into a full-scale modernization effort—touching everything from the underlying container to iterator concepts, from test coverage to documentation style. More than 170 commits later, the library is leaner, more flexible, and better aligned with modern C++ practices. Making the core more flexible The most transformative change this quarter was allowing users to choose the underlying container type for dynamic_bitset. Until now, the implementation assumed std::vector, which limited optimization opportunities and imposed certain behaviors. By lifting that restriction, developers can now use alternatives like boost::container::small_vector, enabling small buffer optimization and more control over memory layout. This change had ripple effects throughout the codebase. I had to revisit assumptions about contiguous storage, update operators like &amp;lt;&amp;lt;=, &amp;gt;&amp;gt;=, and ensure that reference stability and iterator behavior were correctly handled. Introducing C++20 iterators One of the more exciting additions this quarter was support for C++20-style iterators. These new iterators conform to the standard iterator concepts, making dynamic_bitset more interoperable with modern algorithms and range-based utilities. I added assertions to ensure that both the underlying container and dynamic_bitset itself meet the requirements for bidirectional iteration. These checks are enabled only when compiling with C++20 or later, and they help catch subtle mismatches early—especially when users plug in custom containers. Saying goodbye to legacy workarounds With modern compilers and standard libraries, many old workarounds are no longer needed. I removed the max_size_workaround() after confirming that major implementations now correctly account for allocators in max_size(). I also dropped support for obsolete compilers like MSVC 6 and CodeWarrior 8.3, and for pre-standard iostreams, cleaned up outdated macros, and removed compatibility layers for pre-C++11 environments. These removals weren’t just cosmetic—they simplified the code and made it easier to reason about. In many places, I replaced legacy constructs with standard features like noexcept and std::move(). constexpr support When it is compiled as C++20 or later, almost all functions in DynamicBitset are now constexpr. Dropping obsolete dependencies As part of the cleanup effort, I also removed several outdated dependencies that were no longer justified. These included Boost.Integer (previously used by lowest_bit()), core/allocator_access.hpp, and various compatibility headers tied to pre-C++11 environments. This not only reduces compile-time overhead and cognitive load, but also makes the library easier to audit and maintain. Strengthening the test suite A part of this quarter’s work was expanding and refining the test coverage. I added new tests for flip(), resize(), swap(), and operator!=(). I also ensured that input iterators are properly supported in append(), and verified that std::hash behaves correctly even when two bitsets share the same underlying container but differ in size. Along the way, I cleaned up misleading comments, shortened overly complex conditions, and removed legacy test code that no longer reflected the current behavior of the library. The result is a test suite that’s more robust, more meaningful, and easier to maintain. Documentation that speaks clearly I’ve always believed that documentation should be treated as part of the design, not an afterthought. This quarter, I ported the existing documentation to MrDocs and Antora, while fixing and improving a few bits in the process. This uncovered a few MrDocs bugs, some of which remain—but I’m hopeful. I also spent time harmonizing the style and structure of the library’s comments and docstrings. I chose to document iterator categories rather than exposing concrete types, which keeps the interface clean and focused on behavior rather than implementation details. New member functions and smarter implementations This quarter also introduced several new member functions that expand the expressiveness and utility of dynamic_bitset: push_front() and pop_front() allow bit-level manipulation at the front of the bitset, complementing the existing back-oriented operations. find_first_off() and find_next_off() provide symmetric functionality to their find_first() counterparts, making it easier to locate unset bits. A constructor from basic_string_view was added for C++17 and later, improving interoperability with modern string APIs. Alongside these additions, I revisited the implementation of several existing members to improve performance and clarity: push_back() and pop_back() were streamlined for better efficiency. all() and lowest_bit() were simplified and optimized, with the latter also shedding its dependency on Boost.Integer. append() was fixed to properly support input iterators and avoid redundant checks. Minor but impactful cleanups A large number of small edits improved correctness, readability, and maintainability: Fixed the stream inserter to set badbit if an exception is thrown during output. Changed the stream extractor to rethrow any exceptions coming from the underlying container. Reordered and cleaned up all #include sections to use the “” form for Boost includes where appropriate and to keep include groups sorted. Removed an example timing benchmark that was misleading and a number of unneeded comments and minor typos across code and docs. These edits reduce noise and make code reviews and maintenance more pleasant. Reflections Looking back, this quarter reminded me of the value of revisiting assumptions. Many of the workarounds and constraints that once made sense are now obsolete. By embracing modern C++ features and simplifying where possible, we can make libraries like dynamic_bitset more powerful and more approachable. It also reinforced the importance of clarity—both in code and in documentation. Whether it’s a test case, a comment, or a public API, precision and consistency go a long way. The work continues, but the foundation is stronger than ever. If you’re using dynamic_bitset or thinking about integrating it into your project, I’d love to hear your feedback.</summary></entry><entry><title type="html">Working on Boost.Bloom roadmap</title><link href="http://cppalliance.org/joaquin/2025/10/09/Joaquins2025Q3Update.html" rel="alternate" type="text/html" title="Working on Boost.Bloom roadmap" /><published>2025-10-09T00:00:00+00:00</published><updated>2025-10-09T00:00:00+00:00</updated><id>http://cppalliance.org/joaquin/2025/10/09/Joaquins2025Q3Update</id><content type="html" xml:base="http://cppalliance.org/joaquin/2025/10/09/Joaquins2025Q3Update.html">&lt;p&gt;During Q3 2025, I’ve been working in the following areas:&lt;/p&gt;

&lt;h3 id=&quot;boostbloom&quot;&gt;Boost.Bloom&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://www.boost.org/doc/libs/latest/libs/bloom/doc/html/bloom.html&quot;&gt;Boost.Bloom&lt;/a&gt; has been officially
released in Boost 1.89. I’ve continued working on a number of roadmap features:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Originally, some subfilters (&lt;code&gt;block&lt;/code&gt;, &lt;code&gt;fast_multiblock32&lt;/code&gt; and &lt;code&gt;fast_multiblock64)&lt;/code&gt;
implemented lookup in a branchful or early-exit way: as soon as a bit checks to zero, lookup
terminates (with result &lt;code&gt;false&lt;/code&gt;). After extensive benchmarks, I’ve changed these subfilters
to branchless execution for somewhat better performance (&lt;a href=&quot;https://github.com/boostorg/bloom/pull/42&quot;&gt;PR#42&lt;/a&gt;).
Note that &lt;code&gt;boost::bloom::filter&amp;lt;T, K, ...&amp;gt;&lt;/code&gt; is still
branchful for &lt;code&gt;K&lt;/code&gt; (the number of subfilter operations per element): in this case, branchless
execution involves too much extra work and does not compensate for the removed branch speculation.
Ivan Matek helped with this investigation.&lt;/li&gt;
  &lt;li&gt;Added &lt;a href=&quot;https://www.boost.org/doc/libs/develop/libs/bloom/doc/html/bloom.html#tutorial_bulk_operations&quot;&gt;bulk-mode operations&lt;/a&gt;
following a similar approach to what we did with Boost.Unordered concurrent containers
(&lt;a href=&quot;https://github.com/boostorg/bloom/pull/43&quot;&gt;PR#42&lt;/a&gt;).&lt;/li&gt;
  &lt;li&gt;I’ve been also working on a proof of concept for a dynamic filter where the &lt;em&gt;k&lt;/em&gt; and/or &lt;em&gt;k’&lt;/em&gt; values
can be specified at run time. As expected, the dynamic filter is slower than its static
counterpart, but benchmarks show that execution times can increase by up to 2x for lookup and
even more for insertion, which makes me undecided as to whether to launch this feature.
An alternative approach is to have a &lt;code&gt;dynamic_filter&amp;lt;T&amp;gt;&lt;/code&gt; be a wrapper over a virtual interface
whose implementation is selected at run time from a static table of implementations
based on static &lt;code&gt;filter&amp;lt;T, K&amp;gt;&lt;/code&gt; with
&lt;code&gt;K&lt;/code&gt; between 1 and some maximum value (this type erasure technique is described, among
other places, in slides 157-205 of Sean Parent’s
&lt;a href=&quot;https://raw.githubusercontent.com/wiki/sean-parent/sean-parent.github.io/presentations/2013-09-11-cpp-seasoning/cpp-seasoning.pdf&quot;&gt;C++ Seasoning&lt;/a&gt;
talk): performance is much better, but this approach also has drawbacks of its own.&lt;/li&gt;
  &lt;li&gt;Reviewed a contribution fom Braden Ganetsky to make the project’s &lt;code&gt;CMakeLists.txt&lt;/code&gt;
more Visual Studio-friendly (&lt;a href=&quot;https://github.com/boostorg/bloom/pull/33&quot;&gt;PR#33&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;boostunordered&quot;&gt;Boost.Unordered&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Reviewed &lt;a href=&quot;https://github.com/boostorg/unordered/pull/316&quot;&gt;PR#316&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;boostmultiindex&quot;&gt;Boost.MultiIndex&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Reviewed &lt;a href=&quot;https://github.com/boostorg/multi_index/pull/83&quot;&gt;PR#83&lt;/a&gt;, &lt;a href=&quot;https://github.com/boostorg/multi_index/pull/84&quot;&gt;PR#84&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;boostflyweight&quot;&gt;Boost.Flyweight&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Fixed an internal compile error that manifested with newer compilers implementing
&lt;a href=&quot;https://wg21.link/p0522r0&quot;&gt;P0522R0&lt;/a&gt;
(&lt;a href=&quot;https://github.com/boostorg/flyweight/pull/23&quot;&gt;PR#23&lt;/a&gt;).&lt;/li&gt;
  &lt;li&gt;Reviewed &lt;a href=&quot;https://github.com/boostorg/flyweight/pull/22&quot;&gt;PR#22&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;boostpolycollection&quot;&gt;Boost.PolyCollection&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Reviewed &lt;a href=&quot;https://github.com/boostorg/poly_collection/pull/32&quot;&gt;PR#32&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;boost-website&quot;&gt;Boost website&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Filed issues
&lt;a href=&quot;https://github.com/boostorg/website-v2/issues/1845&quot;&gt;#1845&lt;/a&gt;,
&lt;a href=&quot;https://github.com/boostorg/website-v2/issues/1846&quot;&gt;#1846&lt;/a&gt;,
&lt;a href=&quot;https://github.com/boostorg/website-v2/issues/1851&quot;&gt;#1851&lt;/a&gt;,
&lt;a href=&quot;https://github.com/boostorg/website-v2/issues/1858&quot;&gt;#1858&lt;/a&gt;,
&lt;a href=&quot;https://github.com/boostorg/website-v2/issues/1900&quot;&gt;#1900&lt;/a&gt;,
&lt;a href=&quot;https://github.com/boostorg/website-v2/issues/1927&quot;&gt;#1927&lt;/a&gt;,
&lt;a href=&quot;https://github.com/boostorg/website-v2/issues/1936&quot;&gt;#1936&lt;/a&gt;,
&lt;a href=&quot;https://github.com/boostorg/website-v2/issues/1937&quot;&gt;#1937&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Helped with the transition of the global release notes procedure to one
based on the new website repo exclusively
(&lt;a href=&quot;https://github.com/boostorg/website-v2-docs/pull/508&quot;&gt;PR#508&lt;/a&gt;,
&lt;a href=&quot;https://github.com/boostorg/website-v2-docs/pull/510&quot;&gt;PR#510&lt;/a&gt;). This procedure is
expected to launch in time for the upcoming Boost 1.90 release.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;boost-promotion&quot;&gt;Boost promotion&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Prepared and posted around 10 messages on Boost’s X account and Reddit.
The activity on social media has grown considerably thanks to the dedication of
Rob Beeston and others.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;support-to-the-community&quot;&gt;Support to the community&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Helped Jean-Louis Leroy get Drone support for the upcoming
Boost.OpenMethod library (&lt;a href=&quot;https://github.com/boostorg/openmethod/pull/39&quot;&gt;PR#39&lt;/a&gt;).&lt;/li&gt;
  &lt;li&gt;Supporting the community as a member of the Fiscal Sponsorhip Committee (FSC).&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="joaquin" /><summary type="html">During Q3 2025, I’ve been working in the following areas: Boost.Bloom Boost.Bloom has been officially released in Boost 1.89. I’ve continued working on a number of roadmap features: Originally, some subfilters (block, fast_multiblock32 and fast_multiblock64) implemented lookup in a branchful or early-exit way: as soon as a bit checks to zero, lookup terminates (with result false). After extensive benchmarks, I’ve changed these subfilters to branchless execution for somewhat better performance (PR#42). Note that boost::bloom::filter&amp;lt;T, K, ...&amp;gt; is still branchful for K (the number of subfilter operations per element): in this case, branchless execution involves too much extra work and does not compensate for the removed branch speculation. Ivan Matek helped with this investigation. Added bulk-mode operations following a similar approach to what we did with Boost.Unordered concurrent containers (PR#42). I’ve been also working on a proof of concept for a dynamic filter where the k and/or k’ values can be specified at run time. As expected, the dynamic filter is slower than its static counterpart, but benchmarks show that execution times can increase by up to 2x for lookup and even more for insertion, which makes me undecided as to whether to launch this feature. An alternative approach is to have a dynamic_filter&amp;lt;T&amp;gt; be a wrapper over a virtual interface whose implementation is selected at run time from a static table of implementations based on static filter&amp;lt;T, K&amp;gt; with K between 1 and some maximum value (this type erasure technique is described, among other places, in slides 157-205 of Sean Parent’s C++ Seasoning talk): performance is much better, but this approach also has drawbacks of its own. Reviewed a contribution fom Braden Ganetsky to make the project’s CMakeLists.txt more Visual Studio-friendly (PR#33). Boost.Unordered Reviewed PR#316. Boost.MultiIndex Reviewed PR#83, PR#84. Boost.Flyweight Fixed an internal compile error that manifested with newer compilers implementing P0522R0 (PR#23). Reviewed PR#22. Boost.PolyCollection Reviewed PR#32. Boost website Filed issues #1845, #1846, #1851, #1858, #1900, #1927, #1936, #1937. Helped with the transition of the global release notes procedure to one based on the new website repo exclusively (PR#508, PR#510). This procedure is expected to launch in time for the upcoming Boost 1.90 release. Boost promotion Prepared and posted around 10 messages on Boost’s X account and Reddit. The activity on social media has grown considerably thanks to the dedication of Rob Beeston and others. Support to the community Helped Jean-Louis Leroy get Drone support for the upcoming Boost.OpenMethod library (PR#39). Supporting the community as a member of the Fiscal Sponsorhip Committee (FSC).</summary></entry><entry><title type="html">Levelling up Boost.Redis</title><link href="http://cppalliance.org/ruben/2025/10/07/Ruben2025Q3Update.html" rel="alternate" type="text/html" title="Levelling up Boost.Redis" /><published>2025-10-07T00:00:00+00:00</published><updated>2025-10-07T00:00:00+00:00</updated><id>http://cppalliance.org/ruben/2025/10/07/Ruben2025Q3Update</id><content type="html" xml:base="http://cppalliance.org/ruben/2025/10/07/Ruben2025Q3Update.html">&lt;p&gt;I’ve really come to appreciate Boost.Redis design. With only
three asynchronous primitives it exposes all the power of Redis,
with features like automatic pipelining that make it pretty unique.
Boost.Redis 1.90 will ship with some new exciting features that I’ll
cover in this post.&lt;/p&gt;

&lt;h2 id=&quot;cancelling-requests-with-asiocancel_after&quot;&gt;Cancelling requests with asio::cancel_after&lt;/h2&gt;

&lt;p&gt;Boost.Redis implements a number of reliability measures, including reconnection.
Suppose that you attempt to execute a request using &lt;code&gt;async_exec&lt;/code&gt;,
but the Redis server can’t be contacted (for example, because of a temporary network error).
Boost.Redis will try to re-establish the connection to the failed server,
and &lt;code&gt;async_exec&lt;/code&gt; will suspend until the server is healthy again.&lt;/p&gt;

&lt;p&gt;This is a great feature if the outage is transitory. But what would happen if
the Redis server is permanently down - for example, because of deployment issue that
must be manually solved? The user will see that &lt;code&gt;async_exec&lt;/code&gt; never completes.
If new requests continue to be issued, the program will end up consuming an
unbound amount of resources.&lt;/p&gt;

&lt;p&gt;Starting with Boost 1.90, you can use &lt;code&gt;asio::cancel_after&lt;/code&gt; to set
a timeout to your requests, preventing this from happening:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;// Compose your request
redis::request req;
req.push(&quot;SET&quot;, &quot;my_key&quot;, 42);

// If the request doesn't complete within 30s, consider it as failed
co_await conn.async_exec(req, redis::ignore, asio::cancel_after(30s));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For this to work, &lt;code&gt;async_exec&lt;/code&gt; must properly support
&lt;a href=&quot;https://www.boost.org/doc/libs/latest/doc/html/boost_asio/overview/core/cancellation.html&quot;&gt;per-operation cancellation&lt;/a&gt;.
This is tricky because Boost.Redis allows executing several requests concurrently,
which are merged into a single pipeline before being sent.
For the above to useful, cancelling one request shouldn’t affect other requests.
In Asio parlance, &lt;code&gt;async_exec&lt;/code&gt; should support partial cancellation, at least.&lt;/p&gt;

&lt;p&gt;Cancelling a request that hasn’t been sent yet is trivial - you just remove it from
the queue and call it a day. Cancelling requests that are in progress is more involved.
We’ve solved this by using “tombstones”. If a response encounters a tombstone,
it will get ignored. This way, cancelling &lt;code&gt;async_exec&lt;/code&gt; has always an immediate
effect, but the connection is kept in a well-defined state.&lt;/p&gt;

&lt;h2 id=&quot;custom-setup-requests&quot;&gt;Custom setup requests&lt;/h2&gt;

&lt;p&gt;Redis talks the RESP3 protocol. But it’s not the only database system that speaks it.
We’ve recently learnt that other systems, like &lt;a href=&quot;https://www.tarantool.io/en/tarantooldb/&quot;&gt;Tarantool DB&lt;/a&gt;,
are also capable of speaking RESP3. This means that Boost.Redis can be used to
interact with these systems.&lt;/p&gt;

&lt;p&gt;At least in theory. In Boost 1.89, the library uses the &lt;a href=&quot;https://redis.io/docs/latest/commands/hello/&quot;&gt;&lt;code&gt;HELLO&lt;/code&gt;&lt;/a&gt;
command to upgrade to RESP3 (Redis’ default is using the less powerful RESP2).
The command is issued as part of the reconnection loop, without user intervention.
It happens that systems like Tarantool DB don’t support &lt;code&gt;HELLO&lt;/code&gt; because they
don’t speak RESP2 at all, so there is nothing to upgrade.&lt;/p&gt;

&lt;p&gt;This is part of a larger problem: users might want to run arbitrary commands
when the connection is established, to perform setup tasks.
This might include &lt;a href=&quot;https://redis.io/docs/latest/commands/auth/&quot;&gt;&lt;code&gt;AUTH&lt;/code&gt;&lt;/a&gt; to provide
credentials or &lt;a href=&quot;https://redis.io/docs/latest/commands/select/&quot;&gt;&lt;code&gt;SELECT&lt;/code&gt;&lt;/a&gt; to choose
a database index.&lt;/p&gt;

&lt;p&gt;Until now, all you could do is configure the parameters used by the &lt;code&gt;HELLO&lt;/code&gt; command.
Starting with Boost 1.90, you can run arbitrary commands at connection startup:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;// At startup, don't send any HELLO, but set up authentication and select a database
redis::request setup_request;
setup_request.push(&quot;AUTH&quot;, &quot;my_user&quot;, &quot;my_password&quot;);
setup_request.push(&quot;SELECT&quot;, 2);

redis::config cfg {
    .use_setup = true, // use the custom setup request, rather than the default HELLO command
    .setup = std::move(setup_request), // will be run every time a connection is established
};

conn.async_run(cfg, asio::detached);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This opens the door simplifying code using PubSub. At the moment, such code needs
to issue a &lt;code&gt;SUBSCRIBE&lt;/code&gt; command every time a reconnection happens, which implies
some tricks around &lt;code&gt;async_receive&lt;/code&gt;. With this feature, you can just add a &lt;code&gt;SUBSCRIBE&lt;/code&gt;
command to your setup request and forget.&lt;/p&gt;

&lt;p&gt;This will be further explored in the next months, since &lt;code&gt;async_receive&lt;/code&gt; is currently
aware of reconnections, so it might need some extra changes to see real benefits.&lt;/p&gt;

&lt;h2 id=&quot;valkey-support&quot;&gt;Valkey support&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://valkey.io/&quot;&gt;Valkey&lt;/a&gt; is a fork from Redis v7.3. At the time of writing,
both databases are mostly interoperable in terms of protocol features, but
they are being developed separately (as happened with MySQL and MariaDB).&lt;/p&gt;

&lt;p&gt;In Boost.Redis we’ve committed to supporting both long-term
(at the moment, by deploying CI builds to test both).&lt;/p&gt;

&lt;h2 id=&quot;race-free-cancellation&quot;&gt;Race-free cancellation&lt;/h2&gt;

&lt;p&gt;It is very easy to introduce race conditions in cancellation with Asio.
Consider the following code, which is typical in libraries that
predate per-operation cancellation:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;struct connection
{
    asio::ip::tcp::socket sock;
    std::string buffer;

    struct echo_op
    {
        connection* obj;
        asio::coroutine coro{};

        template &amp;lt;class Self&amp;gt;
        void operator()(Self&amp;amp; self, error_code ec = {}, std::size_t = {})
        {
            BOOST_ASIO_CORO_REENTER(coro)
            {
                while (true)
                {
                    // Read from the socket
                    BOOST_ASIO_CORO_YIELD
                    asio::async_read_until(obj-&amp;gt;sock, asio::dynamic_buffer(obj-&amp;gt;buffer), &quot;\n&quot;, std::move(self));

                    // Check for errors
                    if (ec)
                        self.complete(ec);

                    // Write back
                    BOOST_ASIO_CORO_YIELD
                    asio::async_write(obj-&amp;gt;sock, asio::buffer(obj-&amp;gt;buffer), std::move(self));

                    // Done
                    self.complete(ec);
                }
            }
        }
    };

    template &amp;lt;class CompletionToken&amp;gt;
    auto async_echo(CompletionToken&amp;amp;&amp;amp; token)
    {
        return asio::async_compose&amp;lt;CompletionToken, void(error_code)&amp;gt;(echo_op{this}, token, sock);
    }

    void cancel() { sock.cancel(); }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There is a race condition here. &lt;code&gt;cancel()&lt;/code&gt; may actually not cancel a running &lt;code&gt;async_echo&lt;/code&gt;.
After a read or write completes, the respective handler may not be called immediately,
but queued for execution. If &lt;code&gt;cancel()&lt;/code&gt; is called within that time frame, the cancellation
will be ignored.&lt;/p&gt;

&lt;p&gt;The proper way to handle this is using per-operation cancellation, rather than a &lt;code&gt;cancel()&lt;/code&gt; method.
&lt;code&gt;async_compose&lt;/code&gt; knows about this problem and keeps state about received cancellations, so you can write:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;// Read from the socket
BOOST_ASIO_CORO_YIELD
asio::async_read_until(obj-&amp;gt;sock, asio::dynamic_buffer(obj-&amp;gt;buffer), &quot;\n&quot;, std::move(self));

// Check for errors
if (ec)
    self.complete(ec);

// Check for cancellations
if (!!(self.get_cancellation_state().cancelled() &amp;amp; asio::cancellation_type_t::terminal))
    self.complete(asio::error::operation_aborted);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In 1.90, the library uses this approach everywhere, so cancellation is reliable.
Keeping the &lt;code&gt;cancel()&lt;/code&gt; method is a challenge, as it involves re-wiring cancellation
slots, so I won’t show it here - but we’ve managed to do it.&lt;/p&gt;

&lt;h2 id=&quot;next-steps&quot;&gt;Next steps&lt;/h2&gt;

&lt;p&gt;I’ve got plans to keep working on Boost.Redis for a time. You can expect
more features in 1.91, like &lt;a href=&quot;https://redis.io/docs/latest/operate/oss_and_stack/management/sentinel/&quot;&gt;Sentinel&lt;/a&gt;
support and &lt;a href=&quot;https://github.com/boostorg/redis/issues/104&quot;&gt;more reliable health checks&lt;/a&gt;.&lt;/p&gt;</content><author><name></name></author><category term="ruben" /><summary type="html">I’ve really come to appreciate Boost.Redis design. With only three asynchronous primitives it exposes all the power of Redis, with features like automatic pipelining that make it pretty unique. Boost.Redis 1.90 will ship with some new exciting features that I’ll cover in this post. Cancelling requests with asio::cancel_after Boost.Redis implements a number of reliability measures, including reconnection. Suppose that you attempt to execute a request using async_exec, but the Redis server can’t be contacted (for example, because of a temporary network error). Boost.Redis will try to re-establish the connection to the failed server, and async_exec will suspend until the server is healthy again. This is a great feature if the outage is transitory. But what would happen if the Redis server is permanently down - for example, because of deployment issue that must be manually solved? The user will see that async_exec never completes. If new requests continue to be issued, the program will end up consuming an unbound amount of resources. Starting with Boost 1.90, you can use asio::cancel_after to set a timeout to your requests, preventing this from happening: // Compose your request redis::request req; req.push(&quot;SET&quot;, &quot;my_key&quot;, 42); // If the request doesn't complete within 30s, consider it as failed co_await conn.async_exec(req, redis::ignore, asio::cancel_after(30s)); For this to work, async_exec must properly support per-operation cancellation. This is tricky because Boost.Redis allows executing several requests concurrently, which are merged into a single pipeline before being sent. For the above to useful, cancelling one request shouldn’t affect other requests. In Asio parlance, async_exec should support partial cancellation, at least. Cancelling a request that hasn’t been sent yet is trivial - you just remove it from the queue and call it a day. Cancelling requests that are in progress is more involved. We’ve solved this by using “tombstones”. If a response encounters a tombstone, it will get ignored. This way, cancelling async_exec has always an immediate effect, but the connection is kept in a well-defined state. Custom setup requests Redis talks the RESP3 protocol. But it’s not the only database system that speaks it. We’ve recently learnt that other systems, like Tarantool DB, are also capable of speaking RESP3. This means that Boost.Redis can be used to interact with these systems. At least in theory. In Boost 1.89, the library uses the HELLO command to upgrade to RESP3 (Redis’ default is using the less powerful RESP2). The command is issued as part of the reconnection loop, without user intervention. It happens that systems like Tarantool DB don’t support HELLO because they don’t speak RESP2 at all, so there is nothing to upgrade. This is part of a larger problem: users might want to run arbitrary commands when the connection is established, to perform setup tasks. This might include AUTH to provide credentials or SELECT to choose a database index. Until now, all you could do is configure the parameters used by the HELLO command. Starting with Boost 1.90, you can run arbitrary commands at connection startup: // At startup, don't send any HELLO, but set up authentication and select a database redis::request setup_request; setup_request.push(&quot;AUTH&quot;, &quot;my_user&quot;, &quot;my_password&quot;); setup_request.push(&quot;SELECT&quot;, 2); redis::config cfg { .use_setup = true, // use the custom setup request, rather than the default HELLO command .setup = std::move(setup_request), // will be run every time a connection is established }; conn.async_run(cfg, asio::detached); This opens the door simplifying code using PubSub. At the moment, such code needs to issue a SUBSCRIBE command every time a reconnection happens, which implies some tricks around async_receive. With this feature, you can just add a SUBSCRIBE command to your setup request and forget. This will be further explored in the next months, since async_receive is currently aware of reconnections, so it might need some extra changes to see real benefits. Valkey support Valkey is a fork from Redis v7.3. At the time of writing, both databases are mostly interoperable in terms of protocol features, but they are being developed separately (as happened with MySQL and MariaDB). In Boost.Redis we’ve committed to supporting both long-term (at the moment, by deploying CI builds to test both). Race-free cancellation It is very easy to introduce race conditions in cancellation with Asio. Consider the following code, which is typical in libraries that predate per-operation cancellation: struct connection { asio::ip::tcp::socket sock; std::string buffer; struct echo_op { connection* obj; asio::coroutine coro{}; template &amp;lt;class Self&amp;gt; void operator()(Self&amp;amp; self, error_code ec = {}, std::size_t = {}) { BOOST_ASIO_CORO_REENTER(coro) { while (true) { // Read from the socket BOOST_ASIO_CORO_YIELD asio::async_read_until(obj-&amp;gt;sock, asio::dynamic_buffer(obj-&amp;gt;buffer), &quot;\n&quot;, std::move(self)); // Check for errors if (ec) self.complete(ec); // Write back BOOST_ASIO_CORO_YIELD asio::async_write(obj-&amp;gt;sock, asio::buffer(obj-&amp;gt;buffer), std::move(self)); // Done self.complete(ec); } } } }; template &amp;lt;class CompletionToken&amp;gt; auto async_echo(CompletionToken&amp;amp;&amp;amp; token) { return asio::async_compose&amp;lt;CompletionToken, void(error_code)&amp;gt;(echo_op{this}, token, sock); } void cancel() { sock.cancel(); } }; There is a race condition here. cancel() may actually not cancel a running async_echo. After a read or write completes, the respective handler may not be called immediately, but queued for execution. If cancel() is called within that time frame, the cancellation will be ignored. The proper way to handle this is using per-operation cancellation, rather than a cancel() method. async_compose knows about this problem and keeps state about received cancellations, so you can write: // Read from the socket BOOST_ASIO_CORO_YIELD asio::async_read_until(obj-&amp;gt;sock, asio::dynamic_buffer(obj-&amp;gt;buffer), &quot;\n&quot;, std::move(self)); // Check for errors if (ec) self.complete(ec); // Check for cancellations if (!!(self.get_cancellation_state().cancelled() &amp;amp; asio::cancellation_type_t::terminal)) self.complete(asio::error::operation_aborted); In 1.90, the library uses this approach everywhere, so cancellation is reliable. Keeping the cancel() method is a challenge, as it involves re-wiring cancellation slots, so I won’t show it here - but we’ve managed to do it. Next steps I’ve got plans to keep working on Boost.Redis for a time. You can expect more features in 1.91, like Sentinel support and more reliable health checks.</summary></entry><entry><title type="html">Decimal Goes Back to Review</title><link href="http://cppalliance.org/matt/2025/10/06/Matts2025Q3Update.html" rel="alternate" type="text/html" title="Decimal Goes Back to Review" /><published>2025-10-06T00:00:00+00:00</published><updated>2025-10-06T00:00:00+00:00</updated><id>http://cppalliance.org/matt/2025/10/06/Matts2025Q3Update</id><content type="html" xml:base="http://cppalliance.org/matt/2025/10/06/Matts2025Q3Update.html">&lt;p&gt;We are excited to announce that the Decimal (&lt;a href=&quot;https://github.com/cppalliance/decimal&quot;&gt;https://github.com/cppalliance/decimal&lt;/a&gt;) library is going back to review for inclusion in Boost from 06 to 15 October.
In preparation for this we have made quite a few changes since the indeterminate end of the first review about 9 months ago:&lt;/p&gt;

&lt;p&gt;Breaking Changes:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Based on bitwise comparisons with other similar libraries and database software, we have changed the internal encoding of our IEEE 754-compliant types&lt;/li&gt;
  &lt;li&gt;We spent about 3 months optimizing just back end integer types that are now used throughout the library, and as the internals of decimal128_t&lt;/li&gt;
  &lt;li&gt;We have changed the type names to better match conventions:
    &lt;ul&gt;
      &lt;li&gt;&lt;code&gt;decimalXX&lt;/code&gt; is now &lt;code&gt;decimalXX_t&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code&gt;decimalXX_fast&lt;/code&gt; is now &lt;code&gt;decimal_fastXX_t&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The headers have been similarly renamed (e.g. decimal32.hpp -&amp;gt; decimal32_t.hpp), and can now be used independently instead of requiring the monolith based on feedback in Review&lt;/li&gt;
  &lt;li&gt;Constructors have been simplified to reduce confusion (no more double negative logic)&lt;/li&gt;
  &lt;li&gt;The default rounding mode has changed to align with IEEE 754, with rounding bugs being squashed across the modes as well&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Other Changes:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The documenation content has been overhauled thanks to feedback from Peter Turcan and others during the first review&lt;/li&gt;
  &lt;li&gt;The docs are no longer a single long page of Asciidoc; we have moved to Antora. Thanks to Joaquín and Christian for making it trivial to copy from Unordered to make that happen.
    &lt;ul&gt;
      &lt;li&gt;https://develop.decimal.cpp.al/&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;We now support formatting with {fmt}&lt;/li&gt;
  &lt;li&gt;Benchmarks have been expanded to include GCC &lt;code&gt;_DecimalXX&lt;/code&gt; types, and Intel’s libbid. I think people should be pleased with the results now, since that was a huge point of contention at the end of the review&lt;/li&gt;
  &lt;li&gt;We have added support for CMake pkg config for ease of use&lt;/li&gt;
  &lt;li&gt;Every post-review issue John was kind enough to consolidate and open have been addressed: https://github.com/cppalliance/decimal/issues?q=is%3Aissue%20state%3Aclosed%20label%3A%22Boost%20Review%22&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Continued Developments:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;I think the only unaddressed comment from the first review is support for hardware decimal floating point types.
There are a few rarer architectures that have native decimal floating point units like POWER10.
Is it possible to fully integrate these native types for use in the library?
Armed with a compiler farm account I have begun developing a wrapper around the native types that seems to work.
Stay tuned.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;One item that we have considered, but have not put any effort into yet would be getting the library running on CUDA platforms.
If this is a feature that you are interested in, please let us know!&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;As is always the case with Boost reviews, regardless of the outcome I am sure that we will receive lots of feedback on how to improve the library.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you are interested, much of the contents of the first review can be found in the original thread on the boost mailing list archive: https://lists.boost.org/archives/list/boost@lists.boost.org/thread/AGFOQZMJ4HKKQ5C5XDDKNJ3VJL72YTWL/&lt;/p&gt;</content><author><name></name></author><category term="matt" /><summary type="html">We are excited to announce that the Decimal (https://github.com/cppalliance/decimal) library is going back to review for inclusion in Boost from 06 to 15 October. In preparation for this we have made quite a few changes since the indeterminate end of the first review about 9 months ago: Breaking Changes: Based on bitwise comparisons with other similar libraries and database software, we have changed the internal encoding of our IEEE 754-compliant types We spent about 3 months optimizing just back end integer types that are now used throughout the library, and as the internals of decimal128_t We have changed the type names to better match conventions: decimalXX is now decimalXX_t decimalXX_fast is now decimal_fastXX_t The headers have been similarly renamed (e.g. decimal32.hpp -&amp;gt; decimal32_t.hpp), and can now be used independently instead of requiring the monolith based on feedback in Review Constructors have been simplified to reduce confusion (no more double negative logic) The default rounding mode has changed to align with IEEE 754, with rounding bugs being squashed across the modes as well Other Changes: The documenation content has been overhauled thanks to feedback from Peter Turcan and others during the first review The docs are no longer a single long page of Asciidoc; we have moved to Antora. Thanks to Joaquín and Christian for making it trivial to copy from Unordered to make that happen. https://develop.decimal.cpp.al/ We now support formatting with {fmt} Benchmarks have been expanded to include GCC _DecimalXX types, and Intel’s libbid. I think people should be pleased with the results now, since that was a huge point of contention at the end of the review We have added support for CMake pkg config for ease of use Every post-review issue John was kind enough to consolidate and open have been addressed: https://github.com/cppalliance/decimal/issues?q=is%3Aissue%20state%3Aclosed%20label%3A%22Boost%20Review%22 Continued Developments: I think the only unaddressed comment from the first review is support for hardware decimal floating point types. There are a few rarer architectures that have native decimal floating point units like POWER10. Is it possible to fully integrate these native types for use in the library? Armed with a compiler farm account I have begun developing a wrapper around the native types that seems to work. Stay tuned. One item that we have considered, but have not put any effort into yet would be getting the library running on CUDA platforms. If this is a feature that you are interested in, please let us know! As is always the case with Boost reviews, regardless of the outcome I am sure that we will receive lots of feedback on how to improve the library. If you are interested, much of the contents of the first review can be found in the original thread on the boost mailing list archive: https://lists.boost.org/archives/list/boost@lists.boost.org/thread/AGFOQZMJ4HKKQ5C5XDDKNJ3VJL72YTWL/</summary></entry><entry><title type="html">Systems, CI Updates Q3 2025</title><link href="http://cppalliance.org/sam/2025/10/05/SamsQ3Update.html" rel="alternate" type="text/html" title="Systems, CI Updates Q3 2025" /><published>2025-10-05T00:00:00+00:00</published><updated>2025-10-05T00:00:00+00:00</updated><id>http://cppalliance.org/sam/2025/10/05/SamsQ3Update</id><content type="html" xml:base="http://cppalliance.org/sam/2025/10/05/SamsQ3Update.html">&lt;h3 id=&quot;doc-previews-and-doc-builds&quot;&gt;Doc Previews and Doc Builds&lt;/h3&gt;

&lt;p&gt;The isomorphic-git improvements are an ongoing saga. (As a reminder, isomorphic-git is a dependency and component of Antora, which can’t parse submodules while boost relies heavily on submodules). This quarter I coded full submodule support into isomorphic-git and then submitted a PR with 150 files modified. An issue is that the library is suffering from a general lack of maintainers, it’s stuck on Nodejs 14 from 5 years ago, and uses many out-of-date packages. These are preventing proper CI tests (specifically, recursive copy isn’t supported) and now the maintainer refuses to merge the pull request without a major overhaul of BrowserFS -&amp;gt; ZenFS. It’s a complete detour since this has nothing directly to do with submodules.&lt;/p&gt;

&lt;p&gt;An amusing anecdote from the story: out of the blue a developer from Germany appeared and he was very energetic about fixing everything in isomorphic-git. For a week or so, it seemed he would solve all problems. He would overhaul the entire package (which has been neglected), contribute many improvements, solve all bugs, upgrade ZenFS, etc. I was genuinely optimistic about his participation. However my latest assessment of the situation is he’s experiencing some delusions of grandeur based on comments in git repositories such as…  that upgrading isomorphic-git “will trigger a massive, multi-trillion-dollar restructuring of the digital economy”. After expressing impatience with the existing maintainers of isomorphic-git, the developer forked the repo, and has ceased to be involved directly.&lt;/p&gt;

&lt;p&gt;However all is not lost. The author of ZenFS is actively working with isomorphic-git to implement the BrowserFS -&amp;gt; ZenFS upgrade. He is contributing the pull request.&lt;/p&gt;

&lt;h3 id=&quot;boost-website-boostorgwebsite-v2&quot;&gt;Boost website boostorg/website-v2&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Adjust db caching to support master/develop branches.&lt;/li&gt;
  &lt;li&gt;Improve script to deploy websites via ‘git push’.&lt;/li&gt;
  &lt;li&gt;Remove files from wowbagger, disk space filling up.&lt;/li&gt;
  &lt;li&gt;Redirect live.boost.org to boost.org. Switch regression.boost.io -&amp;gt; regression.boost.org. Fix bugs in the regression CI jobs.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;mailman3&quot;&gt;Mailman3&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Modified scripts to allow developers to locally download, parse, graph MM3 traffic. That is, conveniently download the database backups of the mailing lists.&lt;/li&gt;
  &lt;li&gt;Plausible Analytics for lists.boost.org.&lt;/li&gt;
  &lt;li&gt;Gunicorn number-of-workers adjustments.&lt;/li&gt;
  &lt;li&gt;Discuss HTML-formatting features with MM3 upstream maintainers. Resistance to the idea, and also from Andrey and others at Boost. It is not a basic feature to implement - affects multiple areas of the app. May not proceed in the short-term.&lt;/li&gt;
  &lt;li&gt;Troubleshooting, and discovered the cause of a page load delay. Disabled ‘member visibility’ for now, which causes a massive SQL query every time anyone visits the profile page.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;boost-ci&quot;&gt;boost-ci&lt;/h3&gt;

&lt;p&gt;Completed from last quarter: Nearly all CI jobs that use boost-ci set B2_CI_VERSION=1. Eliminate the need for this variable by making it a default, which will avoid errors when the variable isn’t set properly. CI configuration becomes one step easier. B2_CI_VERSION=1 may now be omitted.&lt;/p&gt;

&lt;h3 id=&quot;jenkins&quot;&gt;Jenkins&lt;/h3&gt;

&lt;p&gt;Asio docs builds for K-ballo.&lt;/p&gt;

&lt;h3 id=&quot;boost-release-process-boostorgrelease-tools&quot;&gt;Boost release process boostorg/release-tools&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Release-tools bug fixes in connection with boostorg/redis antora builds.&lt;/li&gt;
  &lt;li&gt;Commitbot accepts case-insensitive variables. (Needs to be merged.)&lt;/li&gt;
  &lt;li&gt;publish_release.py: extend preflight checks to staging.&lt;/li&gt;
  &lt;li&gt;New superproject container image - upgrade Doxygen.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;drone&quot;&gt;Drone&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Built a container image “cppalliance/2404-p2996:1” to support P2996 (“Reflection for C++26”), based on the repository https://github.com/bloomberg/clang-p2996 that contains experimental support for P2996 reflection.&lt;/li&gt;
  &lt;li&gt;Upgraded Xcode versions on existing macOS machines.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;json-benchmarks&quot;&gt;JSON Benchmarks&lt;/h3&gt;

&lt;p&gt;After a server outage, recovered access through the console on dedicatednode2.cpp.al. Adjusted network configuration.&lt;/p&gt;

&lt;h3 id=&quot;gha&quot;&gt;GHA&lt;/h3&gt;

&lt;p&gt;Significant time working on an upgrade to the latest version of the Terraform code. Encountered multiple bugs. The CI user on Windows is no longer configurable, but it should be set (to ‘Administrator’) during boost CI tests. Composed and sent a pull request. Ongoing.&lt;/p&gt;</content><author><name></name></author><category term="sam" /><summary type="html">Doc Previews and Doc Builds The isomorphic-git improvements are an ongoing saga. (As a reminder, isomorphic-git is a dependency and component of Antora, which can’t parse submodules while boost relies heavily on submodules). This quarter I coded full submodule support into isomorphic-git and then submitted a PR with 150 files modified. An issue is that the library is suffering from a general lack of maintainers, it’s stuck on Nodejs 14 from 5 years ago, and uses many out-of-date packages. These are preventing proper CI tests (specifically, recursive copy isn’t supported) and now the maintainer refuses to merge the pull request without a major overhaul of BrowserFS -&amp;gt; ZenFS. It’s a complete detour since this has nothing directly to do with submodules. An amusing anecdote from the story: out of the blue a developer from Germany appeared and he was very energetic about fixing everything in isomorphic-git. For a week or so, it seemed he would solve all problems. He would overhaul the entire package (which has been neglected), contribute many improvements, solve all bugs, upgrade ZenFS, etc. I was genuinely optimistic about his participation. However my latest assessment of the situation is he’s experiencing some delusions of grandeur based on comments in git repositories such as… that upgrading isomorphic-git “will trigger a massive, multi-trillion-dollar restructuring of the digital economy”. After expressing impatience with the existing maintainers of isomorphic-git, the developer forked the repo, and has ceased to be involved directly. However all is not lost. The author of ZenFS is actively working with isomorphic-git to implement the BrowserFS -&amp;gt; ZenFS upgrade. He is contributing the pull request. Boost website boostorg/website-v2 Adjust db caching to support master/develop branches. Improve script to deploy websites via ‘git push’. Remove files from wowbagger, disk space filling up. Redirect live.boost.org to boost.org. Switch regression.boost.io -&amp;gt; regression.boost.org. Fix bugs in the regression CI jobs. Mailman3 Modified scripts to allow developers to locally download, parse, graph MM3 traffic. That is, conveniently download the database backups of the mailing lists. Plausible Analytics for lists.boost.org. Gunicorn number-of-workers adjustments. Discuss HTML-formatting features with MM3 upstream maintainers. Resistance to the idea, and also from Andrey and others at Boost. It is not a basic feature to implement - affects multiple areas of the app. May not proceed in the short-term. Troubleshooting, and discovered the cause of a page load delay. Disabled ‘member visibility’ for now, which causes a massive SQL query every time anyone visits the profile page. boost-ci Completed from last quarter: Nearly all CI jobs that use boost-ci set B2_CI_VERSION=1. Eliminate the need for this variable by making it a default, which will avoid errors when the variable isn’t set properly. CI configuration becomes one step easier. B2_CI_VERSION=1 may now be omitted. Jenkins Asio docs builds for K-ballo. Boost release process boostorg/release-tools Release-tools bug fixes in connection with boostorg/redis antora builds. Commitbot accepts case-insensitive variables. (Needs to be merged.) publish_release.py: extend preflight checks to staging. New superproject container image - upgrade Doxygen. Drone Built a container image “cppalliance/2404-p2996:1” to support P2996 (“Reflection for C++26”), based on the repository https://github.com/bloomberg/clang-p2996 that contains experimental support for P2996 reflection. Upgraded Xcode versions on existing macOS machines. JSON Benchmarks After a server outage, recovered access through the console on dedicatednode2.cpp.al. Adjusted network configuration. GHA Significant time working on an upgrade to the latest version of the Terraform code. Encountered multiple bugs. The CI user on Windows is no longer configurable, but it should be set (to ‘Administrator’) during boost CI tests. Composed and sent a pull request. Ongoing.</summary></entry><entry><title type="html">Boost.RunTimeServices: The Glue for Optional Runtime Features</title><link href="http://cppalliance.org/mohammad/2025/07/16/MohammadsQ2Update.html" rel="alternate" type="text/html" title="Boost.RunTimeServices: The Glue for Optional Runtime Features" /><published>2025-07-16T00:00:00+00:00</published><updated>2025-07-16T00:00:00+00:00</updated><id>http://cppalliance.org/mohammad/2025/07/16/MohammadsQ2Update</id><content type="html" xml:base="http://cppalliance.org/mohammad/2025/07/16/MohammadsQ2Update.html">&lt;h2 id=&quot;how-boostruntimeservices-emerged-from-boosthttpproto-development&quot;&gt;How Boost.RunTimeServices Emerged from Boost.HTTP.Proto Development&lt;/h2&gt;

&lt;p&gt;During the development of the
&lt;a href=&quot;https://github.com/cppalliance/http_proto&quot;&gt;&lt;strong&gt;Boost.HTTP.Proto&lt;/strong&gt;&lt;/a&gt; library, we
recognized the need for a flexible mechanism to install and access optional
services at runtime without requiring prior knowledge of their specific
implementations. For example, building a library with optional support
for zlib and Brotli compression, even if those libraries weren’t installed on
the user’s machine. This challenge led to the creation of
&lt;a href=&quot;https://github.com/cppalliance/rts&quot;&gt;&lt;strong&gt;Boost.RunTimeServices&lt;/strong&gt;&lt;/a&gt;, a solution that
offers several key benefits to both library developers and users, which I will
briefly outline below.&lt;/p&gt;

&lt;h4 id=&quot;libraries-with-no-configuration-macros&quot;&gt;Libraries With No Configuration Macros&lt;/h4&gt;

&lt;p&gt;One approach to managing optional dependencies in libraries is to use
configuration macros at build time, such as &lt;code&gt;BOOST_HTTP_PROTO_HAS_ZLIB&lt;/code&gt; or
&lt;code&gt;BOOST_COOKIES_HAS_PSL&lt;/code&gt;. However, this approach has major drawbacks:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Combinatorial explosion of binary variants.&lt;/li&gt;
  &lt;li&gt;Users can’t easily determine which features are enabled in a binary.&lt;/li&gt;
  &lt;li&gt;Configuration macros leak into downstream libraries, compounding complexity.&lt;/li&gt;
  &lt;li&gt;Changing features requires full rebuilds of all dependent code.&lt;/li&gt;
  &lt;li&gt;Difficult to distribute a single binary via package managers.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;With &lt;strong&gt;Boost.RunTimeServices&lt;/strong&gt;, configuration macros become unnecessary.
Features can be queried and installed at runtime. For example, installing an
optional zlib inflate service:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-CPP&quot;&gt;rts::context rts_ctx;
rts::zlib::install_inflate_service(rts_ctx);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then, a library can conditionally use the service:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-CPP&quot;&gt;if(cfg.decompression)
{
  auto&amp;amp; svc = ctx.get_service&amp;lt;rts::zlib::inflate_service&amp;gt;();
  svc.inflate(stream, rts::zlib::flush::finish);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&quot;smaller-binaries-by-stripping-unused-features&quot;&gt;Smaller Binaries by Stripping Unused Features&lt;/h4&gt;

&lt;p&gt;Since service interfaces are decoupled from implementations, unused services and
their dependencies can be eliminated by the linker. For example the following is
part of the implementation of &lt;code&gt;rts::zlib::inflate_service&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-CPP&quot;&gt;class inflate_service_impl
    : public inflate_service
{
public:
    using key_type = inflate_service;

    int
    init2(stream&amp;amp; st, int windowBits) const override
    {
        stream_cast sc(st);
        return inflateInit2(sc.get(), windowBits);
    }

    int
    inflate(stream&amp;amp; st, int flush) const override
    {
        stream_cast sc(st);
        return ::inflate(sc.get(), flush);
    }

    // ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The implementation class is only instantiated within:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-CPP&quot;&gt;inflate_service&amp;amp;
install_inflate_service(context&amp;amp; ctx)
{
    return ctx.make_service&amp;lt;inflate_service_impl&amp;gt;();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Libraries interact only with the abstract interface:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-CPP&quot;&gt;struct BOOST_SYMBOL_VISIBLE
inflate_service
    : public service
{
    virtual int init2(stream&amp;amp; st, int windowBits) const = 0;
    virtual int inflate(stream&amp;amp; st, int flush) const = 0;
    // ...
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If the user never calls &lt;code&gt;install_inflate_service&lt;/code&gt;, the implementation and its
dependencies are omitted from the binary.&lt;/p&gt;

&lt;p&gt;In this particular example, having separate services for inflation and deflation
gives us more granularity on the matter. For instance, a client
application that uses &lt;strong&gt;Boost.HTTP.Proto&lt;/strong&gt; will more likely only need to install
&lt;code&gt;rts::zlib::inflate_service&lt;/code&gt;, because it typically only needs to parse
compressed HTTP response messages and compression of HTTP requests almost never
happens in client applications. The reverse is true for server applications and
they might only need to install &lt;code&gt;rts::zlib::deflate_service&lt;/code&gt;, since client
requests usually arrive uncompressed and the server needs to compress responses
(if requested).&lt;/p&gt;

&lt;h4 id=&quot;libraries-built-independent-of-the-availability-of-optional-services&quot;&gt;Libraries Built Independent of the Availability of Optional Services&lt;/h4&gt;

&lt;p&gt;Because a library that uses an optional service needs only the interface of that
service, there is no need for a build-time dependency. Therefore, we can always
build a single version of a library that takes advantage of all optional
services if they are available at runtime.&lt;/p&gt;

&lt;p&gt;For example, in the case of &lt;strong&gt;Boost.HTTP.Proto&lt;/strong&gt;, one can use the library
without any compression services, as users simply don’t install those services
and there’s no need to link any extra libraries.&lt;/p&gt;

&lt;p&gt;Another user can use the exact same binary of &lt;strong&gt;Boost.HTTP.Proto&lt;/strong&gt; with zlib and
Brotli decompression algorithms:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-CPP&quot;&gt;rts::context rts_ctx;
rts::zlib::install_inflate_service(rts_ctx); // links against boost_rts_zlib
rts::brotli::install_decoder_service(rts_ctx); // links against boost_rts_brotli
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&quot;optional-services-in-downstream-libraries&quot;&gt;Optional Services in Downstream Libraries&lt;/h4&gt;

&lt;p&gt;Assume we want to create a library named &lt;strong&gt;Boost.Request&lt;/strong&gt; that uses
&lt;strong&gt;Boost.HTTP.Proto&lt;/strong&gt; and &lt;strong&gt;Boost.HTTP.IO&lt;/strong&gt;, and provides an easy-to-use
interface for client-side usage. Such a library doesn’t need to care about
optional services and can delegate that responsibility to the end user, allowing
them to decide which services to install. For example, &lt;strong&gt;Boost.Request&lt;/strong&gt; can
internally query the availability of these services and make requests
accordingly:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-CPP&quot;&gt;if(rts_ctx.has_service&amp;lt;brotli::decoder_service&amp;gt;())
    encodings.append(&quot;br&quot;);

if(rts_ctx.has_service&amp;lt;zlib::inflate_service&amp;gt;())
{
    encodings.append(&quot;deflate&quot;);
    encodings.append(&quot;gzip&quot;);
}

if(!accept_encoding.empty())
    request.set(field::accept_encoding, encodings.str());
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;why-this-needs-to-be-a-separate-library&quot;&gt;Why This Needs to Be a Separate Library&lt;/h2&gt;

&lt;p&gt;This is a core library that many other libraries may want to use. For example, a
user who installs zlib services expects them to be usable in both
&lt;strong&gt;Boost.HTTP.Proto&lt;/strong&gt; and &lt;strong&gt;Boost.WS.Proto&lt;/strong&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;rts::context rts_ctx;
rts::zlib::install_inflate_service(rts_ctx);
rts::zlib::install_deflate_service(rts_ctx);

// Usage site
http_proto::parser parser(rts_ctx);
ws_proto::stream stream(rts_ctx);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;User libraries need to link against &lt;code&gt;boost_rts&lt;/code&gt; in order to access
&lt;code&gt;rts::context&lt;/code&gt;. Note that &lt;code&gt;boost_rts&lt;/code&gt; is a lightweight target with no dependency
on optional services like zlib or Brotli.&lt;/p&gt;

&lt;h2 id=&quot;existing-challenges&quot;&gt;Existing Challenges&lt;/h2&gt;

&lt;h4 id=&quot;minimum-library-for-mandatory-symbols&quot;&gt;Minimum Library For Mandatory Symbols&lt;/h4&gt;

&lt;p&gt;A library that uses an optional service might still need to link against a
minimal version that provides necessary symbols such as &lt;code&gt;error_category&lt;/code&gt;
instances, because we usually need to instantiate them inside the source and
can’t leave them in headers.&lt;/p&gt;

&lt;p&gt;For example, assume a library that needs to call an API to provide the error
message:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-CPP&quot;&gt;char const*
error_cat_type::
message(
    int ev,
    char*,
    std::size_t) const noexcept
{
    return c_api_get_error_message(ev);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This clearly can’t be left in the headers because it would require the existence
of the &lt;code&gt;c_api_get_error_message&lt;/code&gt; symbol at link time, which defeats the purpose
of optional services.&lt;/p&gt;

&lt;p&gt;To allow optional linkage, a fallback could be provided:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-CPP&quot;&gt;char const*
error_cat_type::
message(
    int ev,
    char*,
    std::size_t) const noexcept
{
    return &quot;service not available&quot;;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;But the remaining question is: where should this implementation go if we want
optional linkage against services? Currently, we place this code inside the core
&lt;strong&gt;Boost.RunTimeServices&lt;/strong&gt; library, which could become a scalability problem in
the future as the number of services grows.&lt;/p&gt;

&lt;h4 id=&quot;an-even-finer-grain-control-over-used-and-unused-symbols&quot;&gt;An Even Finer Grain Control Over Used and Unused Symbols&lt;/h4&gt;

&lt;p&gt;Even though separate services (e.g., &lt;code&gt;inflate_service&lt;/code&gt;, &lt;code&gt;deflate_service&lt;/code&gt;) help
the linker remove unused code; the granularity is still limited. For example, if
a library uses only &lt;code&gt;inflate_service::init&lt;/code&gt;, the linker still includes
&lt;code&gt;inflate_service::init2&lt;/code&gt; and other unused methods. This is because interfaces are
polymorphic and the linker can’t remove individual virtual methods:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-CPP&quot;&gt;class inflate_service_impl
    : public inflate_service
{
public:
    using key_type = inflate_service;

    int
    init(stream&amp;amp; st) const override
    {
        stream_cast sc(st);
        return inflateInit(sc.get());
    }

    int
    init2(stream&amp;amp; st, int windowBits) const override
    {
        stream_cast sc(st);
        return inflateInit2(sc.get(), windowBits);
    }

    // ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&quot;space-overhead-and-indirection-cost-of-virtual-services&quot;&gt;Space Overhead and Indirection Cost of Virtual Services&lt;/h4&gt;

&lt;p&gt;This is probably not an issue for most users, as these costs are negligible in
real-world applications. However, a solution that provides the same
functionality as virtual service interfaces but without these overheads would be
highly desirable.&lt;/p&gt;</content><author><name></name></author><category term="mohammad" /><summary type="html">How Boost.RunTimeServices Emerged from Boost.HTTP.Proto Development During the development of the Boost.HTTP.Proto library, we recognized the need for a flexible mechanism to install and access optional services at runtime without requiring prior knowledge of their specific implementations. For example, building a library with optional support for zlib and Brotli compression, even if those libraries weren’t installed on the user’s machine. This challenge led to the creation of Boost.RunTimeServices, a solution that offers several key benefits to both library developers and users, which I will briefly outline below. Libraries With No Configuration Macros One approach to managing optional dependencies in libraries is to use configuration macros at build time, such as BOOST_HTTP_PROTO_HAS_ZLIB or BOOST_COOKIES_HAS_PSL. However, this approach has major drawbacks: Combinatorial explosion of binary variants. Users can’t easily determine which features are enabled in a binary. Configuration macros leak into downstream libraries, compounding complexity. Changing features requires full rebuilds of all dependent code. Difficult to distribute a single binary via package managers. With Boost.RunTimeServices, configuration macros become unnecessary. Features can be queried and installed at runtime. For example, installing an optional zlib inflate service: rts::context rts_ctx; rts::zlib::install_inflate_service(rts_ctx); Then, a library can conditionally use the service: if(cfg.decompression) { auto&amp;amp; svc = ctx.get_service&amp;lt;rts::zlib::inflate_service&amp;gt;(); svc.inflate(stream, rts::zlib::flush::finish); } Smaller Binaries by Stripping Unused Features Since service interfaces are decoupled from implementations, unused services and their dependencies can be eliminated by the linker. For example the following is part of the implementation of rts::zlib::inflate_service: class inflate_service_impl : public inflate_service { public: using key_type = inflate_service; int init2(stream&amp;amp; st, int windowBits) const override { stream_cast sc(st); return inflateInit2(sc.get(), windowBits); } int inflate(stream&amp;amp; st, int flush) const override { stream_cast sc(st); return ::inflate(sc.get(), flush); } // ... } The implementation class is only instantiated within: inflate_service&amp;amp; install_inflate_service(context&amp;amp; ctx) { return ctx.make_service&amp;lt;inflate_service_impl&amp;gt;(); } Libraries interact only with the abstract interface: struct BOOST_SYMBOL_VISIBLE inflate_service : public service { virtual int init2(stream&amp;amp; st, int windowBits) const = 0; virtual int inflate(stream&amp;amp; st, int flush) const = 0; // ... }; If the user never calls install_inflate_service, the implementation and its dependencies are omitted from the binary. In this particular example, having separate services for inflation and deflation gives us more granularity on the matter. For instance, a client application that uses Boost.HTTP.Proto will more likely only need to install rts::zlib::inflate_service, because it typically only needs to parse compressed HTTP response messages and compression of HTTP requests almost never happens in client applications. The reverse is true for server applications and they might only need to install rts::zlib::deflate_service, since client requests usually arrive uncompressed and the server needs to compress responses (if requested). Libraries Built Independent of the Availability of Optional Services Because a library that uses an optional service needs only the interface of that service, there is no need for a build-time dependency. Therefore, we can always build a single version of a library that takes advantage of all optional services if they are available at runtime. For example, in the case of Boost.HTTP.Proto, one can use the library without any compression services, as users simply don’t install those services and there’s no need to link any extra libraries. Another user can use the exact same binary of Boost.HTTP.Proto with zlib and Brotli decompression algorithms: rts::context rts_ctx; rts::zlib::install_inflate_service(rts_ctx); // links against boost_rts_zlib rts::brotli::install_decoder_service(rts_ctx); // links against boost_rts_brotli Optional Services in Downstream Libraries Assume we want to create a library named Boost.Request that uses Boost.HTTP.Proto and Boost.HTTP.IO, and provides an easy-to-use interface for client-side usage. Such a library doesn’t need to care about optional services and can delegate that responsibility to the end user, allowing them to decide which services to install. For example, Boost.Request can internally query the availability of these services and make requests accordingly: if(rts_ctx.has_service&amp;lt;brotli::decoder_service&amp;gt;()) encodings.append(&quot;br&quot;); if(rts_ctx.has_service&amp;lt;zlib::inflate_service&amp;gt;()) { encodings.append(&quot;deflate&quot;); encodings.append(&quot;gzip&quot;); } if(!accept_encoding.empty()) request.set(field::accept_encoding, encodings.str()); Why This Needs to Be a Separate Library This is a core library that many other libraries may want to use. For example, a user who installs zlib services expects them to be usable in both Boost.HTTP.Proto and Boost.WS.Proto: rts::context rts_ctx; rts::zlib::install_inflate_service(rts_ctx); rts::zlib::install_deflate_service(rts_ctx); // Usage site http_proto::parser parser(rts_ctx); ws_proto::stream stream(rts_ctx); User libraries need to link against boost_rts in order to access rts::context. Note that boost_rts is a lightweight target with no dependency on optional services like zlib or Brotli. Existing Challenges Minimum Library For Mandatory Symbols A library that uses an optional service might still need to link against a minimal version that provides necessary symbols such as error_category instances, because we usually need to instantiate them inside the source and can’t leave them in headers. For example, assume a library that needs to call an API to provide the error message: char const* error_cat_type:: message( int ev, char*, std::size_t) const noexcept { return c_api_get_error_message(ev); } This clearly can’t be left in the headers because it would require the existence of the c_api_get_error_message symbol at link time, which defeats the purpose of optional services. To allow optional linkage, a fallback could be provided: char const* error_cat_type:: message( int ev, char*, std::size_t) const noexcept { return &quot;service not available&quot;; } But the remaining question is: where should this implementation go if we want optional linkage against services? Currently, we place this code inside the core Boost.RunTimeServices library, which could become a scalability problem in the future as the number of services grows. An Even Finer Grain Control Over Used and Unused Symbols Even though separate services (e.g., inflate_service, deflate_service) help the linker remove unused code; the granularity is still limited. For example, if a library uses only inflate_service::init, the linker still includes inflate_service::init2 and other unused methods. This is because interfaces are polymorphic and the linker can’t remove individual virtual methods: class inflate_service_impl : public inflate_service { public: using key_type = inflate_service; int init(stream&amp;amp; st) const override { stream_cast sc(st); return inflateInit(sc.get()); } int init2(stream&amp;amp; st, int windowBits) const override { stream_cast sc(st); return inflateInit2(sc.get(), windowBits); } // ... } Space Overhead and Indirection Cost of Virtual Services This is probably not an issue for most users, as these costs are negligible in real-world applications. However, a solution that provides the same functionality as virtual service interfaces but without these overheads would be highly desirable.</summary></entry><entry><title type="html">Bigger, Faster, Stronger Types</title><link href="http://cppalliance.org/matt/2025/07/14/Matts2025Q2Update.html" rel="alternate" type="text/html" title="Bigger, Faster, Stronger Types" /><published>2025-07-14T00:00:00+00:00</published><updated>2025-07-14T00:00:00+00:00</updated><id>http://cppalliance.org/matt/2025/07/14/Matts2025Q2Update</id><content type="html" xml:base="http://cppalliance.org/matt/2025/07/14/Matts2025Q2Update.html">&lt;p&gt;We continue to make exciting progress developing new libraries for inclusion in Boost, and expanding those already available.&lt;/p&gt;

&lt;h1 id=&quot;new-libraries&quot;&gt;New Libraries&lt;/h1&gt;

&lt;h2 id=&quot;int128&quot;&gt;int128&lt;/h2&gt;

&lt;p&gt;Int128 (&lt;a href=&quot;https://github.com/cppalliance/int128&quot;&gt;https://github.com/cppalliance/int128&lt;/a&gt;) is a small library that has more or less fallen out of work on Decimal.
It provides two type: an unsigned 128-bit integer and a signed 128-bit integer.
Since my last post the library should now be ready for beta, and subsequently production use.
Much effort was put into optimizing every operation on a multitude of architectures.
The documentation includes bar charts showing the performance of our types vs Boost.Multiprecision, and built-in types (if available).
While orgianlly envisioned as just an improvement to the Decimal backend arithmetic, I think this has much more additional usefulness.&lt;/p&gt;

&lt;h2 id=&quot;decimal&quot;&gt;Decimal&lt;/h2&gt;

&lt;p&gt;Decimal (&lt;a href=&quot;https://github.com/cppalliance/decimal&quot;&gt;https://github.com/cppalliance/decimal&lt;/a&gt;) is a ground-up implementation of IEEE 754 Decimal Floating Point types in C++14, co-authored with Chris Kormanyos.
In January we had our formal review for inclusion in Boost.
As int128 above became more production ready we have integrated it into Decimal as a new backend integer type.
Not only do we now use the int128 as a backend, we were able to find a few bugs in integration due to the special functions test suite in Decimal.
The relationship during co-development has worked out really well.
We also recently merged a new 256-bit integer backend based on developments and lessons learned from &lt;code&gt;int128&lt;/code&gt;.
These combined have given us &amp;gt;100% speedups for the 128-bit types, and also benefit the 64-bit types to a lesser degree.
Discussions are ongoing in the Cpplang Slack channel &lt;code&gt;#boost-decimal&lt;/code&gt;.&lt;/p&gt;

&lt;h1 id=&quot;existing-libraries&quot;&gt;Existing Libraries&lt;/h1&gt;

&lt;h2 id=&quot;math&quot;&gt;Math&lt;/h2&gt;

&lt;p&gt;As posted a few versions ago Boost.Math began offering support to be run on GPU with NVCC, NVRTC, and SYCL.
We have recieved a few bug reports now that this functionallity is being used more.
For Boost 1.89 we have put good effort into fixes and internal restructuring to address the issues that people have been having.&lt;/p&gt;

&lt;h2 id=&quot;multiprecision&quot;&gt;Multiprecision&lt;/h2&gt;

&lt;p&gt;For the first time in a while Boost.Multiprecision has a new backend type: &lt;code&gt;cpp_double_fp_backend&lt;/code&gt;.
This project was started during GSoC 2021 and has finally come to full fruition.
The &lt;code&gt;cpp_double_fp_backend&lt;/code&gt; back-end is the sum of two IEEE floating-point numbers combined to create a type having roughly twice the composite width of one of its parts.
The &lt;code&gt;cpp_double_fp_backend&lt;/code&gt; back-end is used in conjunction with &lt;code&gt;number&lt;/code&gt; and acts as an entirely C++ header only floating-point number type.
If you need more precision than a &lt;code&gt;double&lt;/code&gt; with less computational expense than arbitrary precision types look out for this in Boost 1.89.&lt;/p&gt;</content><author><name></name></author><category term="matt" /><summary type="html">We continue to make exciting progress developing new libraries for inclusion in Boost, and expanding those already available. New Libraries int128 Int128 (https://github.com/cppalliance/int128) is a small library that has more or less fallen out of work on Decimal. It provides two type: an unsigned 128-bit integer and a signed 128-bit integer. Since my last post the library should now be ready for beta, and subsequently production use. Much effort was put into optimizing every operation on a multitude of architectures. The documentation includes bar charts showing the performance of our types vs Boost.Multiprecision, and built-in types (if available). While orgianlly envisioned as just an improvement to the Decimal backend arithmetic, I think this has much more additional usefulness. Decimal Decimal (https://github.com/cppalliance/decimal) is a ground-up implementation of IEEE 754 Decimal Floating Point types in C++14, co-authored with Chris Kormanyos. In January we had our formal review for inclusion in Boost. As int128 above became more production ready we have integrated it into Decimal as a new backend integer type. Not only do we now use the int128 as a backend, we were able to find a few bugs in integration due to the special functions test suite in Decimal. The relationship during co-development has worked out really well. We also recently merged a new 256-bit integer backend based on developments and lessons learned from int128. These combined have given us &amp;gt;100% speedups for the 128-bit types, and also benefit the 64-bit types to a lesser degree. Discussions are ongoing in the Cpplang Slack channel #boost-decimal. Existing Libraries Math As posted a few versions ago Boost.Math began offering support to be run on GPU with NVCC, NVRTC, and SYCL. We have recieved a few bug reports now that this functionallity is being used more. For Boost 1.89 we have put good effort into fixes and internal restructuring to address the issues that people have been having. Multiprecision For the first time in a while Boost.Multiprecision has a new backend type: cpp_double_fp_backend. This project was started during GSoC 2021 and has finally come to full fruition. The cpp_double_fp_backend back-end is the sum of two IEEE floating-point numbers combined to create a type having roughly twice the composite width of one of its parts. The cpp_double_fp_backend back-end is used in conjunction with number and acts as an entirely C++ header only floating-point number type. If you need more precision than a double with less computational expense than arbitrary precision types look out for this in Boost 1.89.</summary></entry><entry><title type="html">Bringing B2-Style Test Granularity to CMake</title><link href="http://cppalliance.org/alan/2025/07/10/Alan.html" rel="alternate" type="text/html" title="Bringing B2-Style Test Granularity to CMake" /><published>2025-07-10T00:00:00+00:00</published><updated>2025-07-10T00:00:00+00:00</updated><id>http://cppalliance.org/alan/2025/07/10/Alan</id><content type="html" xml:base="http://cppalliance.org/alan/2025/07/10/Alan.html">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;Boost libraries typically maintain granular unit tests using Boost.Build (B2). B2 provides a &lt;code&gt;run&lt;/code&gt; rule that makes it easy to define many independent test targets from a single source file or executable. Each test case can be listed, invoked, and reported separately, which improves developer workflow, test clarity, and CI diagnostics.&lt;/p&gt;

&lt;p&gt;However, Boost’s CMake integration has lacked this granularity. When Boost libraries are built with CMake, the typical approach is to define a single test executable and add all test suites as a single test in CTest with &lt;code&gt;add_test()&lt;/code&gt;. As a result, when running tests with CTest, developers lose the ability to see individual test failures in isolation, run only subsets of tests, or leverage parallel execution at the test level.&lt;/p&gt;

&lt;p&gt;The goal of this work is to bridge that gap. We want to replicate the B2 “one executable, many independent tests” idiom in CMake. Specifically, we want to use modern CMake techniques to split a single unit test executable into multiple independent CTest targets, while preserving the flexibility and simplicity of the Boost testing style.&lt;/p&gt;

&lt;h1 id=&quot;problem-analysis&quot;&gt;Problem Analysis&lt;/h1&gt;

&lt;p&gt;To understand why splitting tests into independent CTest targets is non-trivial, it helps to look at &lt;strong&gt;how CMake’s build and test model is structured&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;When building and testing libraries with CMake, the developer usually has a workflow of four key phases:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Configuration step&lt;/strong&gt;: This is where CMakeLists.txt files are processed and commands like &lt;code&gt;add_executable&lt;/code&gt; and &lt;code&gt;add_test()&lt;/code&gt; are called. Test targets must be defined here, so CTest knows about them.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Build step&lt;/strong&gt;: This is when the underlying build system (the CMake “generator”: e.g., Ninja or Make) compiles sources and produces executables, including unit test binaries.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Test step&lt;/strong&gt;: This is when &lt;code&gt;ctest&lt;/code&gt; runs the defined tests, using the executables built in the previous step.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Installation step&lt;/strong&gt;: This is where the built libraries and executables are installed to their final locations. This step is not directly relevant to the problem at hand, but it’s part of the overall CMake workflow.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;At the configuration step, we would like to have something like&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-cmake&quot;&gt;add_test(NAME test_a COMMAND my_unit_test_executable a)
add_test(NAME test_b COMMAND my_unit_test_executable b)
add_test(NAME test_c COMMAND my_unit_test_executable c)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;instead of&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-cmake&quot;&gt;add_test(NAME my_unit_test_executable COMMAND my_unit_test_executable)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The fundamental obstacle is that, in the general case, &lt;strong&gt;you cannot know what tests exist inside a unit test executable until you can &lt;em&gt;run&lt;/em&gt; it&lt;/strong&gt;. Many modern test frameworks (like Boost.Test, Catch2, GoogleTest) support listing their available tests by running the executable with a special argument (e.g., &lt;code&gt;--list-tests&lt;/code&gt;). But this only works &lt;em&gt;after&lt;/em&gt; the executable is built.&lt;/p&gt;

&lt;p&gt;In other words:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;You need the executable to discover the tests, but CMake requires you to declare the tests in the configuration phase before building the executable in the build step.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This dependency cycle is the core problem that makes it difficult to reproduce B2’s &lt;code&gt;run&lt;/code&gt; rule semantics in CMake. Without special handling, you’re forced to treat the entire unit test binary as a single test, losing the ability to register its internal test cases as independent CTest targets.&lt;/p&gt;

&lt;p&gt;The solution to this problem involves the &lt;a href=&quot;https://cmake.org/cmake/help/latest/prop_dir/TEST_INCLUDE_FILES.html&quot;&gt;&lt;code&gt;TEST_INCLUDE_FILES&lt;/code&gt;&lt;/a&gt; directory property, which allows you to specify additional files that CTest should consider when running tests. By leveraging this property, we can dynamically generate a CMake script that defines individual &lt;code&gt;add_test()&lt;/code&gt; calls for each test case found in the unit test executable.&lt;/p&gt;

&lt;p&gt;So we can use&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-cmake&quot;&gt;set_property(DIRECTORY
    APPEND PROPERTY TEST_INCLUDE_FILES &quot;${TEST_SUITE_CTEST_INCLUDE_FILE}&quot;
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to include a generated CMake script that contains the individual test definitions. This allows us to run the executable post-build, extract the test names, and then register them with CTest in a way that mimics the B2 experience. Other modern test frameworks have explored this feature to provide an automated test discovery mechanism for their libraries in CMake. For example, Catch2’s &lt;code&gt;catch_discover_tests()&lt;/code&gt; and GoogleTest’s &lt;code&gt;gtest_discover_tests()&lt;/code&gt; run the built test executable with a listing flag (like &lt;code&gt;--list-tests&lt;/code&gt;) to extract individual test cases and generate separate &lt;code&gt;add_test()&lt;/code&gt; entries for each.&lt;/p&gt;

&lt;h1 id=&quot;design-overview&quot;&gt;Design Overview&lt;/h1&gt;

&lt;p&gt;Since CMake requires test registration in the configuration step, but we can only discover test cases &lt;em&gt;after&lt;/em&gt; building the executable, we introduce an approach to bridge that gap. The high-level plan is:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Build the executable&lt;/strong&gt;: Compile the unit test executable as usual. The target is defined in the configuration step and built in the build step.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Post-build step&lt;/strong&gt;: After building, run the executable with &lt;code&gt;--list-tests&lt;/code&gt; (or equivalent) to enumerate all available test cases. This is achieved with a custom command that runs after the build completes.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Generate a CMake script&lt;/strong&gt;: This post-build step writes a &lt;code&gt;.cmake&lt;/code&gt; file containing one &lt;code&gt;add_test()&lt;/code&gt; call for each discovered test case.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Conditional inclusion&lt;/strong&gt;: The main CMake configuration includes this generated script &lt;em&gt;only if it exists&lt;/em&gt;, so the tests appear in CTest after they’re generated. The new script is included using the &lt;code&gt;TEST_INCLUDE_FILES&lt;/code&gt; property, which allows CTest to pick it up automatically.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This approach effectively moves test discovery to the build phase while still registering the resulting tests with CTest in the configuration phase for subsequent runs.&lt;/p&gt;

&lt;p&gt;This process is transparent to the user. In Boost.URL, where we implemented the functionality, the test registration process went from:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-cmake&quot;&gt;add_test(NAME boost_url_unit_tests COMMAND boost_url_unit_tests)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-cmake&quot;&gt;boost_url_test_suite_discover_tests(boost_url_unit_tests)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&quot;implementation-details&quot;&gt;Implementation Details&lt;/h1&gt;

&lt;p&gt;This section describes the approach bottom-up, showing the overall mechanism of discovering and registering independent test targets in CMake.&lt;/p&gt;

&lt;h2 id=&quot;the-test-listing-extractor-script&quot;&gt;The Test Listing Extractor Script&lt;/h2&gt;

&lt;p&gt;The first piece is a small CMake script that &lt;strong&gt;runs the compiled test executable&lt;/strong&gt; with &lt;code&gt;--list-tests&lt;/code&gt; (or an equivalent flag your test framework supports). It captures the output, which is expected to be a plain list of test case names.&lt;/p&gt;

&lt;p&gt;For example, suppose your unit test executable outputs:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-cmake&quot;&gt;UnitA.TestAlpha
UnitA.TestBeta
UnitB.TestGamma
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The script saves these names so they can be transformed into separate CTest targets.&lt;/p&gt;

&lt;p&gt;Example command in CMake:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-cmake&quot;&gt;execute_process(
        COMMAND &quot;${TEST_SUITE_TEST_EXECUTABLE}&quot; ${TEST_SUITE_TEST_SPEC} --list-tests
        OUTPUT_VARIABLE TEST_SUITE_LIST_TESTS_OUTPUT
        ERROR_VARIABLE TEST_SUITE_LIST_TESTS_OUTPUT
        RESULT_VARIABLE TEST_SUITE_RESULT
        WORKING_DIRECTORY &quot;${TEST_SUITE_TEST_WORKING_DIR}&quot;
)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;generator-of-cmake-test-definitions&quot;&gt;Generator of CMake Test Definitions&lt;/h2&gt;

&lt;p&gt;Once the list of tests is available, the script generates a new &lt;code&gt;.cmake&lt;/code&gt; file containing one &lt;code&gt;add_test()&lt;/code&gt; call per discovered test. This file effectively defines the independent CTest targets.&lt;/p&gt;

&lt;p&gt;Example generated &lt;code&gt;tests.cmake&lt;/code&gt; content:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-cmake&quot;&gt;add_test(NAME UnitA.TestAlpha COMMAND my_test_executable UnitA.TestAlpha)
add_test(NAME UnitA.TestBeta COMMAND my_test_executable UnitA.TestBeta)
add_test(NAME UnitB.TestGamma COMMAND my_test_executable UnitB.TestGamma)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This approach ensures each test is addressable, selectable, and independently reported by CTest.&lt;/p&gt;

&lt;h2 id=&quot;post-build-step-integration&quot;&gt;Post-Build Step Integration&lt;/h2&gt;

&lt;p&gt;CMake can’t know these test names at configuration time, so we hook the test listing step to the build phase using a &lt;code&gt;POST_BUILD&lt;/code&gt; custom command. After the test executable is built, this command runs the extractor and generates the script file defining the tests.&lt;/p&gt;

&lt;p&gt;Example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-cmake&quot;&gt;add_custom_command(
        # The executable target with the unit tests
        TARGET ${TARGET}
        POST_BUILD
        BYPRODUCTS &quot;${TEST_SUITE_CTEST_TESTS_FILE}&quot;
        # Run the CMake script to discover tests after the build step
        COMMAND &quot;${CMAKE_COMMAND}&quot;
        # Arguments to the script
        -D &quot;TEST_TARGET=${TARGET}&quot;
        -D &quot;TEST_EXECUTABLE=$&amp;lt;TARGET_FILE:${TARGET}&amp;gt;&quot;
        -D &quot;TEST_WORKING_DIR=${TEST_SUITE_WORKING_DIRECTORY}&quot;
        # ...
        # The output file where the test definitions will be written
        -D &quot;CTEST_FILE=${TEST_SUITE_CTEST_TESTS_FILE}&quot;
        # The script that generates the test definitions
        -P &quot;${TEST_SUITE_DISCOVER_AND_WRITE_TESTS_SCRIPT}&quot;
        VERBATIM
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This ensures the test listing happens automatically as part of the build.&lt;/p&gt;

&lt;h2 id=&quot;including-generated-tests&quot;&gt;Including Generated Tests&lt;/h2&gt;

&lt;p&gt;The main CMake configuration includes the generated &lt;code&gt;.cmake&lt;/code&gt; file, but only if it exists. This avoids errors on a test pass before the executable is built. This could happen because the user is calling &lt;code&gt;ctest&lt;/code&gt; before the build step completes, because the test executable was not built, or because the cache was invalidated.&lt;/p&gt;

&lt;p&gt;So the discovery function uses the example pattern:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-cmake&quot;&gt;if(EXISTS &quot;${CMAKE_BINARY_DIR}/generated/tests.cmake&quot;)
    include(&quot;${CMAKE_BINARY_DIR}/generated/tests.cmake&quot;)
endif()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And this is the file that the test step will ultimately include in the CTest run, allowing CTest to see all the individual test targets.&lt;/p&gt;

&lt;h2 id=&quot;cmake-function-for-reuse&quot;&gt;CMake Function for Reuse&lt;/h2&gt;

&lt;p&gt;To make this easy for other libraries, the pattern can be wrapped in a CMake function. This function:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Defines the &lt;code&gt;POST_BUILD&lt;/code&gt; rule for the given target.&lt;/li&gt;
  &lt;li&gt;Encapsulates the details of running the extractor script.&lt;/li&gt;
  &lt;li&gt;Ensures consistent output locations for the generated test definitions.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Example usage:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-cmake&quot;&gt;boost_url_test_suite_discover_tests(boost_url_unit_tests)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This approach lets library maintainers adopt the system with minimal changes to their existing CMake setup, while maintaining Boost’s fine-grained, many-target test philosophy.&lt;/p&gt;

&lt;p&gt;When we look at CI results for Boost.URL, this is the only thing we used to have:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  /__w/_tool/cmake/3.20.0/x64/bin/ctest --test-dir /__w/url/boost-root/build_cmake --parallel 4 --no-tests=error --progress --output-on-failure
  Internal ctest changing into directory: /__w/url/boost-root/build_cmake
  Test project /__w/url/boost-root/build_cmake
      Start 1: boost_url_unit_tests
      Start 2: boost_url_extra
      Start 3: boost_url_limits
  1/3 Test #2: boost_url_extra ..................   Passed    0.00 sec
  2/3 Test #3: boost_url_limits .................   Passed    0.00 sec
  3/3 Test #1: boost_url_unit_tests .............   Passed    0.02 sec
  
  100% tests passed, 0 tests failed out of 3
  
  Total Test time (real) =   0.02 sec
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And now we see one unit test per test case:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  /__w/_tool/cmake/3.20.0/x64/bin/ctest --test-dir /__w/url/boost-root/build_cmake --parallel 4 --no-tests=error --progress --output-on-failure
  Internal ctest changing into directory: /__w/url/boost-root/build_cmake
  Test project /__w/url/boost-root/build_cmake
        Start  1: boost.url.absolute_uri_rule
        Start  2: boost.url.authority_rule
        Start  3: boost.url.authority_view
        Start  4: boost.url.compat.ada
   1/76 Test  #1: boost.url.absolute_uri_rule ..........   Passed    0.01 sec
        Start  5: boost.url.decode_view
   2/76 Test  #2: boost.url.authority_rule .............   Passed    0.01 sec
        Start  6: boost.url.doc.3_urls
   3/76 Test  #3: boost.url.authority_view .............   Passed    0.01 sec
        Start  7: boost.url.doc.grammar
   4/76 Test  #5: boost.url.decode_view ................   Passed    0.01 sec
        Start  8: boost.url.encode
   5/76 Test  #4: boost.url.compat.ada .................   Passed    0.01 sec
        Start  9: boost.url.error
   6/76 Test  #6: boost.url.doc.3_urls .................   Passed    0.01 sec
        Start 10: boost.url.format
   7/76 Test  #7: boost.url.doc.grammar ................   Passed    0.01 sec
        Start 11: boost.url.gen_delim_chars
   8/76 Test  #8: boost.url.encode .....................   Passed    0.01 sec
        Start 12: boost.url.grammar.alnum_chars   
  ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;meaning that each test is now executed and reported individually and in parallel, allowing developers to see which specific tests passed or failed, and enabling more granular control over test execution.&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;This approach brings fine-grained tests into the modern CMake Boost workflow. By splitting a single test executable into multiple independent CTest targets, maintainers gain:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;More granular failure reporting&lt;/strong&gt;: CI logs show exactly which test case failed.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Better developer experience&lt;/strong&gt;: Developers can run or re-run individual tests easily.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Improved parallel execution&lt;/strong&gt;: Faster test runs in CI and locally.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Better IDE integration&lt;/strong&gt;: IDEs can show individual test cases.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For other Boost libraries considering adopting this pattern, the only requirement is that their test executables support a &lt;code&gt;--list-tests&lt;/code&gt; (or equivalent) command that outputs the available test cases. Once that’s available, the necessary CMake changes to define an equivalent function are minimal:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Add a &lt;code&gt;POST_BUILD&lt;/code&gt; step that runs the listing command and generates the &lt;code&gt;.cmake&lt;/code&gt; file.&lt;/li&gt;
  &lt;li&gt;Conditionally include that generated file in the main CMakeLists.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If the output of &lt;code&gt;--list-tests&lt;/code&gt; is one test suite per line, the existing script can be used as-is. This small investment pays off with a much more maintainable and CI-friendly testing setup. I encourage other maintainers and contributors to try this technique, refine it, and share feedback.&lt;/p&gt;

&lt;p&gt;The complete script and CMake snippets are available in the Boost.URL repository at commit &lt;a href=&quot;https://github.com/boostorg/url/commit/a1a5d18e9356036e446f98fc774eb1a1f5e242af&quot;&gt;#a1a5d18&lt;/a&gt;.&lt;/p&gt;</content><author><name></name></author><category term="alan" /><summary type="html">Introduction Boost libraries typically maintain granular unit tests using Boost.Build (B2). B2 provides a run rule that makes it easy to define many independent test targets from a single source file or executable. Each test case can be listed, invoked, and reported separately, which improves developer workflow, test clarity, and CI diagnostics. However, Boost’s CMake integration has lacked this granularity. When Boost libraries are built with CMake, the typical approach is to define a single test executable and add all test suites as a single test in CTest with add_test(). As a result, when running tests with CTest, developers lose the ability to see individual test failures in isolation, run only subsets of tests, or leverage parallel execution at the test level. The goal of this work is to bridge that gap. We want to replicate the B2 “one executable, many independent tests” idiom in CMake. Specifically, we want to use modern CMake techniques to split a single unit test executable into multiple independent CTest targets, while preserving the flexibility and simplicity of the Boost testing style. Problem Analysis To understand why splitting tests into independent CTest targets is non-trivial, it helps to look at how CMake’s build and test model is structured. When building and testing libraries with CMake, the developer usually has a workflow of four key phases: Configuration step: This is where CMakeLists.txt files are processed and commands like add_executable and add_test() are called. Test targets must be defined here, so CTest knows about them. Build step: This is when the underlying build system (the CMake “generator”: e.g., Ninja or Make) compiles sources and produces executables, including unit test binaries. Test step: This is when ctest runs the defined tests, using the executables built in the previous step. Installation step: This is where the built libraries and executables are installed to their final locations. This step is not directly relevant to the problem at hand, but it’s part of the overall CMake workflow. At the configuration step, we would like to have something like add_test(NAME test_a COMMAND my_unit_test_executable a) add_test(NAME test_b COMMAND my_unit_test_executable b) add_test(NAME test_c COMMAND my_unit_test_executable c) instead of add_test(NAME my_unit_test_executable COMMAND my_unit_test_executable) The fundamental obstacle is that, in the general case, you cannot know what tests exist inside a unit test executable until you can run it. Many modern test frameworks (like Boost.Test, Catch2, GoogleTest) support listing their available tests by running the executable with a special argument (e.g., --list-tests). But this only works after the executable is built. In other words: You need the executable to discover the tests, but CMake requires you to declare the tests in the configuration phase before building the executable in the build step. This dependency cycle is the core problem that makes it difficult to reproduce B2’s run rule semantics in CMake. Without special handling, you’re forced to treat the entire unit test binary as a single test, losing the ability to register its internal test cases as independent CTest targets. The solution to this problem involves the TEST_INCLUDE_FILES directory property, which allows you to specify additional files that CTest should consider when running tests. By leveraging this property, we can dynamically generate a CMake script that defines individual add_test() calls for each test case found in the unit test executable. So we can use set_property(DIRECTORY APPEND PROPERTY TEST_INCLUDE_FILES &quot;${TEST_SUITE_CTEST_INCLUDE_FILE}&quot; ) to include a generated CMake script that contains the individual test definitions. This allows us to run the executable post-build, extract the test names, and then register them with CTest in a way that mimics the B2 experience. Other modern test frameworks have explored this feature to provide an automated test discovery mechanism for their libraries in CMake. For example, Catch2’s catch_discover_tests() and GoogleTest’s gtest_discover_tests() run the built test executable with a listing flag (like --list-tests) to extract individual test cases and generate separate add_test() entries for each. Design Overview Since CMake requires test registration in the configuration step, but we can only discover test cases after building the executable, we introduce an approach to bridge that gap. The high-level plan is: Build the executable: Compile the unit test executable as usual. The target is defined in the configuration step and built in the build step. Post-build step: After building, run the executable with --list-tests (or equivalent) to enumerate all available test cases. This is achieved with a custom command that runs after the build completes. Generate a CMake script: This post-build step writes a .cmake file containing one add_test() call for each discovered test case. Conditional inclusion: The main CMake configuration includes this generated script only if it exists, so the tests appear in CTest after they’re generated. The new script is included using the TEST_INCLUDE_FILES property, which allows CTest to pick it up automatically. This approach effectively moves test discovery to the build phase while still registering the resulting tests with CTest in the configuration phase for subsequent runs. This process is transparent to the user. In Boost.URL, where we implemented the functionality, the test registration process went from: add_test(NAME boost_url_unit_tests COMMAND boost_url_unit_tests) to boost_url_test_suite_discover_tests(boost_url_unit_tests) Implementation Details This section describes the approach bottom-up, showing the overall mechanism of discovering and registering independent test targets in CMake. The Test Listing Extractor Script The first piece is a small CMake script that runs the compiled test executable with --list-tests (or an equivalent flag your test framework supports). It captures the output, which is expected to be a plain list of test case names. For example, suppose your unit test executable outputs: UnitA.TestAlpha UnitA.TestBeta UnitB.TestGamma The script saves these names so they can be transformed into separate CTest targets. Example command in CMake: execute_process( COMMAND &quot;${TEST_SUITE_TEST_EXECUTABLE}&quot; ${TEST_SUITE_TEST_SPEC} --list-tests OUTPUT_VARIABLE TEST_SUITE_LIST_TESTS_OUTPUT ERROR_VARIABLE TEST_SUITE_LIST_TESTS_OUTPUT RESULT_VARIABLE TEST_SUITE_RESULT WORKING_DIRECTORY &quot;${TEST_SUITE_TEST_WORKING_DIR}&quot; ) Generator of CMake Test Definitions Once the list of tests is available, the script generates a new .cmake file containing one add_test() call per discovered test. This file effectively defines the independent CTest targets. Example generated tests.cmake content: add_test(NAME UnitA.TestAlpha COMMAND my_test_executable UnitA.TestAlpha) add_test(NAME UnitA.TestBeta COMMAND my_test_executable UnitA.TestBeta) add_test(NAME UnitB.TestGamma COMMAND my_test_executable UnitB.TestGamma) This approach ensures each test is addressable, selectable, and independently reported by CTest. Post-Build Step Integration CMake can’t know these test names at configuration time, so we hook the test listing step to the build phase using a POST_BUILD custom command. After the test executable is built, this command runs the extractor and generates the script file defining the tests. Example: add_custom_command( # The executable target with the unit tests TARGET ${TARGET} POST_BUILD BYPRODUCTS &quot;${TEST_SUITE_CTEST_TESTS_FILE}&quot; # Run the CMake script to discover tests after the build step COMMAND &quot;${CMAKE_COMMAND}&quot; # Arguments to the script -D &quot;TEST_TARGET=${TARGET}&quot; -D &quot;TEST_EXECUTABLE=$&amp;lt;TARGET_FILE:${TARGET}&amp;gt;&quot; -D &quot;TEST_WORKING_DIR=${TEST_SUITE_WORKING_DIRECTORY}&quot; # ... # The output file where the test definitions will be written -D &quot;CTEST_FILE=${TEST_SUITE_CTEST_TESTS_FILE}&quot; # The script that generates the test definitions -P &quot;${TEST_SUITE_DISCOVER_AND_WRITE_TESTS_SCRIPT}&quot; VERBATIM ) This ensures the test listing happens automatically as part of the build. Including Generated Tests The main CMake configuration includes the generated .cmake file, but only if it exists. This avoids errors on a test pass before the executable is built. This could happen because the user is calling ctest before the build step completes, because the test executable was not built, or because the cache was invalidated. So the discovery function uses the example pattern: if(EXISTS &quot;${CMAKE_BINARY_DIR}/generated/tests.cmake&quot;) include(&quot;${CMAKE_BINARY_DIR}/generated/tests.cmake&quot;) endif() And this is the file that the test step will ultimately include in the CTest run, allowing CTest to see all the individual test targets. CMake Function for Reuse To make this easy for other libraries, the pattern can be wrapped in a CMake function. This function: Defines the POST_BUILD rule for the given target. Encapsulates the details of running the extractor script. Ensures consistent output locations for the generated test definitions. Example usage: boost_url_test_suite_discover_tests(boost_url_unit_tests) This approach lets library maintainers adopt the system with minimal changes to their existing CMake setup, while maintaining Boost’s fine-grained, many-target test philosophy. When we look at CI results for Boost.URL, this is the only thing we used to have: /__w/_tool/cmake/3.20.0/x64/bin/ctest --test-dir /__w/url/boost-root/build_cmake --parallel 4 --no-tests=error --progress --output-on-failure Internal ctest changing into directory: /__w/url/boost-root/build_cmake Test project /__w/url/boost-root/build_cmake Start 1: boost_url_unit_tests Start 2: boost_url_extra Start 3: boost_url_limits 1/3 Test #2: boost_url_extra .................. Passed 0.00 sec 2/3 Test #3: boost_url_limits ................. Passed 0.00 sec 3/3 Test #1: boost_url_unit_tests ............. Passed 0.02 sec 100% tests passed, 0 tests failed out of 3 Total Test time (real) = 0.02 sec And now we see one unit test per test case: /__w/_tool/cmake/3.20.0/x64/bin/ctest --test-dir /__w/url/boost-root/build_cmake --parallel 4 --no-tests=error --progress --output-on-failure Internal ctest changing into directory: /__w/url/boost-root/build_cmake Test project /__w/url/boost-root/build_cmake Start 1: boost.url.absolute_uri_rule Start 2: boost.url.authority_rule Start 3: boost.url.authority_view Start 4: boost.url.compat.ada 1/76 Test #1: boost.url.absolute_uri_rule .......... Passed 0.01 sec Start 5: boost.url.decode_view 2/76 Test #2: boost.url.authority_rule ............. Passed 0.01 sec Start 6: boost.url.doc.3_urls 3/76 Test #3: boost.url.authority_view ............. Passed 0.01 sec Start 7: boost.url.doc.grammar 4/76 Test #5: boost.url.decode_view ................ Passed 0.01 sec Start 8: boost.url.encode 5/76 Test #4: boost.url.compat.ada ................. Passed 0.01 sec Start 9: boost.url.error 6/76 Test #6: boost.url.doc.3_urls ................. Passed 0.01 sec Start 10: boost.url.format 7/76 Test #7: boost.url.doc.grammar ................ Passed 0.01 sec Start 11: boost.url.gen_delim_chars 8/76 Test #8: boost.url.encode ..................... Passed 0.01 sec Start 12: boost.url.grammar.alnum_chars ... meaning that each test is now executed and reported individually and in parallel, allowing developers to see which specific tests passed or failed, and enabling more granular control over test execution. Conclusion This approach brings fine-grained tests into the modern CMake Boost workflow. By splitting a single test executable into multiple independent CTest targets, maintainers gain: More granular failure reporting: CI logs show exactly which test case failed. Better developer experience: Developers can run or re-run individual tests easily. Improved parallel execution: Faster test runs in CI and locally. Better IDE integration: IDEs can show individual test cases. For other Boost libraries considering adopting this pattern, the only requirement is that their test executables support a --list-tests (or equivalent) command that outputs the available test cases. Once that’s available, the necessary CMake changes to define an equivalent function are minimal: Add a POST_BUILD step that runs the listing command and generates the .cmake file. Conditionally include that generated file in the main CMakeLists. If the output of --list-tests is one test suite per line, the existing script can be used as-is. This small investment pays off with a much more maintainable and CI-friendly testing setup. I encourage other maintainers and contributors to try this technique, refine it, and share feedback. The complete script and CMake snippets are available in the Boost.URL repository at commit #a1a5d18.</summary></entry><entry><title type="html">Ready, Set, Redis!</title><link href="http://cppalliance.org/ruben/2025/07/10/Ruben2025Q2Update.html" rel="alternate" type="text/html" title="Ready, Set, Redis!" /><published>2025-07-10T00:00:00+00:00</published><updated>2025-07-10T00:00:00+00:00</updated><id>http://cppalliance.org/ruben/2025/07/10/Ruben2025Q2Update</id><content type="html" xml:base="http://cppalliance.org/ruben/2025/07/10/Ruben2025Q2Update.html">&lt;p&gt;I’m happy to announce that I’m now a co-maintainer of &lt;a href=&quot;https://github.com/boostorg/redis&quot;&gt;Boost.Redis&lt;/a&gt;,
a high-level Redis client written on top of Asio, and hence sister of Boost.MySQL.
I’m working with its author, Marcelo, to make it even better than what it is now
(and that’s a lot to say).&lt;/p&gt;

&lt;p&gt;First of all, we’re working on improving test coverage. Boost.Redis was originally
written making heavy use of &lt;code&gt;asio::async_compose&lt;/code&gt;. If you have a
JavaScript or Python background, this approach will feel natural to you, since it’s similar
to &lt;code&gt;async&lt;/code&gt;/&lt;code&gt;await&lt;/code&gt;. Unfortunately, this approach makes code difficult to test.&lt;/p&gt;

&lt;p&gt;For instance, consider &lt;code&gt;redis::connection::async_exec&lt;/code&gt;, which enqueues a request to be
executed by the Redis server and then waits for its response. This is a (considerably simplified)
snippet of how this function could be implemented with &lt;code&gt;async_compose&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;struct exec_op {
    connection* conn;
    std::shared_ptr&amp;lt;detail::request_info&amp;gt; info; // a request + extra info
    asio::coroutine coro{}; // a coroutine polyfill that uses switch/case statements

    // Will be called by Asio until self.complete() is called
    template &amp;lt;class Self&amp;gt;
    void operator()(Self&amp;amp; self , system::error_code = {}, std::size_t = 0)
    {
        BOOST_ASIO_CORO_REENTER(coro)
        {
            // Check whether the user wants to wait for the connection to
            // be stablished.
            if (info-&amp;gt;req-&amp;gt;get_config().cancel_if_not_connected &amp;amp;&amp;amp; !conn-&amp;gt;state.is_open) {
                BOOST_ASIO_CORO_YIELD asio::async_immediate(self.get_io_executor(), std::move(self));
                return self.complete(error::not_connected, 0);
            }

            // Add the request to the queue
            conn-&amp;gt;state.add_request(info);

            // Notify the writer task that there is a new request available
            conn-&amp;gt;writer_timer.cancel();

            while (true) {
                // Wait for the request to complete. We will be notified using a channel
                BOOST_ASIO_CORO_YIELD info-&amp;gt;channel.async_wait(std::move(self));

                // Are we done yet?
                if (info-&amp;gt;is_done) {
                    self.complete(info-&amp;gt;ec, info-&amp;gt;bytes_read);
                    return;
                }

                // Check for cancellations
                if (self.get_cancellation_state().cancelled() != asio::cancellation_type_t::none) {
                    // We can only honor cancellations if the request hasn't been sent to the server
                    if (!info-&amp;gt;request_sent()) {
                        conn-&amp;gt;state.remove_request(info);
                        self.complete(asio::error::operation_aborted, 0);
                        return;
                    } else {
                        // Can't cancel, keep waiting
                    }
                }
            }
        }
    }
};

template &amp;lt;class CompletionToken, class Response&amp;gt;
auto connection::async_exec(const request&amp;amp; req, Response&amp;amp; res, CompletionToken&amp;amp;&amp;amp; token)
{
    return asio::async_compose&amp;lt;CompletionToken, void(system::error_code, std::size_t)&amp;gt;(
        exec_op{this, detail::make_info(req, res)},
        token,
        *this
    );
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The snippet above contains non-trivial logic, specially regarding cancellation.
While the code is understandable, it is difficult to test,
since Asio doesn’t include lots of testing utilities.
The end result is usually untested code, prune to difficult to diagnose bugs.&lt;/p&gt;

&lt;p&gt;As an alternative, we can refactor this code into two classes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A finite state machine object that encapsulates all logic. This should be a
lightweight and should never interact with any Asio I/O object, so we can test
logic easily.&lt;/li&gt;
  &lt;li&gt;A dumb &lt;code&gt;async_compose&lt;/code&gt; function that just applies the actions mandated by the
finite state machine.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The finite state machine for the above code could be like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;
// The finite state machine returns exec_action objects
// communicating what should be done next so the algorithm can progress
enum class exec_action_type
{
    notify_writer, // We should notify the writer task
    wait,          // We should wait for the channel to be notified
    immediate,     // We should invoke asio::async_immediate() to avoid recursion problems
    done,          // We're done and should call self.complete()
};

struct exec_action
{
    exec_action_type type;
    error_code ec;            // has meaning if type == exec_action_type::done
    std::size_t bytes_read{}; // has meaning if type == exec_action_type::done
};

// Contains all the algorithm logic. It is cheap to create and copy.
// It is conceptually similar to a coroutine.
class exec_fsm {
    asio::coroutine coro{};
    std::shared_ptr&amp;lt;detail::request_info&amp;gt; info; // a request + extra info
public:
    explicit exec_fsm(std::shared_ptr&amp;lt;detail::request_info&amp;gt; info) : info(std::move(info)) {}
    
    std::shared_ptr&amp;lt;detail::request_info&amp;gt; get_info() const { return info; }

    // To run the algorithm, run the resume() function until it returns exec_action_type::done.
    exec_action resume(
        connection_state&amp;amp; st, // Contains connection state, but not any I/O objects
        asio::cancellation_type_t cancel_state // The cancellation state of the composed operation
    )
    {
        BOOST_ASIO_REENTER(coro)
        {
            // Check whether the user wants to wait for the connection to
            // be stablished.
            if (info-&amp;gt;req-&amp;gt;get_config().cancel_if_not_connected &amp;amp;&amp;amp; !st.is_open) {
                BOOST_ASIO_CORO_YIELD {exec_action_type::immediate};
                return {exec_action_type::done, error::not_connected, 0};
            }

            // Add the request to the queue
            st.add_request(info);

            // Notify the writer task that there is a new request available
            BOOST_ASIO_CORO_YIELD {exec_action_type::notify_writer};

            while (true) {
                // Wait for the request to complete. We will be notified using a channel
                BOOST_ASIO_CORO_YIELD {exec_action_type::wait};

                // Are we done yet?
                if (info-&amp;gt;is_done) {
                    return {exec_action_type::done, info-&amp;gt;ec, info-&amp;gt;bytes_read};
                }

                // Check for cancellations
                if (cancel_state != asio::cancellation_type_t::none) {
                    // We can only honor cancellations if the request hasn't been sent to the server
                    if (!info-&amp;gt;request_sent()) {
                        conn-&amp;gt;state.remove_request(info);
                        return {exec_action_type::done, asio::error::operation_aborted};
                    } else {
                        // Can't cancel, keep waiting
                    }
                }
            }
        }
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;exec_op&lt;/code&gt; no longer contains any logic:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-cpp&quot;&gt;struct exec_op {
    connection* conn;
    exec_fsm fsm;

    // Will be called by Asio until self.complete() is called
    template &amp;lt;class Self&amp;gt;
    void operator()(Self&amp;amp; self, system::error_code = {}, std::size_t = 0)
    {
        // Call the FSM
        auto action = fsm.resume(conn-&amp;gt;state, self.get_cancellation_state().cancelled());

        // Apply the required action
        switch (action.type)
        {
            case exec_action_type::notify_writer:
                conn-&amp;gt;writer_timer.cancel();
                (*this)(self); // This action doesn't involve a callback, so invoke ourselves again
                break;
            case exec_action_type::wait:
                fsm.get_info()-&amp;gt;channel.async_wait(std::move(self));
                break;
            case exec_action_type::immediate:
                asio::async_immediate(self.get_io_executor(), std::move(self));
                break;
            case exec_action_type::done:
                self.complete(action.ec, action.bytes_read);
                break;
        }
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With this setup, &lt;code&gt;exec_fsm&lt;/code&gt; is now trivial to test, since it doesn’t invoke any I/O.&lt;/p&gt;

&lt;p&gt;We’re migrating most of the algorithms towards this approach, and we’re
finding and fixing many subtle problems in the process. There is still lots to do,
but efforts are already paying off.&lt;/p&gt;

&lt;h2 id=&quot;boostredis-features-and-docs&quot;&gt;Boost.Redis features and docs&lt;/h2&gt;

&lt;p&gt;While I tend to get very excited about this new sans-io approach, I’ve also
made other contributions that had likely had more impact on users. For instance,
I’ve implemented support for UNIX sockets, which had been something recurrently
requested by users that want to squeeze the last bit of performance from their setup.&lt;/p&gt;

&lt;p&gt;I’ve also worked on logging. Since the reconnection algorithm is complex, Boost.Redis
logs some messages by default to simplify diagnostics. This is now performed through
a simple, extensible and well-documented API, allowing users to integrate third-party
logging libraries like &lt;code&gt;spdlog&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Last (but not least), I’ve migrated Boost.Redis docs to the new asciidoc/antora/mrdocs
toolchain. I’m pretty impressed with &lt;a href=&quot;https://www.boost.org/doc/libs/develop/libs/redis/doc/html/redis/index.html&quot;&gt;the results&lt;/a&gt;,
and would like to thank the MrDocs and Boostlook people for their efforts.&lt;/p&gt;

&lt;p&gt;I know that comparisons are odious, but…&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.boost.org/doc/libs/1_88_0/libs/redis/doc/html/classboost_1_1redis_1_1basic__connection.html&quot;&gt;Old docs for &lt;code&gt;basic_connection&lt;/code&gt;&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.boost.org/doc/libs/develop/libs/redis/doc/html/redis/reference/boost/redis/basic_connection.html&quot;&gt;New docs for &lt;code&gt;basic_connection&lt;/code&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;a-great-mysql-comes-with-a-great-responsibility&quot;&gt;A great MySQL comes with a great responsibility&lt;/h2&gt;

&lt;p&gt;It’s not all been Redis these days. Boost.MySQL users also deserve some attention.
I’ve rewritten the MySQL handshake algorithm, so the &lt;code&gt;caching_sha2_password&lt;/code&gt; plugin
can work without TLS.&lt;/p&gt;

&lt;p&gt;For most of you, the sentence above will likely say nothing, so let’s provide some context.
When a client connects to the MySQL server, it performs a connection establishment packet
exchange where several connection parameters are negotiated, the client is authenticated,
and the TLS layer is optionally installed. This is collectively called the MySQL handshake,
and it’s not very clean in design.&lt;/p&gt;

&lt;p&gt;Clients can authenticate using several authentication mechanisms, called authentication
plugins. The most widespread one is &lt;code&gt;mysql_native_password&lt;/code&gt;, a challenge/response mechanism
where the client sends a hashed password to the server. It doesn’t require a TLS layer,
and it’s supported by MySQL 5.x, MySQL 8.x and MariaDB.&lt;/p&gt;

&lt;p&gt;The problem with &lt;code&gt;mysql_native_password&lt;/code&gt; is that it uses &lt;code&gt;SHA1&lt;/code&gt;, which is considered nowadays weak.
MySQL 8.x introduced &lt;code&gt;caching_sha2_password&lt;/code&gt; and deprecated &lt;code&gt;mysql_native_password&lt;/code&gt;, and MySQL 9.x
has removed the latter. &lt;code&gt;caching_sha2_password&lt;/code&gt; uses &lt;code&gt;SHA256&lt;/code&gt;, but it also introduces a cache in the server.
If your user is in the cache, the password is sent hashed, as with &lt;code&gt;mysql_native_password&lt;/code&gt;.
But if it’s not, things get more complex:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;When using a TLS layer, the password is sent in plain text.&lt;/li&gt;
  &lt;li&gt;When not using a TLS layer, the server supplies an RSA key, and the password is sent encrypted using it.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I never got to implement the second point, since most people were just using
the simpler &lt;code&gt;mysql_native_password&lt;/code&gt;. With the advent of MySQL 9, this was becoming a problem,
since it meant using TLS even for local network connections (like the ones between Docker containers),
with the overhead it implies.&lt;/p&gt;

&lt;p&gt;Implementing this new exchange has required a big refactor and many tests,
but it has paid off, as it unravelled some buggy edge-cases.
Remember the &lt;code&gt;async_compose&lt;/code&gt; vs sans-io discussion at the beginning of this post?
For such complex exchanges, going sans-io has been key.&lt;/p&gt;

&lt;h2 id=&quot;three-databases-are-better-than-two&quot;&gt;Three databases are better than two&lt;/h2&gt;

&lt;p&gt;Why MySQL and not Postgres? Well, I found myself asking this question, too.
Following what I’ve learnt with Boost.MySQL, I’m writing a new library
to interact with Postgres. It’s not usable yet, but it’s made some
progress. You can check it out &lt;a href=&quot;https://github.com/anarthal/nativepg&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;new-boost-citizens-openmethod-and-bloom&quot;&gt;New Boost citizens: OpenMethod and Bloom&lt;/h2&gt;

&lt;p&gt;I’ve also had the pleasure to participate in the review of two wonderful
libraries that have been accepted into Boost: &lt;a href=&quot;https://github.com/jll63/Boost.OpenMethod&quot;&gt;OpenMethod&lt;/a&gt;,
which allows defining virtual functions outside classes; and &lt;a href=&quot;https://github.com/boostorg/bloom&quot;&gt;Bloom&lt;/a&gt;,
which implements Bloom filters. The family keeps growing.&lt;/p&gt;

&lt;h2 id=&quot;c20-modules-and-boost&quot;&gt;C++20 modules and Boost&lt;/h2&gt;

&lt;p&gt;I’m happy to see some more Boost authors adding support for C++20 modules
in their libraries. Concretely, I’ve reviewed PRs for Boost.Pfr and Boost.Any.&lt;/p&gt;

&lt;p&gt;This is really exciting for me, and I hope to be able to dedicate some time soon
to progress my C++20 prototype for Boost.Core and Boost.Mp11.&lt;/p&gt;

&lt;h2 id=&quot;lightweight-test-context&quot;&gt;Lightweight test context&lt;/h2&gt;

&lt;p&gt;Boost.Core contains a small component to write unit tests: the &lt;a href=&quot;https://live.boost.org/doc/libs/master/libs/core/doc/html/core/lightweight_test.html&quot;&gt;lightweight test&lt;/a&gt;
framework. It’s extremely simple, and that makes it fast, both at runtime and compile-time.&lt;/p&gt;

&lt;p&gt;It’s sometimes too simple. I’m a big fan of parametric tests, where you run a test case
over a set of different values. You can do so with lightweight test by just using a loop,
but that makes failures difficult to diagnose.&lt;/p&gt;

&lt;p&gt;I’m implementing an equivalent to &lt;a href=&quot;https://live.boost.org/doc/libs/1_88_0/libs/test/doc/html/boost_test/test_output/test_tools_support_for_logging/contexts.html&quot;&gt;&lt;code&gt;BOOST_TEST_CONTEXT&lt;/code&gt;&lt;/a&gt;
for lightweight test. I’m still on the middle of it, so I’ll dive deeper onto this
in my next post. All I can say is that this addition makes lightweight test
a perfect fit for most of my testing needs!&lt;/p&gt;

&lt;h2 id=&quot;next-steps&quot;&gt;Next steps&lt;/h2&gt;

&lt;p&gt;It looks like databases, Asio and modules are definitely part of my future.
So many exciting things that I sometimes struggle to decide on which one to focus!&lt;/p&gt;</content><author><name></name></author><category term="ruben" /><summary type="html">I’m happy to announce that I’m now a co-maintainer of Boost.Redis, a high-level Redis client written on top of Asio, and hence sister of Boost.MySQL. I’m working with its author, Marcelo, to make it even better than what it is now (and that’s a lot to say). First of all, we’re working on improving test coverage. Boost.Redis was originally written making heavy use of asio::async_compose. If you have a JavaScript or Python background, this approach will feel natural to you, since it’s similar to async/await. Unfortunately, this approach makes code difficult to test. For instance, consider redis::connection::async_exec, which enqueues a request to be executed by the Redis server and then waits for its response. This is a (considerably simplified) snippet of how this function could be implemented with async_compose: struct exec_op { connection* conn; std::shared_ptr&amp;lt;detail::request_info&amp;gt; info; // a request + extra info asio::coroutine coro{}; // a coroutine polyfill that uses switch/case statements // Will be called by Asio until self.complete() is called template &amp;lt;class Self&amp;gt; void operator()(Self&amp;amp; self , system::error_code = {}, std::size_t = 0) { BOOST_ASIO_CORO_REENTER(coro) { // Check whether the user wants to wait for the connection to // be stablished. if (info-&amp;gt;req-&amp;gt;get_config().cancel_if_not_connected &amp;amp;&amp;amp; !conn-&amp;gt;state.is_open) { BOOST_ASIO_CORO_YIELD asio::async_immediate(self.get_io_executor(), std::move(self)); return self.complete(error::not_connected, 0); } // Add the request to the queue conn-&amp;gt;state.add_request(info); // Notify the writer task that there is a new request available conn-&amp;gt;writer_timer.cancel(); while (true) { // Wait for the request to complete. We will be notified using a channel BOOST_ASIO_CORO_YIELD info-&amp;gt;channel.async_wait(std::move(self)); // Are we done yet? if (info-&amp;gt;is_done) { self.complete(info-&amp;gt;ec, info-&amp;gt;bytes_read); return; } // Check for cancellations if (self.get_cancellation_state().cancelled() != asio::cancellation_type_t::none) { // We can only honor cancellations if the request hasn't been sent to the server if (!info-&amp;gt;request_sent()) { conn-&amp;gt;state.remove_request(info); self.complete(asio::error::operation_aborted, 0); return; } else { // Can't cancel, keep waiting } } } } } }; template &amp;lt;class CompletionToken, class Response&amp;gt; auto connection::async_exec(const request&amp;amp; req, Response&amp;amp; res, CompletionToken&amp;amp;&amp;amp; token) { return asio::async_compose&amp;lt;CompletionToken, void(system::error_code, std::size_t)&amp;gt;( exec_op{this, detail::make_info(req, res)}, token, *this ); } The snippet above contains non-trivial logic, specially regarding cancellation. While the code is understandable, it is difficult to test, since Asio doesn’t include lots of testing utilities. The end result is usually untested code, prune to difficult to diagnose bugs. As an alternative, we can refactor this code into two classes: A finite state machine object that encapsulates all logic. This should be a lightweight and should never interact with any Asio I/O object, so we can test logic easily. A dumb async_compose function that just applies the actions mandated by the finite state machine. The finite state machine for the above code could be like: // The finite state machine returns exec_action objects // communicating what should be done next so the algorithm can progress enum class exec_action_type { notify_writer, // We should notify the writer task wait, // We should wait for the channel to be notified immediate, // We should invoke asio::async_immediate() to avoid recursion problems done, // We're done and should call self.complete() }; struct exec_action { exec_action_type type; error_code ec; // has meaning if type == exec_action_type::done std::size_t bytes_read{}; // has meaning if type == exec_action_type::done }; // Contains all the algorithm logic. It is cheap to create and copy. // It is conceptually similar to a coroutine. class exec_fsm { asio::coroutine coro{}; std::shared_ptr&amp;lt;detail::request_info&amp;gt; info; // a request + extra info public: explicit exec_fsm(std::shared_ptr&amp;lt;detail::request_info&amp;gt; info) : info(std::move(info)) {} std::shared_ptr&amp;lt;detail::request_info&amp;gt; get_info() const { return info; } // To run the algorithm, run the resume() function until it returns exec_action_type::done. exec_action resume( connection_state&amp;amp; st, // Contains connection state, but not any I/O objects asio::cancellation_type_t cancel_state // The cancellation state of the composed operation ) { BOOST_ASIO_REENTER(coro) { // Check whether the user wants to wait for the connection to // be stablished. if (info-&amp;gt;req-&amp;gt;get_config().cancel_if_not_connected &amp;amp;&amp;amp; !st.is_open) { BOOST_ASIO_CORO_YIELD {exec_action_type::immediate}; return {exec_action_type::done, error::not_connected, 0}; } // Add the request to the queue st.add_request(info); // Notify the writer task that there is a new request available BOOST_ASIO_CORO_YIELD {exec_action_type::notify_writer}; while (true) { // Wait for the request to complete. We will be notified using a channel BOOST_ASIO_CORO_YIELD {exec_action_type::wait}; // Are we done yet? if (info-&amp;gt;is_done) { return {exec_action_type::done, info-&amp;gt;ec, info-&amp;gt;bytes_read}; } // Check for cancellations if (cancel_state != asio::cancellation_type_t::none) { // We can only honor cancellations if the request hasn't been sent to the server if (!info-&amp;gt;request_sent()) { conn-&amp;gt;state.remove_request(info); return {exec_action_type::done, asio::error::operation_aborted}; } else { // Can't cancel, keep waiting } } } } } }; exec_op no longer contains any logic: struct exec_op { connection* conn; exec_fsm fsm; // Will be called by Asio until self.complete() is called template &amp;lt;class Self&amp;gt; void operator()(Self&amp;amp; self, system::error_code = {}, std::size_t = 0) { // Call the FSM auto action = fsm.resume(conn-&amp;gt;state, self.get_cancellation_state().cancelled()); // Apply the required action switch (action.type) { case exec_action_type::notify_writer: conn-&amp;gt;writer_timer.cancel(); (*this)(self); // This action doesn't involve a callback, so invoke ourselves again break; case exec_action_type::wait: fsm.get_info()-&amp;gt;channel.async_wait(std::move(self)); break; case exec_action_type::immediate: asio::async_immediate(self.get_io_executor(), std::move(self)); break; case exec_action_type::done: self.complete(action.ec, action.bytes_read); break; } } }; With this setup, exec_fsm is now trivial to test, since it doesn’t invoke any I/O. We’re migrating most of the algorithms towards this approach, and we’re finding and fixing many subtle problems in the process. There is still lots to do, but efforts are already paying off. Boost.Redis features and docs While I tend to get very excited about this new sans-io approach, I’ve also made other contributions that had likely had more impact on users. For instance, I’ve implemented support for UNIX sockets, which had been something recurrently requested by users that want to squeeze the last bit of performance from their setup. I’ve also worked on logging. Since the reconnection algorithm is complex, Boost.Redis logs some messages by default to simplify diagnostics. This is now performed through a simple, extensible and well-documented API, allowing users to integrate third-party logging libraries like spdlog. Last (but not least), I’ve migrated Boost.Redis docs to the new asciidoc/antora/mrdocs toolchain. I’m pretty impressed with the results, and would like to thank the MrDocs and Boostlook people for their efforts. I know that comparisons are odious, but… Old docs for basic_connection. New docs for basic_connection. A great MySQL comes with a great responsibility It’s not all been Redis these days. Boost.MySQL users also deserve some attention. I’ve rewritten the MySQL handshake algorithm, so the caching_sha2_password plugin can work without TLS. For most of you, the sentence above will likely say nothing, so let’s provide some context. When a client connects to the MySQL server, it performs a connection establishment packet exchange where several connection parameters are negotiated, the client is authenticated, and the TLS layer is optionally installed. This is collectively called the MySQL handshake, and it’s not very clean in design. Clients can authenticate using several authentication mechanisms, called authentication plugins. The most widespread one is mysql_native_password, a challenge/response mechanism where the client sends a hashed password to the server. It doesn’t require a TLS layer, and it’s supported by MySQL 5.x, MySQL 8.x and MariaDB. The problem with mysql_native_password is that it uses SHA1, which is considered nowadays weak. MySQL 8.x introduced caching_sha2_password and deprecated mysql_native_password, and MySQL 9.x has removed the latter. caching_sha2_password uses SHA256, but it also introduces a cache in the server. If your user is in the cache, the password is sent hashed, as with mysql_native_password. But if it’s not, things get more complex: When using a TLS layer, the password is sent in plain text. When not using a TLS layer, the server supplies an RSA key, and the password is sent encrypted using it. I never got to implement the second point, since most people were just using the simpler mysql_native_password. With the advent of MySQL 9, this was becoming a problem, since it meant using TLS even for local network connections (like the ones between Docker containers), with the overhead it implies. Implementing this new exchange has required a big refactor and many tests, but it has paid off, as it unravelled some buggy edge-cases. Remember the async_compose vs sans-io discussion at the beginning of this post? For such complex exchanges, going sans-io has been key. Three databases are better than two Why MySQL and not Postgres? Well, I found myself asking this question, too. Following what I’ve learnt with Boost.MySQL, I’m writing a new library to interact with Postgres. It’s not usable yet, but it’s made some progress. You can check it out here. New Boost citizens: OpenMethod and Bloom I’ve also had the pleasure to participate in the review of two wonderful libraries that have been accepted into Boost: OpenMethod, which allows defining virtual functions outside classes; and Bloom, which implements Bloom filters. The family keeps growing. C++20 modules and Boost I’m happy to see some more Boost authors adding support for C++20 modules in their libraries. Concretely, I’ve reviewed PRs for Boost.Pfr and Boost.Any. This is really exciting for me, and I hope to be able to dedicate some time soon to progress my C++20 prototype for Boost.Core and Boost.Mp11. Lightweight test context Boost.Core contains a small component to write unit tests: the lightweight test framework. It’s extremely simple, and that makes it fast, both at runtime and compile-time. It’s sometimes too simple. I’m a big fan of parametric tests, where you run a test case over a set of different values. You can do so with lightweight test by just using a loop, but that makes failures difficult to diagnose. I’m implementing an equivalent to BOOST_TEST_CONTEXT for lightweight test. I’m still on the middle of it, so I’ll dive deeper onto this in my next post. All I can say is that this addition makes lightweight test a perfect fit for most of my testing needs! Next steps It looks like databases, Asio and modules are definitely part of my future. So many exciting things that I sometimes struggle to decide on which one to focus!</summary></entry><entry><title type="html">Mailman3 and Website-V2</title><link href="http://cppalliance.org/sam/2025/07/10/SamsQ2Update.html" rel="alternate" type="text/html" title="Mailman3 and Website-V2" /><published>2025-07-10T00:00:00+00:00</published><updated>2025-07-10T00:00:00+00:00</updated><id>http://cppalliance.org/sam/2025/07/10/SamsQ2Update</id><content type="html" xml:base="http://cppalliance.org/sam/2025/07/10/SamsQ2Update.html">&lt;h3 id=&quot;mailman3-deployment&quot;&gt;Mailman3 Deployment&lt;/h3&gt;

&lt;p&gt;The Boost mailing list has been in place for around 25 years. During at least the last 3 years we have been exploring an upgrade to mailman3 which is a completely new framework based on Django and multiple other components. The new server finally went live in June 2025 at the same URL: https://lists.boost.org.&lt;/p&gt;

&lt;p&gt;Mail archives going back to 2004 were imported into the new system. Static file copies of all archives are also hosted at listarchives.boost.org.&lt;/p&gt;

&lt;p&gt;Thanks to some organizational delays, there was more time to ensure a technically stable migration, discover potential problems and interact with the upstream open-source project maintainers. I was able to contribute documentation to the official Mailman Suite docs, switch the search engine from Elastic Search to Xapian (which they recommend), convert the cache to Redis, find a qcluster misconfiguration, submit a fix about an archive import bug, create new shell wrapper scripts for CLI execution, install logrotate, and more.&lt;/p&gt;

&lt;p&gt;Hopefully the new server is more enjoyable to interact with than mailman2. It solves certain issues: posts appear almost instantly on lists.boost.org and they are emailed out quickly. UTF-8 characters render correctly. New features can be added.&lt;/p&gt;

&lt;h3 id=&quot;boost-website-boostorgwebsite-v2&quot;&gt;Boost website boostorg/website-v2&lt;/h3&gt;

&lt;p&gt;The new boost.org went live! After nearly 4 years of development. A major milestone. Switched over DNS.&lt;/p&gt;

&lt;p&gt;Also,&lt;/p&gt;

&lt;p&gt;Enabled IPv6.&lt;br /&gt;
Installed horizontal pod autoscaler (HPA).&lt;br /&gt;
Nginx redirect from boost.io to boost.org.  &lt;br /&gt;
Adjusted Fastly CDN settings for ‘latest’. Fixing Fastly VCL commands to process 404s. Opened ticket, re-organized the order of the expressions.&lt;br /&gt;
Created QA environment. Actually using the cppal-dev environment. Re-DNS servers.&lt;br /&gt;
Discussing and planning a feature in website-v2 to improve doc page load times by a factor of 4, by caching doc pages in postgresql instead of always loading them across the network from S3.&lt;br /&gt;
Improved the install scripts for local developer workstations, specifically the logic and steps of the Linux install.&lt;/p&gt;

&lt;h3 id=&quot;doc-previews-and-doc-builds&quot;&gt;Doc Previews and Doc Builds&lt;/h3&gt;

&lt;p&gt;A few Boost libraries depend on &lt;a href=&quot;https://antora.org/&quot;&gt;Antora&lt;/a&gt;, and the number will expand in the future. An existing problem with Antora is that the component isomorphic-git doesn’t support submodules, while all Boost libraries are submodules.&lt;/p&gt;

&lt;p&gt;I have opened a draft pull request on isomorphic-git to include a subset of submodule capabilities, allowing it to operating on already-checked-out submodules. That would be sufficient to handle most cases of doc builds. Since the original author of isomorphic-git departed, there is at most a part-time maintainer. Review processes are somewhat slow. Further work needs to be done. But it’s progressing and doesn’t appear to be blocked, although there is a hurdle that a correct isomorphic-git update for submodules will need to modify 60+ git commands, each of which has a test suite and varying source code files.&lt;/p&gt;

&lt;h3 id=&quot;boost-ci&quot;&gt;boost-ci&lt;/h3&gt;

&lt;p&gt;Nearly all CI jobs that use boost-ci set B2_CI_VERSION=1. We’re now working on eliminating the need for this variable by making it a default. That will avoid an error when the variable isn’t set properly. CI configuration becomes one step easier. Running reports to find which repos are affected. In-process.&lt;/p&gt;

&lt;h3 id=&quot;infrastructure-monitoring&quot;&gt;Infrastructure Monitoring&lt;/h3&gt;

&lt;p&gt;The upstream Ansible roles to deploy Prometheus and Grafana were redesigned, and migrated from a ‘role’ to a ‘collection’. In order to stay up-to-date and use the latest pip packages, I converted the Alliance’s Prometheus/Grafana server to the new system and re-wrote the ‘node exporter’ modules which are customized to install on multiple operating systems, windows/macos/linux.&lt;/p&gt;

&lt;p&gt;Deployed new server.&lt;/p&gt;

&lt;p&gt;Further monitoring of Drone (number of runners). Postgresql (all db statistics).&lt;/p&gt;

&lt;h3 id=&quot;jenkins&quot;&gt;Jenkins&lt;/h3&gt;

&lt;p&gt;The latest Jenkins jobs send email notifications on failure. Working on designing adjustments to those steps to remove false-positives, which are caused by plugin bugs. It’s valuable to receive accurate email notifications, allowing prompt investigation of the job issues.&lt;/p&gt;

&lt;p&gt;Debugging Bloom. Added Decimal. Int128.&lt;/p&gt;

&lt;p&gt;Upgraded all plugins, server.&lt;/p&gt;

&lt;h3 id=&quot;boost-release-process-boostorgrelease-tools&quot;&gt;Boost release process boostorg/release-tools&lt;/h3&gt;

&lt;p&gt;Boost release 1.88.0.&lt;br /&gt;
Worked with release managers to debug the publish scripts. Opened issues on website-v2 about the release process.&lt;br /&gt;
Helped multiple boost authors with various docs errors affecting superproject builds.&lt;/p&gt;

&lt;h3 id=&quot;drone&quot;&gt;Drone&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Rebuilt vs2022 runners.&lt;/li&gt;
  &lt;li&gt;IBM invoicing issues. not uncommon.&lt;/li&gt;
  &lt;li&gt;IBM password expirations issues due to their configuration defaults.&lt;/li&gt;
  &lt;li&gt;Disabled hyperthreading on runners.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;gha&quot;&gt;GHA&lt;/h3&gt;

&lt;p&gt;Rebuilt windows-2025 runners.&lt;/p&gt;

&lt;h3 id=&quot;benchmarks&quot;&gt;Benchmarks&lt;/h3&gt;
&lt;p&gt;New dedicated benchmark runners for boostorg/bloom.&lt;/p&gt;</content><author><name></name></author><category term="sam" /><summary type="html">Mailman3 Deployment The Boost mailing list has been in place for around 25 years. During at least the last 3 years we have been exploring an upgrade to mailman3 which is a completely new framework based on Django and multiple other components. The new server finally went live in June 2025 at the same URL: https://lists.boost.org. Mail archives going back to 2004 were imported into the new system. Static file copies of all archives are also hosted at listarchives.boost.org. Thanks to some organizational delays, there was more time to ensure a technically stable migration, discover potential problems and interact with the upstream open-source project maintainers. I was able to contribute documentation to the official Mailman Suite docs, switch the search engine from Elastic Search to Xapian (which they recommend), convert the cache to Redis, find a qcluster misconfiguration, submit a fix about an archive import bug, create new shell wrapper scripts for CLI execution, install logrotate, and more. Hopefully the new server is more enjoyable to interact with than mailman2. It solves certain issues: posts appear almost instantly on lists.boost.org and they are emailed out quickly. UTF-8 characters render correctly. New features can be added. Boost website boostorg/website-v2 The new boost.org went live! After nearly 4 years of development. A major milestone. Switched over DNS. Also, Enabled IPv6. Installed horizontal pod autoscaler (HPA). Nginx redirect from boost.io to boost.org. Adjusted Fastly CDN settings for ‘latest’. Fixing Fastly VCL commands to process 404s. Opened ticket, re-organized the order of the expressions. Created QA environment. Actually using the cppal-dev environment. Re-DNS servers. Discussing and planning a feature in website-v2 to improve doc page load times by a factor of 4, by caching doc pages in postgresql instead of always loading them across the network from S3. Improved the install scripts for local developer workstations, specifically the logic and steps of the Linux install. Doc Previews and Doc Builds A few Boost libraries depend on Antora, and the number will expand in the future. An existing problem with Antora is that the component isomorphic-git doesn’t support submodules, while all Boost libraries are submodules. I have opened a draft pull request on isomorphic-git to include a subset of submodule capabilities, allowing it to operating on already-checked-out submodules. That would be sufficient to handle most cases of doc builds. Since the original author of isomorphic-git departed, there is at most a part-time maintainer. Review processes are somewhat slow. Further work needs to be done. But it’s progressing and doesn’t appear to be blocked, although there is a hurdle that a correct isomorphic-git update for submodules will need to modify 60+ git commands, each of which has a test suite and varying source code files. boost-ci Nearly all CI jobs that use boost-ci set B2_CI_VERSION=1. We’re now working on eliminating the need for this variable by making it a default. That will avoid an error when the variable isn’t set properly. CI configuration becomes one step easier. Running reports to find which repos are affected. In-process. Infrastructure Monitoring The upstream Ansible roles to deploy Prometheus and Grafana were redesigned, and migrated from a ‘role’ to a ‘collection’. In order to stay up-to-date and use the latest pip packages, I converted the Alliance’s Prometheus/Grafana server to the new system and re-wrote the ‘node exporter’ modules which are customized to install on multiple operating systems, windows/macos/linux. Deployed new server. Further monitoring of Drone (number of runners). Postgresql (all db statistics). Jenkins The latest Jenkins jobs send email notifications on failure. Working on designing adjustments to those steps to remove false-positives, which are caused by plugin bugs. It’s valuable to receive accurate email notifications, allowing prompt investigation of the job issues. Debugging Bloom. Added Decimal. Int128. Upgraded all plugins, server. Boost release process boostorg/release-tools Boost release 1.88.0. Worked with release managers to debug the publish scripts. Opened issues on website-v2 about the release process. Helped multiple boost authors with various docs errors affecting superproject builds. Drone Rebuilt vs2022 runners. IBM invoicing issues. not uncommon. IBM password expirations issues due to their configuration defaults. Disabled hyperthreading on runners. GHA Rebuilt windows-2025 runners. Benchmarks New dedicated benchmark runners for boostorg/bloom.</summary></entry><entry><title type="html">Include Hallucinations for Adventures in AI-Generated C++</title><link href="http://cppalliance.org/peter/2025/07/07/PeterTurcan-Q2-2025.html" rel="alternate" type="text/html" title="Include Hallucinations for Adventures in AI-Generated C++" /><published>2025-07-07T00:00:00+00:00</published><updated>2025-07-07T00:00:00+00:00</updated><id>http://cppalliance.org/peter/2025/07/07/PeterTurcan-Q2-2025</id><content type="html" xml:base="http://cppalliance.org/peter/2025/07/07/PeterTurcan-Q2-2025.html">&lt;p&gt;AI generated code has some fun side effects. Whilst generating a lot of code and testing it using Microsoft Visual Studio I had the odd experience of giving the AI model a line of buggy code, and it forthrightly states to replace this faulty line with this new line. On close inspection both lines are identical! Ha - in the AI world this is known as a “hallucination” - amusing but not the answer I was looking for.&lt;/p&gt;

&lt;p&gt;Other odd side effects of AI generated code include having unused “#include &amp;lt;header&amp;gt;” statements - I commented out a bunch of #includes that I was not sure about, and presto the code compiled and ran unimpressed with my efforts to disable it. Unused #includes don’t so much add errors but the appearance of complexity. As I am in the education business, complexity is something I try to avoid.&lt;/p&gt;

&lt;p&gt;I did find that the more complex the syntax - say in metaprogamming with templates, or shorthand means of referencing elements within a multi-dimensional matrix perhaps - the more likely AI would not get it right. My simplistic conclusion is that a C++ AI model will get the code right as long as you don’t veer too far from the standard language and the fewer libraries the better. In my also simplistic opinion this is not ready for prime time - we all use, and want to use, libraries to take much of the heavy-lifting away from development effort and time.&lt;/p&gt;

&lt;p&gt;Investigating the use of the enormous precision available using libraries such as Boost.Multiprecision, I am impressed by the huge prime numbers used in cryptography and the accuracy of constants in science such as astrophysics (gravitational constants, pi, zeta constants in string theory and the like). At the same time - fun fact - NASA’s orbital calculations use only around 15 digits of pi to get very precise orbits, so precision can become an obsession devolved of any practical application!&lt;/p&gt;

&lt;p&gt;With recent library releases, such as Boost.Hash, it seemed prudent to add pertinent hash terminology to the User Guide Glossary - help the uninitiated understand what it’s all about. Same for Open Methods and Bloom Filters - all adding more terminology to our already overloaded capacity. Another fun fact - Bloom filters are not named after anything to do with blooming - but simply after the name of the inventor - Burton Howard Bloom.&lt;/p&gt;

&lt;p&gt;Testing Boost libraries did pique my imagination several times. Many years ago, working with a smart human friend - a computer analyst - we devised a language to be used for giving orders in a battle simulation. “Marshal Davout, order one infantry and one cavalry division to attack the hill to the NorthEast”, for example. This involved three distinct steps - syntax analysis to check for correct wording, semantic analysis to check for correct grammar, and interpretation. The first two steps are logical and complete. The third step - interpretation is a toughie - “is there a hill to the NorthEast?”  -  and if not, what do I do? Similarly, “what if I have two infantry divisions available, but no cavalry, should I still attack?”.  Duh - interpretation can be ambiguous and difficult. Wish Boost.Spirit had been available way back then, it has a granular approach to syntax and semantics I could recognize as being intuitive and useful - would have taken a lot of the work out of syntax and semantics, and left time for battling with the ambiguities of interpretation.&lt;/p&gt;

&lt;p&gt;Talking of useful Boost libraries, I did some testing with Boost.Asio, and writing and running client-server and peer-to-peer samples on multiple computers. Yikes it worked well and is largely intuitive. Go Asio.&lt;/p&gt;

&lt;p&gt;Perhaps one of the less-well documented topics involving Boost libraries is the topic of which libraries play well together, and which do not. I started building up some knowledge on this and added a “Combining Libraries” section to the User Guide FAQ - it is what I would want to know if I was a newcomer to Boost - many hands make light work - or many libraries make light work.&lt;/p&gt;

&lt;p&gt;May your AI always hallucinate slightly less than your compiler does.&lt;/p&gt;</content><author><name></name></author><category term="peter" /><summary type="html">AI generated code has some fun side effects. Whilst generating a lot of code and testing it using Microsoft Visual Studio I had the odd experience of giving the AI model a line of buggy code, and it forthrightly states to replace this faulty line with this new line. On close inspection both lines are identical! Ha - in the AI world this is known as a “hallucination” - amusing but not the answer I was looking for. Other odd side effects of AI generated code include having unused “#include &amp;lt;header&amp;gt;” statements - I commented out a bunch of #includes that I was not sure about, and presto the code compiled and ran unimpressed with my efforts to disable it. Unused #includes don’t so much add errors but the appearance of complexity. As I am in the education business, complexity is something I try to avoid. I did find that the more complex the syntax - say in metaprogamming with templates, or shorthand means of referencing elements within a multi-dimensional matrix perhaps - the more likely AI would not get it right. My simplistic conclusion is that a C++ AI model will get the code right as long as you don’t veer too far from the standard language and the fewer libraries the better. In my also simplistic opinion this is not ready for prime time - we all use, and want to use, libraries to take much of the heavy-lifting away from development effort and time. Investigating the use of the enormous precision available using libraries such as Boost.Multiprecision, I am impressed by the huge prime numbers used in cryptography and the accuracy of constants in science such as astrophysics (gravitational constants, pi, zeta constants in string theory and the like). At the same time - fun fact - NASA’s orbital calculations use only around 15 digits of pi to get very precise orbits, so precision can become an obsession devolved of any practical application! With recent library releases, such as Boost.Hash, it seemed prudent to add pertinent hash terminology to the User Guide Glossary - help the uninitiated understand what it’s all about. Same for Open Methods and Bloom Filters - all adding more terminology to our already overloaded capacity. Another fun fact - Bloom filters are not named after anything to do with blooming - but simply after the name of the inventor - Burton Howard Bloom. Testing Boost libraries did pique my imagination several times. Many years ago, working with a smart human friend - a computer analyst - we devised a language to be used for giving orders in a battle simulation. “Marshal Davout, order one infantry and one cavalry division to attack the hill to the NorthEast”, for example. This involved three distinct steps - syntax analysis to check for correct wording, semantic analysis to check for correct grammar, and interpretation. The first two steps are logical and complete. The third step - interpretation is a toughie - “is there a hill to the NorthEast?” - and if not, what do I do? Similarly, “what if I have two infantry divisions available, but no cavalry, should I still attack?”. Duh - interpretation can be ambiguous and difficult. Wish Boost.Spirit had been available way back then, it has a granular approach to syntax and semantics I could recognize as being intuitive and useful - would have taken a lot of the work out of syntax and semantics, and left time for battling with the ambiguities of interpretation. Talking of useful Boost libraries, I did some testing with Boost.Asio, and writing and running client-server and peer-to-peer samples on multiple computers. Yikes it worked well and is largely intuitive. Go Asio. Perhaps one of the less-well documented topics involving Boost libraries is the topic of which libraries play well together, and which do not. I started building up some knowledge on this and added a “Combining Libraries” section to the User Guide FAQ - it is what I would want to know if I was a newcomer to Boost - many hands make light work - or many libraries make light work. May your AI always hallucinate slightly less than your compiler does.</summary></entry><entry><title type="html">Boost.Bloom ready for shipping in Boost 1.89</title><link href="http://cppalliance.org/joaquin/2025/07/01/Joaquins2025Q2Update.html" rel="alternate" type="text/html" title="Boost.Bloom ready for shipping in Boost 1.89" /><published>2025-07-01T00:00:00+00:00</published><updated>2025-07-01T00:00:00+00:00</updated><id>http://cppalliance.org/joaquin/2025/07/01/Joaquins2025Q2Update</id><content type="html" xml:base="http://cppalliance.org/joaquin/2025/07/01/Joaquins2025Q2Update.html">&lt;p&gt;During Q2 2025, I’ve been working in the following areas:&lt;/p&gt;

&lt;h3 id=&quot;boostbloom&quot;&gt;Boost.Bloom&lt;/h3&gt;

&lt;p&gt;The acceptance review for &lt;a href=&quot;https://github.com/boostorg/bloom&quot;&gt;Boost.Bloom&lt;/a&gt;
took place between the 13th and 22nd of May,
and the final verdict was &lt;a href=&quot;https://lists.boost.org/archives/list/boost@lists.boost.org/message/L4X3LREHFIZXNJRL7XLMC4NPOLWXXVCA/&quot;&gt;acceptance into Boost&lt;/a&gt;.
Arnauld Becheler did an awesome job at managing the review, which was one of the most
lively and productive I remember in recent years. Incorporating the feedback from the review
took me the last five weeks of this quarter, but everything’s ready for shipping with Boost 1.89 (Aug 2025):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/boostorg/bloom/issues?q=is%3Aissue%20state%3Aclosed%20author%3ABecheler&quot;&gt;Review feedback as compiled by Arnauld&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/boostorg/bloom/pull/32&quot;&gt;Post-review changes&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.boost.org/doc/libs/develop/libs/bloom/doc/html/bloom.html&quot;&gt;Docs on &lt;code&gt;develop&lt;/code&gt; branch&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;boostcontainerhash&quot;&gt;Boost.ContainerHash&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Added &lt;code&gt;boost::hash_is_avalanching&lt;/code&gt; trait (&lt;a href=&quot;https://github.com/boostorg/container_hash/pull/40&quot;&gt;PR#40&lt;/a&gt;).
This trait was originally in Boost.Unordered, but it makes sense that it be moved here because
Boost.Bloom also uses it.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;boostunordered&quot;&gt;Boost.Unordered&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Added &lt;code&gt;pull(const_iterator)&lt;/code&gt; to open-addressing containers (&lt;a href=&quot;https://github.com/boostorg/unordered/pull/309&quot;&gt;PR#309&lt;/a&gt;).&lt;/li&gt;
  &lt;li&gt;CI maintenance work (&lt;a href=&quot;https://github.com/boostorg/unordered/pull/310&quot;&gt;PR#310&lt;/a&gt;, &lt;a href=&quot;https://github.com/boostorg/unordered/pull/311&quot;&gt;PR#311&lt;/a&gt;).&lt;/li&gt;
  &lt;li&gt;Improved documentation of &lt;code&gt;erase_if&lt;/code&gt; (&lt;a href=&quot;https://github.com/boostorg/unordered/pull/312&quot;&gt;PR#312&lt;/a&gt;).&lt;/li&gt;
  &lt;li&gt;Deprecated &lt;code&gt;boost::unordered::hash_is_avalanching&lt;/code&gt; in favor of &lt;code&gt;boost::hash_is_avalanching&lt;/code&gt; (&lt;a href=&quot;https://github.com/boostorg/unordered/pull/313&quot;&gt;PR#313&lt;/a&gt;).&lt;/li&gt;
  &lt;li&gt;Addressed some user-filed issues (&lt;a href=&quot;https://github.com/boostorg/unordered/issues/305&quot;&gt;#305&lt;/a&gt;, &lt;a href=&quot;https://github.com/boostorg/unordered/issues/308&quot;&gt;#308&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;boostmultiindex&quot;&gt;Boost.MultiIndex&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;CI maintenance work (&lt;a href=&quot;https://github.com/boostorg/multi_index/pull/82&quot;&gt;PR#82&lt;/a&gt;).&lt;/li&gt;
  &lt;li&gt;Addressed a user-filed issue (&lt;a href=&quot;https://github.com/boostorg/multi_index/issues/81&quot;&gt;#81&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;boostflyweight&quot;&gt;Boost.Flyweight&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;CI maintenance work (&lt;a href=&quot;https://github.com/boostorg/flyweight/pull/21&quot;&gt;PR#21&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;boostpolycollection&quot;&gt;Boost.PolyCollection&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;CI maintenance work (&lt;a href=&quot;https://github.com/boostorg/poly_collection/pull/31&quot;&gt;PR#31&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;boostinterprocess&quot;&gt;Boost.Interprocess&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Filed some issues (&lt;a href=&quot;https://github.com/boostorg/interprocess/issues/258&quot;&gt;#258&lt;/a&gt;, &lt;a href=&quot;https://github.com/boostorg/interprocess/issues/259&quot;&gt;#259&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;boost-website&quot;&gt;Boost website&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Filed some issues (&lt;a href=&quot;https://github.com/boostorg/website-v2/issues/1760&quot;&gt;#1760&lt;/a&gt;, &lt;a href=&quot;https://github.com/boostorg/website-v2/issues/1792&quot;&gt;#1792&lt;/a&gt;, &lt;a href=&quot;https://github.com/boostorg/website-v2/issues/1832&quot;&gt;#1832&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;boost-promotion&quot;&gt;Boost promotion&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Posted several tweets on Boost’s X account:
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://x.com/Boost_Libraries/status/1910454023079289213&quot;&gt;Boost 1.88 announcement&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://x.com/Boost_Libraries/status/1910991838606991446&quot;&gt;Boost.MQTT5 promotion&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://x.com/Boost_Libraries/status/1916512666778009719&quot;&gt;Boost.OpenMethod review announcement&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://x.com/Boost_Libraries/status/1921946625502486634&quot;&gt;New website announcement&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://x.com/Boost_Libraries/status/1922243232097824902&quot;&gt;Boost.Bloom review announcement&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://x.com/Boost_Libraries/status/1927809347205091779&quot;&gt;Boost.OpenMethod review result&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://x.com/Boost_Libraries/status/1928128488583672161&quot;&gt;Boost.Bloom review result&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://x.com/Boost_Libraries/status/1933540234026971535&quot;&gt;Promotion of a talk about cancellations in Asio&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://x.com/Boost_Libraries/status/1937467125141995660&quot;&gt;Promotion of a compilation of videos on Boost from the Utah C++ Programmers Group&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;I also did a special series on X covering the presence of Boost on the latest WG21 meeting in Sofia, Bulgaria:
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://x.com/Boost_Libraries/status/1934649592403939668&quot;&gt;Boost.Hash2&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://x.com/Boost_Libraries/status/1934998270880723015&quot;&gt;Fiscal Sponsorship Agreement&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://x.com/Boost_Libraries/status/1935366708837105997&quot;&gt;Boost.Parser&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://x.com/Boost_Libraries/status/1935757341934186575&quot;&gt;Boost.Math&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://x.com/Boost_Libraries/status/1936092537032159615&quot;&gt;Boost.Unordered&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://x.com/Boost_Libraries/status/1936451629118521502&quot;&gt;Boost.MQTT5&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;support-to-the-community&quot;&gt;Support to the community&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://lists.boost.org/archives/list/boost@lists.boost.org/message/5L6ZCDS2DBUUZSBZYALCEPIFRAKNP25O/&quot;&gt;Reviewed&lt;/a&gt; Jean-Louis Leroy’s Boost.OpenMethod proposal.&lt;/li&gt;
  &lt;li&gt;Did a small theoretical analysis of &lt;a href=&quot;https://github.com/joaquintides/perfect_range_hash&quot;&gt;Boost.OpenMethod’s perfect hashing algorithm&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Did some &lt;a href=&quot;https://github.com/cmazakas/c2&quot;&gt;&lt;code&gt;c2.py&lt;/code&gt;&lt;/a&gt; testing for Chris Mazakas.&lt;/li&gt;
  &lt;li&gt;Supporting the community as a member of the Fiscal Sponsorhip Committee (FSC).
The asset transfer from the Boost Foundation to the C++ Alliance was finally completed this quarter,
which has enabled the launch of the long-awaited new website.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><category term="joaquin" /><summary type="html">During Q2 2025, I’ve been working in the following areas: Boost.Bloom The acceptance review for Boost.Bloom took place between the 13th and 22nd of May, and the final verdict was acceptance into Boost. Arnauld Becheler did an awesome job at managing the review, which was one of the most lively and productive I remember in recent years. Incorporating the feedback from the review took me the last five weeks of this quarter, but everything’s ready for shipping with Boost 1.89 (Aug 2025): Review feedback as compiled by Arnauld Post-review changes Docs on develop branch Boost.ContainerHash Added boost::hash_is_avalanching trait (PR#40). This trait was originally in Boost.Unordered, but it makes sense that it be moved here because Boost.Bloom also uses it. Boost.Unordered Added pull(const_iterator) to open-addressing containers (PR#309). CI maintenance work (PR#310, PR#311). Improved documentation of erase_if (PR#312). Deprecated boost::unordered::hash_is_avalanching in favor of boost::hash_is_avalanching (PR#313). Addressed some user-filed issues (#305, #308). Boost.MultiIndex CI maintenance work (PR#82). Addressed a user-filed issue (#81). Boost.Flyweight CI maintenance work (PR#21). Boost.PolyCollection CI maintenance work (PR#31). Boost.Interprocess Filed some issues (#258, #259). Boost website Filed some issues (#1760, #1792, #1832). Boost promotion Posted several tweets on Boost’s X account: Boost 1.88 announcement Boost.MQTT5 promotion Boost.OpenMethod review announcement New website announcement Boost.Bloom review announcement Boost.OpenMethod review result Boost.Bloom review result Promotion of a talk about cancellations in Asio Promotion of a compilation of videos on Boost from the Utah C++ Programmers Group I also did a special series on X covering the presence of Boost on the latest WG21 meeting in Sofia, Bulgaria: Boost.Hash2 Fiscal Sponsorship Agreement Boost.Parser Boost.Math Boost.Unordered Boost.MQTT5 Support to the community Reviewed Jean-Louis Leroy’s Boost.OpenMethod proposal. Did a small theoretical analysis of Boost.OpenMethod’s perfect hashing algorithm. Did some c2.py testing for Chris Mazakas. Supporting the community as a member of the Fiscal Sponsorhip Committee (FSC). The asset transfer from the Boost Foundation to the C++ Alliance was finally completed this quarter, which has enabled the launch of the long-awaited new website.</summary></entry></feed>