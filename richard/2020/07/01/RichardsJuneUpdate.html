<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Richard's May/June Update | The C++ Alliance</title>
<link href="https://fonts.googleapis.com/css?family=Roboto:400,700" rel="stylesheet">
<!-- Bootstrap core CSS -->
<link href="/css/style.css" rel="stylesheet">
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png?v=1">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png?v=1">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png?v=1">
<link rel="manifest" href="/site.webmanifest?v=1">
<link rel="mask-icon" href="/safari-pinned-tab.svg?v=1" color="#a91c20">
<link rel="shortcut icon" href="/favicon.ico?v=1">
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="theme-color" content="#ffffff">
<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Richard’s May/June Update | The C++ Alliance</title>
<meta name="generator" content="Jekyll v3.8.7" />
<meta property="og:title" content="Richard’s May/June Update" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Boost 1.74 - Interesting Developments in Asio We’re currently beta-testing Boost 1.74, the lead-up to which has seen a flurry of activity in Asio, which has impacted Beast. Recent versions of Asio have moved away from the idea of sequencing completion handlers directly on an io_context (which used to be called an io_service) towards the execution of completion handlers by an Executor. The basic idea being that the executor is a lightweight handle to some execution context, which did what the io_context always used to do - schedule the execution of completion handlers. The changes to Asio have been tracking The Networking TS which describes a concept of Executor relevant to asynchronous IO. The Unified Executors proposal unifies the concepts of io execution and the general concept of “a place to execute work” - a somewhat more generic idea than merely an IO loop or thread pool. Work has been ongoing by the members of WG21 to produce an execution model that serves all parties’ needs. Courtesy of an incredible effort by Chris Kohlhoff, Latest Asio and Boost.Asio 1.74 has been updated to accommodate both models of executors, with the Unified Executors model being the default. It’s important to note that most users won’t notice the change in API this time around since by default the Asio in 1.74 also includes the 1.73 interface. There are a number of preprocessor macros that can be defined to change this default behaviour: BOOST_ASIO_NO_TS_EXECUTORS Defining this macro disables the Networking TS executor model. The most immediate thing you’ll notice if you define this macro is that for some executor e, the expression e.context() becomes invalid. In the Unified Executors world, this operation is expressed as a query against the executor: auto&amp; ctx = asio::query(e, asio::execution::context); The idea being that the execution context is a property of an executor that can be queried for. Another change which users are likely to notice when this macro is defined is that the asio::executor_work_guard&lt;&gt; template corresponding asio::make_work_guard function is no longer defined. You may well ask then, how we would prevent an underlying execution context from running out of work? In the Unified Executors world, we can think of Executors as an unbounded set of types with various properties enabled or disabled. The idea is that the state of the properties define the behaviour of the interaction between the executor and its underlying context. In the new world, we don’t explicitly create a work guard which references the executor. We ‘simply’ create a new executor which happens to have the property of ‘tracking work’ (i.e. this executor will in some way ensure that the underlying context has outstanding work until the executor’s lifetime ends). Again, given that e is some executor, here’s how we spell this: auto tracked = asio::require(e, asio::execution::outstanding_work.tracked); After executing this statement, there are now two executors in play. The first, e may or may not be “tracking work” (ensuring that the underlying context does not stop), but tracked certainly is. There is another way to spell this, more useful in a generic programming environment. Suppose you were writing generic code and you don’t know the type of the executor presented to you, or even what kind of execution context it is associated with. However, you do know that if the underlying context can stop if it runs out of work, then we want to prevent it from doing so for the duration of some operation. In this case, we can’t use require because this will fail to compile if the given executor does not support the outstanding_work::tracked property. Therefore we would request (or more correctly, prefer) the capability rather than require it: auto maybe_tracked = asio::prefer(e, asio::execution::outstanding_work.tracked); We can now use maybe_tracked as the executor for our operation, and it will “do the right thing” regarding the tracking of work whatever the underlying type of execution context. It is important to note that it is an executor, not merely a guard object that contains an executor. post, dispatch and defer Another notable change in the Asio API when this macro is defined is that models of the Executor concept lose their post, dispatch and defer member functions. The free function versions still remain, so if you have code like this: e.dispatch([]{ /* something */ }); you will need to rewrite it as: asio::dispatch(e, []{ /* something */ }); or you can be more creative with the underlying property system: asio::execution::execute( asio::prefer( e, asio::execution::blocking.possibly), []{ /* something */ }); Which is more-or-less what the implementation of dispatch does under the covers. It’s actually a little more involved than that since the completion token’s associated allocator has to be taken into account. There is a property for that too: asio::execution::allocator. In summary, all previous Asio and Networking TS execution/completion scenarios are now handled by executing a handler in some executor supporting a set of relevant properties. BOOST_ASIO_NO_DEPRECATED Defining this macro will ensure that old asio-style invocation and allocation completion handler customisation functions will no longer be used. The newer paradigm is to explicitly query or require execution properties at the time of scheduling a completion handler for invocation. If you don’t know what any of that means, you’d be in the majority and don’t need to worry about it. BOOST_ASIO_USE_TS_EXECUTOR_AS_DEFAULT As of Boost 1.74, Asio IO objects will be associated with the new asio::any_io_executor rather than the previous polymorphic asio::executor. Defining this macro, undoes this change. It may be useful to you if you have written code that depends on the use of asio::executor. Other observations Strands are Still a Thing Asio strand objects still seem to occupy a twilight zone between executors and something other than executors. To be honest, when I first saw the property mechanism, I assumed that a strand would be “just another executor” with some “sequential execution” property enabled. This turns out not to be the case. A strand has its own distinct execution context which manages the sequencing of completion handler invocations within it. The strand keeps a copy of the inner executor, which is the one where the strand’s completion handlers will be invoked in turn. However, a strand models the Executor concept, so it also is an executor. execute() looks set to become the new call(). Reading the Unified Executors paper is an interesting, exciting or horrifying experience - depending on your view of what you’d like C++ to be. My take from the paper, fleshed out a little with the experience of touching the implementation in Asio, is that in the new world, the programming thought process will go something like this, imagine the following situation: “I need to execute this set of tasks, Ideally I’d like them to execute in parallel, I’d like to wait for them to be done” As I understand things, the idea behind unified executors is that I will be able to express these desires and mandates by executing my work function(s) in some executor yielded by a series of calls to prefer and require. Something like: auto eparallel = prefer(e, bulk_guarantee.unsequenced); // prefer parallel execution auto eblock = require(eparallel, blocking.always); // require blocking execute(eblock, task1, task2, task3, task...); // blocking call which will execute in parallel if possible Proponents will no doubt think, “Great! Programming by expression of intent”. Detractors might say, “Ugh! Nondeterministic programs. How do I debug this when it goes wrong?” To be honest that this stage, I find myself in both camps. No doubt time will tell. Adventures in B2 (Boost Build) Because of the pressure of testing Beast with the new multi-faceted Asio, I wanted a way to bulk compile and test many different variants of: Compilers Preprocessor macro definitions C++ standards etc. I was dimly aware that the Boost build tool, B2, was capable of doing this from one command-line invocation. It’s worth mentioning at this point that I have fairly recently discovered just how powerful B2 is. It’s a shame that it has never been offered to the world in a neat package with some friendly conversation-style documentation, which seems to be the norm these days. It can actually do anything CMake can do and more. For example, all of the above. My thanks to Peter Dimov for teaching me about the existence of B2 features and how to use them. It turns out to be a simple 2-step process: First defined a user-config.jam file to describe the feature and its settings: import feature ; feature.feature asio.mode : dflt nodep nots ts nodep-nots nodep-ts : propagated composite ; feature.compose &lt;asio.mode&gt;nodep : &lt;define&gt;&quot;BOOST_ASIO_NO_DEPRECATED&quot; ; feature.compose &lt;asio.mode&gt;nots : &lt;define&gt;&quot;BOOST_ASIO_NO_TS_EXECUTORS&quot; ; feature.compose &lt;asio.mode&gt;ts : &lt;define&gt;&quot;BOOST_ASIO_USE_TS_EXECUTOR_AS_DEFAULT&quot; ; feature.compose &lt;asio.mode&gt;nodep-nots : &lt;define&gt;&quot;BOOST_ASIO_NO_DEPRECATED&quot; &lt;define&gt;&quot;BOOST_ASIO_NO_TS_EXECUTORS&quot; ; feature.compose &lt;asio.mode&gt;nodep-ts : &lt;define&gt;&quot;BOOST_ASIO_NO_DEPRECATED&quot; &lt;define&gt;&quot;BOOST_ASIO_USE_TS_EXECUTOR_AS_DEFAULT&quot; ; using clang : : clang++ : &lt;stdlib&gt;&quot;libc++&quot; &lt;cxxflags&gt;&quot;-Wno-c99-extensions&quot; ; using gcc : : g++ : &lt;cxxflags&gt;&quot;-Wno-c99-extensions&quot; ; Then ask b2 to do the rest: ./b2 --user-config=./user-config.jam \ toolset=clang,gcc \ asio.mode=dflt,nodep,nots,ts,nodep-nots,nodep-ts \ variant=release \ cxxstd=2a,17,14,11 \ -j`grep processor /proc/cpuinfo | wc -l` \ libs/beast/test libs/beast/example This will compile all examples and run all tests in beast on a linux platform for the cross-product of: clang and gcc all 6 of the legal combinations of the preprocessor macros BOOST_ASIO_NO_DEPRECATED, BOOST_ASIO_NO_TS_EXECUTORS and BOOST_ASIO_USE_TS_EXECUTOR_AS_DEFAULT C++ standards 2a, 17, 14 and 11 So that’s 48 separate scenarios. It will also: Build any dependencies. Build each scenario into its own separately named path in the bin.v2 directory. Understand which tests passed and failed so that passing tests are not re-run on subsequent calls to b2 unless a dependent file has changed. Use as many CPUs as are available on the host (in my case, fortunately that’s 48, otherwise this would take a long time to run)" />
<meta property="og:description" content="Boost 1.74 - Interesting Developments in Asio We’re currently beta-testing Boost 1.74, the lead-up to which has seen a flurry of activity in Asio, which has impacted Beast. Recent versions of Asio have moved away from the idea of sequencing completion handlers directly on an io_context (which used to be called an io_service) towards the execution of completion handlers by an Executor. The basic idea being that the executor is a lightweight handle to some execution context, which did what the io_context always used to do - schedule the execution of completion handlers. The changes to Asio have been tracking The Networking TS which describes a concept of Executor relevant to asynchronous IO. The Unified Executors proposal unifies the concepts of io execution and the general concept of “a place to execute work” - a somewhat more generic idea than merely an IO loop or thread pool. Work has been ongoing by the members of WG21 to produce an execution model that serves all parties’ needs. Courtesy of an incredible effort by Chris Kohlhoff, Latest Asio and Boost.Asio 1.74 has been updated to accommodate both models of executors, with the Unified Executors model being the default. It’s important to note that most users won’t notice the change in API this time around since by default the Asio in 1.74 also includes the 1.73 interface. There are a number of preprocessor macros that can be defined to change this default behaviour: BOOST_ASIO_NO_TS_EXECUTORS Defining this macro disables the Networking TS executor model. The most immediate thing you’ll notice if you define this macro is that for some executor e, the expression e.context() becomes invalid. In the Unified Executors world, this operation is expressed as a query against the executor: auto&amp; ctx = asio::query(e, asio::execution::context); The idea being that the execution context is a property of an executor that can be queried for. Another change which users are likely to notice when this macro is defined is that the asio::executor_work_guard&lt;&gt; template corresponding asio::make_work_guard function is no longer defined. You may well ask then, how we would prevent an underlying execution context from running out of work? In the Unified Executors world, we can think of Executors as an unbounded set of types with various properties enabled or disabled. The idea is that the state of the properties define the behaviour of the interaction between the executor and its underlying context. In the new world, we don’t explicitly create a work guard which references the executor. We ‘simply’ create a new executor which happens to have the property of ‘tracking work’ (i.e. this executor will in some way ensure that the underlying context has outstanding work until the executor’s lifetime ends). Again, given that e is some executor, here’s how we spell this: auto tracked = asio::require(e, asio::execution::outstanding_work.tracked); After executing this statement, there are now two executors in play. The first, e may or may not be “tracking work” (ensuring that the underlying context does not stop), but tracked certainly is. There is another way to spell this, more useful in a generic programming environment. Suppose you were writing generic code and you don’t know the type of the executor presented to you, or even what kind of execution context it is associated with. However, you do know that if the underlying context can stop if it runs out of work, then we want to prevent it from doing so for the duration of some operation. In this case, we can’t use require because this will fail to compile if the given executor does not support the outstanding_work::tracked property. Therefore we would request (or more correctly, prefer) the capability rather than require it: auto maybe_tracked = asio::prefer(e, asio::execution::outstanding_work.tracked); We can now use maybe_tracked as the executor for our operation, and it will “do the right thing” regarding the tracking of work whatever the underlying type of execution context. It is important to note that it is an executor, not merely a guard object that contains an executor. post, dispatch and defer Another notable change in the Asio API when this macro is defined is that models of the Executor concept lose their post, dispatch and defer member functions. The free function versions still remain, so if you have code like this: e.dispatch([]{ /* something */ }); you will need to rewrite it as: asio::dispatch(e, []{ /* something */ }); or you can be more creative with the underlying property system: asio::execution::execute( asio::prefer( e, asio::execution::blocking.possibly), []{ /* something */ }); Which is more-or-less what the implementation of dispatch does under the covers. It’s actually a little more involved than that since the completion token’s associated allocator has to be taken into account. There is a property for that too: asio::execution::allocator. In summary, all previous Asio and Networking TS execution/completion scenarios are now handled by executing a handler in some executor supporting a set of relevant properties. BOOST_ASIO_NO_DEPRECATED Defining this macro will ensure that old asio-style invocation and allocation completion handler customisation functions will no longer be used. The newer paradigm is to explicitly query or require execution properties at the time of scheduling a completion handler for invocation. If you don’t know what any of that means, you’d be in the majority and don’t need to worry about it. BOOST_ASIO_USE_TS_EXECUTOR_AS_DEFAULT As of Boost 1.74, Asio IO objects will be associated with the new asio::any_io_executor rather than the previous polymorphic asio::executor. Defining this macro, undoes this change. It may be useful to you if you have written code that depends on the use of asio::executor. Other observations Strands are Still a Thing Asio strand objects still seem to occupy a twilight zone between executors and something other than executors. To be honest, when I first saw the property mechanism, I assumed that a strand would be “just another executor” with some “sequential execution” property enabled. This turns out not to be the case. A strand has its own distinct execution context which manages the sequencing of completion handler invocations within it. The strand keeps a copy of the inner executor, which is the one where the strand’s completion handlers will be invoked in turn. However, a strand models the Executor concept, so it also is an executor. execute() looks set to become the new call(). Reading the Unified Executors paper is an interesting, exciting or horrifying experience - depending on your view of what you’d like C++ to be. My take from the paper, fleshed out a little with the experience of touching the implementation in Asio, is that in the new world, the programming thought process will go something like this, imagine the following situation: “I need to execute this set of tasks, Ideally I’d like them to execute in parallel, I’d like to wait for them to be done” As I understand things, the idea behind unified executors is that I will be able to express these desires and mandates by executing my work function(s) in some executor yielded by a series of calls to prefer and require. Something like: auto eparallel = prefer(e, bulk_guarantee.unsequenced); // prefer parallel execution auto eblock = require(eparallel, blocking.always); // require blocking execute(eblock, task1, task2, task3, task...); // blocking call which will execute in parallel if possible Proponents will no doubt think, “Great! Programming by expression of intent”. Detractors might say, “Ugh! Nondeterministic programs. How do I debug this when it goes wrong?” To be honest that this stage, I find myself in both camps. No doubt time will tell. Adventures in B2 (Boost Build) Because of the pressure of testing Beast with the new multi-faceted Asio, I wanted a way to bulk compile and test many different variants of: Compilers Preprocessor macro definitions C++ standards etc. I was dimly aware that the Boost build tool, B2, was capable of doing this from one command-line invocation. It’s worth mentioning at this point that I have fairly recently discovered just how powerful B2 is. It’s a shame that it has never been offered to the world in a neat package with some friendly conversation-style documentation, which seems to be the norm these days. It can actually do anything CMake can do and more. For example, all of the above. My thanks to Peter Dimov for teaching me about the existence of B2 features and how to use them. It turns out to be a simple 2-step process: First defined a user-config.jam file to describe the feature and its settings: import feature ; feature.feature asio.mode : dflt nodep nots ts nodep-nots nodep-ts : propagated composite ; feature.compose &lt;asio.mode&gt;nodep : &lt;define&gt;&quot;BOOST_ASIO_NO_DEPRECATED&quot; ; feature.compose &lt;asio.mode&gt;nots : &lt;define&gt;&quot;BOOST_ASIO_NO_TS_EXECUTORS&quot; ; feature.compose &lt;asio.mode&gt;ts : &lt;define&gt;&quot;BOOST_ASIO_USE_TS_EXECUTOR_AS_DEFAULT&quot; ; feature.compose &lt;asio.mode&gt;nodep-nots : &lt;define&gt;&quot;BOOST_ASIO_NO_DEPRECATED&quot; &lt;define&gt;&quot;BOOST_ASIO_NO_TS_EXECUTORS&quot; ; feature.compose &lt;asio.mode&gt;nodep-ts : &lt;define&gt;&quot;BOOST_ASIO_NO_DEPRECATED&quot; &lt;define&gt;&quot;BOOST_ASIO_USE_TS_EXECUTOR_AS_DEFAULT&quot; ; using clang : : clang++ : &lt;stdlib&gt;&quot;libc++&quot; &lt;cxxflags&gt;&quot;-Wno-c99-extensions&quot; ; using gcc : : g++ : &lt;cxxflags&gt;&quot;-Wno-c99-extensions&quot; ; Then ask b2 to do the rest: ./b2 --user-config=./user-config.jam \ toolset=clang,gcc \ asio.mode=dflt,nodep,nots,ts,nodep-nots,nodep-ts \ variant=release \ cxxstd=2a,17,14,11 \ -j`grep processor /proc/cpuinfo | wc -l` \ libs/beast/test libs/beast/example This will compile all examples and run all tests in beast on a linux platform for the cross-product of: clang and gcc all 6 of the legal combinations of the preprocessor macros BOOST_ASIO_NO_DEPRECATED, BOOST_ASIO_NO_TS_EXECUTORS and BOOST_ASIO_USE_TS_EXECUTOR_AS_DEFAULT C++ standards 2a, 17, 14 and 11 So that’s 48 separate scenarios. It will also: Build any dependencies. Build each scenario into its own separately named path in the bin.v2 directory. Understand which tests passed and failed so that passing tests are not re-run on subsequent calls to b2 unless a dependent file has changed. Use as many CPUs as are available on the host (in my case, fortunately that’s 48, otherwise this would take a long time to run)" />
<link rel="canonical" href="http://cppalliance.org/richard/2020/07/01/RichardsJuneUpdate.html" />
<meta property="og:url" content="http://cppalliance.org/richard/2020/07/01/RichardsJuneUpdate.html" />
<meta property="og:site_name" content="The C++ Alliance" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-07-01T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Richard’s May/June Update" />
<meta name="twitter:site" content="@CPPAlliance" />
<script type="application/ld+json">
{"description":"Boost 1.74 - Interesting Developments in Asio We’re currently beta-testing Boost 1.74, the lead-up to which has seen a flurry of activity in Asio, which has impacted Beast. Recent versions of Asio have moved away from the idea of sequencing completion handlers directly on an io_context (which used to be called an io_service) towards the execution of completion handlers by an Executor. The basic idea being that the executor is a lightweight handle to some execution context, which did what the io_context always used to do - schedule the execution of completion handlers. The changes to Asio have been tracking The Networking TS which describes a concept of Executor relevant to asynchronous IO. The Unified Executors proposal unifies the concepts of io execution and the general concept of “a place to execute work” - a somewhat more generic idea than merely an IO loop or thread pool. Work has been ongoing by the members of WG21 to produce an execution model that serves all parties’ needs. Courtesy of an incredible effort by Chris Kohlhoff, Latest Asio and Boost.Asio 1.74 has been updated to accommodate both models of executors, with the Unified Executors model being the default. It’s important to note that most users won’t notice the change in API this time around since by default the Asio in 1.74 also includes the 1.73 interface. There are a number of preprocessor macros that can be defined to change this default behaviour: BOOST_ASIO_NO_TS_EXECUTORS Defining this macro disables the Networking TS executor model. The most immediate thing you’ll notice if you define this macro is that for some executor e, the expression e.context() becomes invalid. In the Unified Executors world, this operation is expressed as a query against the executor: auto&amp; ctx = asio::query(e, asio::execution::context); The idea being that the execution context is a property of an executor that can be queried for. Another change which users are likely to notice when this macro is defined is that the asio::executor_work_guard&lt;&gt; template corresponding asio::make_work_guard function is no longer defined. You may well ask then, how we would prevent an underlying execution context from running out of work? In the Unified Executors world, we can think of Executors as an unbounded set of types with various properties enabled or disabled. The idea is that the state of the properties define the behaviour of the interaction between the executor and its underlying context. In the new world, we don’t explicitly create a work guard which references the executor. We ‘simply’ create a new executor which happens to have the property of ‘tracking work’ (i.e. this executor will in some way ensure that the underlying context has outstanding work until the executor’s lifetime ends). Again, given that e is some executor, here’s how we spell this: auto tracked = asio::require(e, asio::execution::outstanding_work.tracked); After executing this statement, there are now two executors in play. The first, e may or may not be “tracking work” (ensuring that the underlying context does not stop), but tracked certainly is. There is another way to spell this, more useful in a generic programming environment. Suppose you were writing generic code and you don’t know the type of the executor presented to you, or even what kind of execution context it is associated with. However, you do know that if the underlying context can stop if it runs out of work, then we want to prevent it from doing so for the duration of some operation. In this case, we can’t use require because this will fail to compile if the given executor does not support the outstanding_work::tracked property. Therefore we would request (or more correctly, prefer) the capability rather than require it: auto maybe_tracked = asio::prefer(e, asio::execution::outstanding_work.tracked); We can now use maybe_tracked as the executor for our operation, and it will “do the right thing” regarding the tracking of work whatever the underlying type of execution context. It is important to note that it is an executor, not merely a guard object that contains an executor. post, dispatch and defer Another notable change in the Asio API when this macro is defined is that models of the Executor concept lose their post, dispatch and defer member functions. The free function versions still remain, so if you have code like this: e.dispatch([]{ /* something */ }); you will need to rewrite it as: asio::dispatch(e, []{ /* something */ }); or you can be more creative with the underlying property system: asio::execution::execute( asio::prefer( e, asio::execution::blocking.possibly), []{ /* something */ }); Which is more-or-less what the implementation of dispatch does under the covers. It’s actually a little more involved than that since the completion token’s associated allocator has to be taken into account. There is a property for that too: asio::execution::allocator. In summary, all previous Asio and Networking TS execution/completion scenarios are now handled by executing a handler in some executor supporting a set of relevant properties. BOOST_ASIO_NO_DEPRECATED Defining this macro will ensure that old asio-style invocation and allocation completion handler customisation functions will no longer be used. The newer paradigm is to explicitly query or require execution properties at the time of scheduling a completion handler for invocation. If you don’t know what any of that means, you’d be in the majority and don’t need to worry about it. BOOST_ASIO_USE_TS_EXECUTOR_AS_DEFAULT As of Boost 1.74, Asio IO objects will be associated with the new asio::any_io_executor rather than the previous polymorphic asio::executor. Defining this macro, undoes this change. It may be useful to you if you have written code that depends on the use of asio::executor. Other observations Strands are Still a Thing Asio strand objects still seem to occupy a twilight zone between executors and something other than executors. To be honest, when I first saw the property mechanism, I assumed that a strand would be “just another executor” with some “sequential execution” property enabled. This turns out not to be the case. A strand has its own distinct execution context which manages the sequencing of completion handler invocations within it. The strand keeps a copy of the inner executor, which is the one where the strand’s completion handlers will be invoked in turn. However, a strand models the Executor concept, so it also is an executor. execute() looks set to become the new call(). Reading the Unified Executors paper is an interesting, exciting or horrifying experience - depending on your view of what you’d like C++ to be. My take from the paper, fleshed out a little with the experience of touching the implementation in Asio, is that in the new world, the programming thought process will go something like this, imagine the following situation: “I need to execute this set of tasks, Ideally I’d like them to execute in parallel, I’d like to wait for them to be done” As I understand things, the idea behind unified executors is that I will be able to express these desires and mandates by executing my work function(s) in some executor yielded by a series of calls to prefer and require. Something like: auto eparallel = prefer(e, bulk_guarantee.unsequenced); // prefer parallel execution auto eblock = require(eparallel, blocking.always); // require blocking execute(eblock, task1, task2, task3, task...); // blocking call which will execute in parallel if possible Proponents will no doubt think, “Great! Programming by expression of intent”. Detractors might say, “Ugh! Nondeterministic programs. How do I debug this when it goes wrong?” To be honest that this stage, I find myself in both camps. No doubt time will tell. Adventures in B2 (Boost Build) Because of the pressure of testing Beast with the new multi-faceted Asio, I wanted a way to bulk compile and test many different variants of: Compilers Preprocessor macro definitions C++ standards etc. I was dimly aware that the Boost build tool, B2, was capable of doing this from one command-line invocation. It’s worth mentioning at this point that I have fairly recently discovered just how powerful B2 is. It’s a shame that it has never been offered to the world in a neat package with some friendly conversation-style documentation, which seems to be the norm these days. It can actually do anything CMake can do and more. For example, all of the above. My thanks to Peter Dimov for teaching me about the existence of B2 features and how to use them. It turns out to be a simple 2-step process: First defined a user-config.jam file to describe the feature and its settings: import feature ; feature.feature asio.mode : dflt nodep nots ts nodep-nots nodep-ts : propagated composite ; feature.compose &lt;asio.mode&gt;nodep : &lt;define&gt;&quot;BOOST_ASIO_NO_DEPRECATED&quot; ; feature.compose &lt;asio.mode&gt;nots : &lt;define&gt;&quot;BOOST_ASIO_NO_TS_EXECUTORS&quot; ; feature.compose &lt;asio.mode&gt;ts : &lt;define&gt;&quot;BOOST_ASIO_USE_TS_EXECUTOR_AS_DEFAULT&quot; ; feature.compose &lt;asio.mode&gt;nodep-nots : &lt;define&gt;&quot;BOOST_ASIO_NO_DEPRECATED&quot; &lt;define&gt;&quot;BOOST_ASIO_NO_TS_EXECUTORS&quot; ; feature.compose &lt;asio.mode&gt;nodep-ts : &lt;define&gt;&quot;BOOST_ASIO_NO_DEPRECATED&quot; &lt;define&gt;&quot;BOOST_ASIO_USE_TS_EXECUTOR_AS_DEFAULT&quot; ; using clang : : clang++ : &lt;stdlib&gt;&quot;libc++&quot; &lt;cxxflags&gt;&quot;-Wno-c99-extensions&quot; ; using gcc : : g++ : &lt;cxxflags&gt;&quot;-Wno-c99-extensions&quot; ; Then ask b2 to do the rest: ./b2 --user-config=./user-config.jam \\ toolset=clang,gcc \\ asio.mode=dflt,nodep,nots,ts,nodep-nots,nodep-ts \\ variant=release \\ cxxstd=2a,17,14,11 \\ -j`grep processor /proc/cpuinfo | wc -l` \\ libs/beast/test libs/beast/example This will compile all examples and run all tests in beast on a linux platform for the cross-product of: clang and gcc all 6 of the legal combinations of the preprocessor macros BOOST_ASIO_NO_DEPRECATED, BOOST_ASIO_NO_TS_EXECUTORS and BOOST_ASIO_USE_TS_EXECUTOR_AS_DEFAULT C++ standards 2a, 17, 14 and 11 So that’s 48 separate scenarios. It will also: Build any dependencies. Build each scenario into its own separately named path in the bin.v2 directory. Understand which tests passed and failed so that passing tests are not re-run on subsequent calls to b2 unless a dependent file has changed. Use as many CPUs as are available on the host (in my case, fortunately that’s 48, otherwise this would take a long time to run)","@type":"BlogPosting","url":"http://cppalliance.org/richard/2020/07/01/RichardsJuneUpdate.html","headline":"Richard’s May/June Update","dateModified":"2020-07-01T00:00:00+00:00","datePublished":"2020-07-01T00:00:00+00:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://cppalliance.org/richard/2020/07/01/RichardsJuneUpdate.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->



<link href="/css/prism.css" rel="stylesheet">


<link href='/feed.xml' rel='alternate' type='application/atom+xml'>

</head>

<body id='body' class="line-numbers">

  <!-- Navigation -->
  <nav class='nav dark'>
    <a href='/'>
      <img class='logo' alt='cpp-alliance-logo' src='/images/logo.svg' />
    </a>
    <div class='hamburger' id='nav-hamburger'>
      <span class='hamburger-line'></span>
      <span class='hamburger-line'></span>
      <span class='hamburger-line'></span>
    </div>
    <div class='nav-items' id='nav-items'>
      <div class="nav-item"><a class="nav-link nav-link-mobile" href="/">Home</a></div>
      <div class="nav-item"><a class="nav-link nav-link-mobile" href="/#mission">Mission</a></div>
      <div class="nav-item"><a class="nav-link nav-link-mobile" href="/#team">Team</a></div>
      <div class="nav-item"><a class="nav-link nav-link-mobile" href="/#news">News</a></div>
      <div class="nav-item"><a class="nav-link nav-link-mobile" href="/#links">Links</a></div>
      <div class="nav-item"><a class="nav-link nav-link-mobile" href="/#faq">FAQ</a></div>
      <div class="nav-item"><a class="nav-link nav-link-mobile" href="/#contact">Contact</a></div>
      <div class='socials'>
        <div class='connect-content'>
          <div class='row row-sm'>
            <div class='col-fourth col-fourth-sm social-link'>
              <a class='social-icon nav-link-mobile' href="https://github.com/CPPAlliance">
                <div class='social-icon-img-wrapper'>
                  <img class='social-icon-img github' alt='github-logo' src='/images/icons/github.svg' />
                </div>
                <span class='social-icon-text'>GitHub</span>
              </a>
            </div>
            <div class='col-fourth col-fourth-sm social-link'>
              <a class='social-icon nav-link-mobile' href="https://www.facebook.com/CPPAlliance/">
                <div class='social-icon-img-wrapper'>
                  <img class='social-icon-img facebook' alt='facebook-logo' src='/images/icons/facebook.svg' />
                </div>
                <span class='social-icon-text'>Facebook</span>
              </a>
            </div>
            <div class='col-fourth col-fourth-sm social-link'>
              <a class='social-icon nav-link-mobile' href="https://twitter.com/cppalliance">
                <div class='social-icon-img-wrapper'>
                  <img class='social-icon-img twitter' alt='twitter-logo' src='/images/icons/twitter.svg' />
                </div>
                <span class='social-icon-text'>Twitter</span>
              </a>
            </div>
            <div class='col-fourth col-fourth-sm social-link'>
              <a class='social-icon nav-link-mobile' href="https://www.linkedin.com/in/cppalliance/">
                <div class='social-icon-img-wrapper'>
                  <img class='social-icon-img linkedin' alt='linkedin-logo' src='/images/icons/linkedin.svg' />
                </div>
                <span class='social-icon-text'>LinkedIn</span>
              </a>
            </div>
          </div>
        </div>
      </div>
    </div>
  </nav>






  <div class='post'>
  <div class='current-article'>
    

    <section class='section article'>
      

      <article>
      <div class="title-section center">
        <h2 class='text-l news-title no-border'>Richard's May/June Update</h2>



        
        <div class='author d-iblock'>
          <!-- list of all potential authors -->

          <span class='text-xxs author-name'>By
              <a class='link' href='/people/richard'>

              
              
              

                

              

                

              

                

              

                

              

                

              

                

              

                

              

                

              

                

              

                

              

                

              

                

              

                

              

                
                  Richard Hodges
                

              

                

              

                

              

                

              

                

              

                

              

                

              

                

              

                

              

                

              

                

              

                

              

                

              

                

              

                

              

                

              

                

              

                

              

                

              

              
              </a> on
              
          </span>
        </div>
        
        <span class='center'>Jul 1, 2020</span>
      </div>
        <div class='text-xxs content-text generated-content'>
          <h1 id="boost-174---interesting-developments-in-asio">Boost 1.74 - Interesting Developments in Asio</h1>

<p>We’re currently beta-testing Boost 1.74, the lead-up to which has seen a flurry of activity in Asio, which has
impacted Beast.</p>

<p>Recent versions of Asio have moved away from the idea of sequencing completion handlers directly on an <code>io_context</code>
(which used to be called an <code>io_service</code>) towards the execution of completion handlers by an Executor.</p>

<p>The basic idea being that the executor is a lightweight handle to some execution context, which did what the <code>io_context</code>
always used to do - schedule the execution of completion handlers.</p>

<p>The changes to Asio have been tracking 
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/n4771.pdf">The Networking TS</a> which describes a concept
of Executor relevant to asynchronous IO.</p>

<p>The <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p0443r11.html">Unified Executors</a> proposal unifies the 
concepts of io execution and the general concept of “a place to execute work” - a somewhat more generic idea than merely
an IO loop or thread pool. Work has been ongoing by the members of WG21 to produce an execution model that 
serves all parties’ needs.</p>

<p>Courtesy of an incredible effort by Chris Kohlhoff, Latest Asio and Boost.Asio 1.74 has been updated to accommodate both 
models of executors, with the Unified Executors model being the default. It’s important to note that most users won’t 
notice the change in API this time around since by default the Asio in 1.74 also includes the 1.73 interface.</p>

<p>There are a number of preprocessor macros that can be defined to change this default behaviour:</p>

<h2 id="boost_asio_no_ts_executors"><code>BOOST_ASIO_NO_TS_EXECUTORS</code></h2>

<p>Defining this macro disables the Networking TS executor model. The most immediate thing you’ll notice if you define this
macro is that for some executor <code>e</code>, the expression <code>e.context()</code> becomes invalid.</p>

<p>In the Unified Executors world, this operation is expressed as a query against the executor:</p>
<pre><code class="language-c++">auto&amp; ctx = asio::query(e, asio::execution::context);
</code></pre>
<p>The idea being that the execution context is a <em>property</em> of an executor that can be <em>queried</em> for.</p>

<p>Another change which users are likely to notice when this macro is defined is that the <code>asio::executor_work_guard&lt;&gt;</code> 
template corresponding <code>asio::make_work_guard</code> function is no longer defined.</p>

<p>You may well ask then, how we would prevent an underlying execution context from running out of work?</p>

<p>In the Unified Executors world, we can think of Executors as an unbounded set of types with various properties
enabled or disabled. The idea is that the state of the properties define the behaviour of the interaction between the 
executor and its underlying context.</p>

<p>In the new world, we don’t explicitly create a work guard which references the executor. We ‘simply’ create a new
executor which happens to have the property of ‘tracking work’ (i.e. this executor will in some way ensure that the 
underlying context has outstanding work until the executor’s lifetime ends).</p>

<p>Again, given that <code>e</code> is some executor, here’s how we spell this:</p>

<pre><code class="language-c++">auto tracked = asio::require(e, asio::execution::outstanding_work.tracked);
</code></pre>

<p>After executing this statement, there are now two executors in play. The first, <code>e</code> may or may not be “tracking work”
(ensuring that the underlying context does not stop), but <code>tracked</code> certainly is.</p>

<p>There is another way to spell this, more useful in a generic programming environment.</p>

<p>Suppose you were writing generic code and you don’t know the type of the executor presented to you, or even what kind
of execution context it is associated with. However, you do know that <em>if</em> the underlying context can stop if it runs
out of work, then we want to prevent it from doing so for the duration of some operation.</p>

<p>In this case, we can’t use <code>require</code> because this will fail to compile if the given executor does not support the 
<code>outstanding_work::tracked</code> property. Therefore we would request (or more correctly, <em>prefer</em>) the capability rather 
than require it:</p>

<pre><code class="language-c++">auto maybe_tracked = asio::prefer(e, asio::execution::outstanding_work.tracked);
</code></pre>

<p>We can now use <code>maybe_tracked</code> as the executor for our operation, and it will “do the right thing” regarding the tracking
of work whatever the underlying type of execution context. It is important to note that it <em>is</em> an executor, not merely
a guard object that contains an executor.</p>

<h3 id="post-dispatch-and-defer">post, dispatch and defer</h3>

<p>Another notable change in the Asio API when this macro is defined is that models of the Executor concept lose their
<code>post</code>, <code>dispatch</code> and <code>defer</code> member functions.</p>

<p>The free function versions still remain, so if you have code like this:</p>
<pre><code class="language-c++">e.dispatch([]{ /* something */ });
</code></pre>

<p>you will need to rewrite it as:</p>

<pre><code class="language-c++">asio::dispatch(e, []{ /* something */ });
</code></pre>

<p>or you can be more creative with the underlying property system:</p>

<pre><code class="language-c++">asio::execution::execute(
    asio::prefer(
        e, 
        asio::execution::blocking.possibly), 
    []{ /* something */ });
</code></pre>

<p>Which is more-or-less what the implementation of <code>dispatch</code> does under the covers. It’s actually a little more involved
than that since the completion token’s associated allocator has to be taken into account. There is a 
property for that too: <code>asio::execution::allocator</code>.</p>

<p>In summary, all previous Asio and Networking TS execution/completion scenarios are now handled by executing a handler
in some executor supporting a set of relevant properties.</p>

<h2 id="boost_asio_no_deprecated">BOOST_ASIO_NO_DEPRECATED</h2>

<p>Defining this macro will ensure that old asio-style invocation and allocation completion handler customisation
functions will no longer be used. The newer paradigm is to explicitly query or require execution properties at the 
time of scheduling a completion handler for invocation. If you don’t know what any of that means, you’d be in the 
majority and don’t need to worry about it.</p>

<h2 id="boost_asio_use_ts_executor_as_default">BOOST_ASIO_USE_TS_EXECUTOR_AS_DEFAULT</h2>

<p>As of Boost 1.74, Asio IO objects will be associated with the new <code>asio::any_io_executor</code> rather than the previous
polymorphic <code>asio::executor</code>. Defining this macro, undoes this change. It may be useful to you if you have written code
that depends on the use of <code>asio::executor</code>.</p>

<h2 id="other-observations">Other observations</h2>

<h3 id="strands-are-still-a-thing">Strands are Still a Thing</h3>

<p>Asio <code>strand</code> objects still seem to occupy a twilight zone between executors and something other than executors.</p>

<p>To be honest, when I first saw the property mechanism, I assumed that a strand would be “just another executor” with 
some “sequential execution” property enabled. This turns out not to be the case. A strand has its own distinct execution
context which manages the sequencing of completion handler invocations within it. The strand keeps a copy of the inner
executor, which is the one where the strand’s completion handlers will be invoked in turn.</p>

<p>However, a strand models the Executor concept, so it also <em>is an</em> executor.</p>

<h3 id="execute-looks-set-to-become-the-new-call">execute() looks set to become the new call().</h3>

<p>Reading the Unified Executors paper is an interesting, exciting or horrifying experience - depending on your view of
what you’d like C++ to be.</p>

<p>My take from the paper, fleshed out a little with the experience of touching the implementation in Asio, is that in the 
new world, the programming thought process will go something like this,
imagine the following situation:</p>

<p>“I need to execute this set of tasks,</p>

<p>Ideally I’d like them to execute in parallel,</p>

<p>I’d like to wait for them to be done”</p>

<p>As I understand things, the idea behind unified executors is that I will be able to express these desires and mandates
by executing my work function(s) in some executor yielded by a series of calls to <code>prefer</code> and <code>require</code>.</p>

<p>Something like:</p>

<pre><code class="language-c++">    auto eparallel = prefer(e, bulk_guarantee.unsequenced); // prefer parallel execution
    auto eblock = require(eparallel, blocking.always);      // require blocking
    execute(eblock, task1, task2, task3, task...);          // blocking call which will execute in parallel if possible
</code></pre>

<p>Proponents will no doubt think,</p>

<p>“Great! Programming by expression of intent”.</p>

<p>Detractors might say,</p>

<p>“Ugh! Nondeterministic programs. How do I debug this when it goes wrong?”</p>

<p>To be honest that this stage, I find myself in both camps. No doubt time will tell.</p>

<h1 id="adventures-in-b2-boost-build">Adventures in B2 (Boost Build)</h1>

<p>Because of the pressure of testing Beast with the new multi-faceted Asio, I wanted a way to bulk compile and test many
different variants of:</p>

<ul>
  <li>Compilers</li>
  <li>Preprocessor macro definitions</li>
  <li>C++ standards</li>
  <li>etc.</li>
</ul>

<p>I was dimly aware that the Boost build tool, B2, was capable of doing this from one command-line invocation.</p>

<p>It’s worth mentioning at this point that I have fairly recently discovered just how powerful B2 is. It’s a shame that
it has never been offered to the world in a neat package with some friendly conversation-style documentation, which
seems to be the norm these days.</p>

<p>It can actually do anything CMake can do and more. For example, all of the above.</p>

<p>My thanks to Peter Dimov for teaching me about the existence of B2 <em>features</em> and how to use them.</p>

<p>It turns out to be a simple 2-step process:</p>

<p>First defined a <code>user-config.jam</code> file to describe the feature and its settings:</p>

<pre><code class="language-jam">import feature ;

feature.feature asio.mode : dflt nodep nots ts nodep-nots nodep-ts : propagated composite ;
feature.compose &lt;asio.mode&gt;nodep : &lt;define&gt;"BOOST_ASIO_NO_DEPRECATED" ;
feature.compose &lt;asio.mode&gt;nots : &lt;define&gt;"BOOST_ASIO_NO_TS_EXECUTORS" ;
feature.compose &lt;asio.mode&gt;ts : &lt;define&gt;"BOOST_ASIO_USE_TS_EXECUTOR_AS_DEFAULT" ;
feature.compose &lt;asio.mode&gt;nodep-nots : &lt;define&gt;"BOOST_ASIO_NO_DEPRECATED" &lt;define&gt;"BOOST_ASIO_NO_TS_EXECUTORS" ;
feature.compose &lt;asio.mode&gt;nodep-ts : &lt;define&gt;"BOOST_ASIO_NO_DEPRECATED" &lt;define&gt;"BOOST_ASIO_USE_TS_EXECUTOR_AS_DEFAULT" ;

using clang :   : clang++ : &lt;stdlib&gt;"libc++" &lt;cxxflags&gt;"-Wno-c99-extensions" ;
using gcc :   : g++ : &lt;cxxflags&gt;"-Wno-c99-extensions" ;
</code></pre>

<p>Then ask b2 to do the rest:</p>

<pre><code>./b2 --user-config=./user-config.jam \
  toolset=clang,gcc \
  asio.mode=dflt,nodep,nots,ts,nodep-nots,nodep-ts \
  variant=release \
  cxxstd=2a,17,14,11 \
  -j`grep processor /proc/cpuinfo | wc -l` \
  libs/beast/test libs/beast/example
</code></pre>

<p>This will compile all examples and run all tests in beast on a linux platform for the cross-product of:</p>

<ol>
  <li>clang and gcc</li>
  <li>all 6 of the legal combinations of the preprocessor macros BOOST_ASIO_NO_DEPRECATED, BOOST_ASIO_NO_TS_EXECUTORS and 
BOOST_ASIO_USE_TS_EXECUTOR_AS_DEFAULT</li>
  <li>C++ standards 2a, 17, 14 and 11</li>
</ol>

<p>So that’s 48 separate scenarios.</p>

<p>It will also:</p>

<ul>
  <li>Build any dependencies.</li>
  <li>Build each scenario into its own separately named path in the bin.v2 directory.</li>
  <li>Understand which tests passed and failed so that passing tests are not re-run on subsequent calls to b2 unless a
dependent file has changed.</li>
  <li>Use as many CPUs as are available on the host (in my case, fortunately that’s 48, otherwise this would take a long time
to run)</li>
</ul>


        </div>
      </article>
    </section>
  </div>

  <section class="section news bottom-layout" id='news'>
    <div class='section-title'>
      <h2 class='header text-xl recent-post-header'>All Posts by This Author</h2>
    </div>
    <div class='news-content formatted-text'>
      
      <ul>
        
        
        <li class='news-list-item '>
          <span class='text-xs news-date'>10/31/2020</span>
          <a class='text-l news-title link' href="/richard/2020/10/31/RichardsOctoberUpdate.html">Richard's October Update</a>
        </li>
        
        
        
        <li class='news-list-item '>
          <span class='text-xs news-date'>09/30/2020</span>
          <a class='text-l news-title link' href="/richard/2020/09/30/RichardsSeptemberUpdate.html">Richard's September Update</a>
        </li>
        
        
        
        
        
        
        
        <li class='news-list-item '>
          <span class='text-xs news-date'>09/01/2020</span>
          <a class='text-l news-title link' href="/richard/2020/09/01/RichardsAugustUpdate.html">Richard's August Update</a>
        </li>
        
        
        
        <li class='news-list-item '>
          <span class='text-xs news-date'>08/01/2020</span>
          <a class='text-l news-title link' href="/richard/2020/08/01/RichardsJulyUpdate.html">Richard's July Update</a>
        </li>
        
        
        
        
        
        
        
        <li class='news-list-item '>
          <span class='text-xs news-date'>07/01/2020</span>
          <a class='text-l news-title link' href="/richard/2020/07/01/RichardsJuneUpdate.html">Richard's May/June Update</a>
        </li>
        
        
        
        
        
        
        
        <li class='news-list-item '>
          <span class='text-xs news-date'>04/30/2020</span>
          <a class='text-l news-title link' href="/richard/2020/04/30/RichardsAprilUpdate.html">Richard's April Update</a>
        </li>
        
        
        
        
        
        
        
        <li class='news-list-item '>
          <span class='text-xs news-date'>03/31/2020</span>
          <a class='text-l news-title link' href="/richard/2020/03/31/RichardsMarchUpdate.html">Richard's March Update</a>
        </li>
        
        
        
        
        
        <li class='news-list-item '>
          <span class='text-xs news-date'>02/29/2020</span>
          <a class='text-l news-title link' href="/richard/2020/02/29/RichardsFebruaryUpdate.html">Richard's February Update</a>
        </li>
        
        
        
        <li class='news-list-item '>
          <span class='text-xs news-date'>01/31/2020</span>
          <a class='text-l news-title link' href="/richard/2020/01/31/RichardsJanuaryUpdate.html">Richard's January Update</a>
        </li>
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        <li>
          <a class='text-l all link' href="/news">View All Posts...</a>
        </li>
      </ul>
    </div>
  </section>

</div>


  <footer class='footer'>
    <p class='text-xxs footer-text'>
      <span class='line'>&copy; 2020 The C Plus Plus Alliance, Inc.</span>
      <span class='line'>Contact us at: <a href='mailto:%69%6E%66%6F@%63%70%70%61%6C%6C%69%61%6E%63%65.%6F%72%67'>info@cppalliance.org</a></span>
    </p>
  </footer>

  <!-- Bootstrap core JavaScript -->
  <script src='/js/main.js'></script>
  
  <script src='/js/prism.js'></script>
  

  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-76438364-18', 'auto');
    ga('send', 'pageview');
  </script>

</body>
</html>
